{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import sys\n",
    "import numpy\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Merge\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "questions = open('abstract_math_questions.txt','r')\n",
    "labels = open('abstract_math_labels.txt','r')\n",
    "info_sentences = open('abstract_math_info.txt','r')\n",
    "fact_sentences = open('abstract_math_facts.txt','r')\n",
    "standard_relations = open('abstract_math_relations.txt','r')\n",
    "\n",
    "questions_list = []\n",
    "labels_list = []\n",
    "info_list = []\n",
    "relations_list = []\n",
    "facts_list = []\n",
    "\n",
    "for sentence in questions:\n",
    "    questions_list.append(sentence)\n",
    "    \n",
    "for sentence in labels:\n",
    "    labels_list.append(sentence)\n",
    "    \n",
    "for sentence in info_sentences:\n",
    "    info_list.append(sentence)\n",
    "\n",
    "for sentence in fact_sentences:\n",
    "    facts_list.append(sentence)\n",
    "    \n",
    "for sentence in standard_relations:\n",
    "    relations_list.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "10\n",
      "26\n",
      "5\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(questions_list[0]))\n",
    "print(len(labels_list[0]))\n",
    "print(len(info_list[0]))\n",
    "print(len(facts_list[0]))\n",
    "print(len(relations_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#in this version, we put placeholders for numbers, such as QN1, QN2, etc.. for question numbers\n",
    "\n",
    "fact_num_dict_list = []\n",
    "ques_num_dict_list = []\n",
    "info_num_dict_list = []\n",
    "rela_num_dict_list = []\n",
    "\n",
    "changed_facts_list = []\n",
    "changed_questions_list = []\n",
    "changed_info_list = []\n",
    "changed_relations_list = []\n",
    "\n",
    "#store the numbers in a list of dicts\n",
    "#for facts list: (we will only process the info list, as others do not have numbers this time)\n",
    "for sentence in facts_list:\n",
    "    fact_num_dict = {}\n",
    "    changed_fact_sentence = []\n",
    "    indx_num = 1\n",
    "    for word in sentence.split():\n",
    "        changed_fact_sentence.append(word)\n",
    "    changed_facts_list.append(changed_fact_sentence)\n",
    "    fact_num_dict_list.append(fact_num_dict)\n",
    "\n",
    "#repeat for questions\n",
    "for sentence in questions_list:\n",
    "    quest_num_dict = {}\n",
    "    changed_qu_sentence = []\n",
    "    indx_num = 1\n",
    "    for word in sentence.split():\n",
    "        changed_qu_sentence.append(word)\n",
    "    changed_questions_list.append(changed_qu_sentence)\n",
    "    ques_num_dict_list.append(quest_num_dict)   \n",
    "\n",
    "#repeat for information\n",
    "for sentence in info_list:\n",
    "    info_num_dict = {}\n",
    "    changed_info_sentence = []\n",
    "    indx_num = 1\n",
    "    for word in sentence.split():\n",
    "        if word.isdigit():\n",
    "            if indx_num == 1:\n",
    "                new_word = \"IN1\"\n",
    "            elif indx_num == 2:\n",
    "                new_word = \"IN2\"\n",
    "            elif indx_num == 3:\n",
    "                new_word = \"IN3\"\n",
    "            elif indx_num == 4:\n",
    "                new_word = \"IN4\"\n",
    "            elif indx_num == 5:\n",
    "                new_word = \"IN5\"\n",
    "            info_num_dict[word] = new_word\n",
    "            changed_info_sentence.append(new_word)\n",
    "            indx_num += 1\n",
    "        else:\n",
    "            changed_info_sentence.append(word)\n",
    "    changed_info_list.append(changed_info_sentence)\n",
    "    info_num_dict_list.append(info_num_dict)   \n",
    "\n",
    "#repeat for information\n",
    "for sentence in relations_list:\n",
    "    rela_num_dict = {}\n",
    "    changed_rela_sentence = []\n",
    "    indx_num = 1\n",
    "    for word in sentence.split():\n",
    "        changed_rela_sentence.append(word)\n",
    "    changed_relations_list.append(changed_rela_sentence)\n",
    "    rela_num_dict_list.append(info_num_dict)   \n",
    "    \n",
    "facts_list = changed_facts_list\n",
    "questions_list = changed_questions_list\n",
    "info_list = changed_info_list\n",
    "relations_list = changed_relations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "list_of_all_variables = []\n",
    "\n",
    "### Let's make a list of all variables and prepare them for one-hot-coding\n",
    "\n",
    "# Start by assigning numbers to the standard variables:\n",
    "\n",
    "list_of_all_variables.append(\"QN1\")\n",
    "list_of_all_variables.append(\"QN2\")\n",
    "list_of_all_variables.append(\"QN3\")\n",
    "list_of_all_variables.append(\"QN4\")\n",
    "list_of_all_variables.append(\"QN5\")\n",
    "list_of_all_variables.append(\"QN6\")\n",
    "list_of_all_variables.append(\"QN7\")\n",
    "list_of_all_variables.append(\"QN8\")\n",
    "list_of_all_variables.append(\"FN1\")\n",
    "list_of_all_variables.append(\"FN2\")\n",
    "list_of_all_variables.append(\"FN3\")\n",
    "list_of_all_variables.append(\"FN4\")\n",
    "list_of_all_variables.append(\"FN5\")\n",
    "list_of_all_variables.append(\"FN6\")\n",
    "list_of_all_variables.append(\"FN7\")\n",
    "list_of_all_variables.append(\"FN8\")\n",
    "list_of_all_variables.append(\"IN1\")\n",
    "list_of_all_variables.append(\"IN2\")\n",
    "list_of_all_variables.append(\"IN3\")\n",
    "list_of_all_variables.append(\"IN4\")\n",
    "list_of_all_variables.append(\"IN5\")\n",
    "list_of_all_variables.append(\"IN6\")\n",
    "list_of_all_variables.append(\"IN7\")\n",
    "list_of_all_variables.append(\"IN8\")\n",
    "list_of_all_variables.append(\"N1\")\n",
    "list_of_all_variables.append(\"N2\")\n",
    "list_of_all_variables.append(\"N3\")\n",
    "list_of_all_variables.append(\"N4\")\n",
    "list_of_all_variables.append(\"N5\")\n",
    "list_of_all_variables.append(\"N6\")\n",
    "list_of_all_variables.append(\"N7\")\n",
    "list_of_all_variables.append(\"N8\")\n",
    "list_of_all_variables.append(\"N9\")\n",
    "list_of_all_variables.append(\"V1\")\n",
    "list_of_all_variables.append(\"V2\")\n",
    "list_of_all_variables.append(\"V3\")\n",
    "list_of_all_variables.append(\"V4\")\n",
    "list_of_all_variables.append(\"V5\")\n",
    "list_of_all_variables.append(\"V6\")\n",
    "list_of_all_variables.append(\"V7\")\n",
    "list_of_all_variables.append(\"V8\")\n",
    "list_of_all_variables.append(\"V9\")\n",
    "\n",
    "for sentence in facts_list:\n",
    "    for word in sentence:\n",
    "        if word not in list_of_all_variables:\n",
    "            list_of_all_variables.append(word)\n",
    "    \n",
    "for sentence in info_list:\n",
    "    for word in sentence:\n",
    "        if word not in list_of_all_variables:\n",
    "            list_of_all_variables.append(word) \n",
    "\n",
    "for sentence in questions_list:\n",
    "    for word in sentence:\n",
    "        if word not in list_of_all_variables:\n",
    "            list_of_all_variables.append(word)\n",
    "\n",
    "for sentence in relations_list:\n",
    "    for word in sentence:\n",
    "        if word not in list_of_all_variables:\n",
    "            list_of_all_variables.append(word)      \n",
    "            \n",
    "list_of_all_variables.append(\"<PAD>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QN1', 'QN2', 'QN3', 'QN4', 'QN5', 'QN6', 'QN7', 'QN8', 'FN1', 'FN2', 'FN3', 'FN4', 'FN5', 'FN6', 'FN7', 'FN8', 'IN1', 'IN2', 'IN3', 'IN4', 'IN5', 'IN6', 'IN7', 'IN8', 'N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 'N9', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'NONE', 'MEANS', 'MORE', 'return', 'MAKES', 'ADD', ';', 'buy', 'SUBTRACT', 'changed', 'PAST-TENSE', 'change', 'ADD-OR-SUBTRACT', 'PLURAL', 'A1', 'opened', 'open', 'IN', 'HAVE', 'there', 'are', 'and', '.', 'in', 'the', ',', 'UNITS', 'of', 'at', 'with', 'next', 'to', 'on', 'other', 'side', 'from', 'has', 'already', 'one', 'were', 'a', 'comes', 'he', 'bought', 'last', 'week', 'yesterday', 'called', 'add', 'more', 'subtract', 'went', 'could', 'not', 'go', 'for', 'as', 'another', 'each', 'some', 'first', 'they', 'second', 'during', 'had', 'month', 'than', 'men', 'women', 'days', 'it', 'will', 'be', 'capacity', 'full', 'how', 'many', '?', 'when', 'did', 'total', 'was', 'an', 'have', 'been', 'two', 'KIND-OF', 'NOT', 'BEFORE', 'today', 'SUBSTRACT', '=', 'PLACE', 'PEOPLE', 'COUNT', '1', 'NUM-OF-TYPES', '3', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "\n",
    "word_index = 0\n",
    "\n",
    "for word in list_of_all_variables:\n",
    "    word_to_index[word] = word_index\n",
    "    index_to_word[word_index] = word\n",
    "    word_index += 1\n",
    "print(list_of_all_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_facts_list = []\n",
    "new_questions_list = []\n",
    "new_info_list = []\n",
    "new_relations_list = []\n",
    "\n",
    "pad_up_to = 100\n",
    "pad_index = word_to_index[\"<PAD>\"]\n",
    "\n",
    "for sentence in facts_list:\n",
    "    substitute_sentence = []\n",
    "    for word in sentence:\n",
    "        substitute_sentence.append(word_to_index[word])\n",
    "    for i in range(len(substitute_sentence),pad_up_to):\n",
    "        substitute_sentence.append(pad_index)\n",
    "    new_facts_list.append(substitute_sentence)\n",
    "\n",
    "for sentence in questions_list:\n",
    "    substitute_sentence = []\n",
    "    for word in sentence:\n",
    "        substitute_sentence.append(word_to_index[word])\n",
    "    for i in range(len(substitute_sentence),pad_up_to):\n",
    "        substitute_sentence.append(pad_index)\n",
    "    new_questions_list.append(substitute_sentence)\n",
    "        \n",
    "for sentence in info_list:\n",
    "    substitute_sentence = []\n",
    "    for word in sentence:\n",
    "        substitute_sentence.append(word_to_index[word])\n",
    "    for i in range(len(substitute_sentence),pad_up_to):\n",
    "        substitute_sentence.append(pad_index)\n",
    "    new_info_list.append(substitute_sentence)\n",
    "\n",
    "for sentence in relations_list:\n",
    "    substitute_sentence = []\n",
    "    for word in sentence:\n",
    "        substitute_sentence.append(word_to_index[word])\n",
    "    for i in range(len(substitute_sentence),pad_up_to):\n",
    "        substitute_sentence.append(pad_index)\n",
    "    new_relations_list.append(substitute_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(new_facts_list))\n",
    "print(len(new_questions_list))\n",
    "print(len(new_info_list))\n",
    "print(len(new_relations_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "one_hot_facts = []\n",
    "one_hot_questions = []\n",
    "one_hot_info = []\n",
    "one_hot_relations = []\n",
    "\n",
    "one_hot_length = len(word_to_index)\n",
    "\n",
    "for sentence in new_facts_list:\n",
    "    substitute_sentence = []\n",
    "    for word_ind in sentence:\n",
    "        substitute_word = []\n",
    "        for i in range(one_hot_length):\n",
    "            if i == word_ind:\n",
    "                substitute_word.append(1)\n",
    "            else:\n",
    "                substitute_word.append(0)\n",
    "        substitute_sentence.append(substitute_word)\n",
    "    one_hot_facts.append(substitute_sentence)\n",
    "\n",
    "for sentence in new_questions_list:\n",
    "    substitute_sentence = []\n",
    "    for word_ind in sentence:\n",
    "        substitute_word = []\n",
    "        for i in range(one_hot_length):\n",
    "            if i == word_ind:\n",
    "                substitute_word.append(1)\n",
    "            else:\n",
    "                substitute_word.append(0)\n",
    "        substitute_sentence.append(substitute_word)\n",
    "    one_hot_questions.append(substitute_sentence)\n",
    "\n",
    "for sentence in new_info_list:\n",
    "    substitute_sentence = []\n",
    "    for word_ind in sentence:\n",
    "        substitute_word = []\n",
    "        for i in range(one_hot_length):\n",
    "            if i == word_ind:\n",
    "                substitute_word.append(1)\n",
    "            else:\n",
    "                substitute_word.append(0)\n",
    "        substitute_sentence.append(substitute_word)\n",
    "    one_hot_info.append(substitute_sentence)\n",
    "    \n",
    "for sentence in new_relations_list:\n",
    "    substitute_sentence = []\n",
    "    for word_ind in sentence:\n",
    "        substitute_word = []\n",
    "        for i in range(one_hot_length):\n",
    "            if i == word_ind:\n",
    "                substitute_word.append(1)\n",
    "            else:\n",
    "                substitute_word.append(0)\n",
    "        substitute_sentence.append(substitute_word)\n",
    "    one_hot_relations.append(substitute_sentence)\n",
    "    \n",
    "vectorized_fact_list = np.asarray(one_hot_facts)\n",
    "vectorized_questions = np.asarray(one_hot_questions) \n",
    "vectorized_info = np.asarray(one_hot_info)\n",
    "vectorized_relations = np.asarray(one_hot_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 100, 141)\n",
      "(80, 100, 141)\n",
      "(80, 100, 141)\n",
      "(80, 100, 141)\n"
     ]
    }
   ],
   "source": [
    "print(vectorized_fact_list.shape)\n",
    "print(vectorized_questions.shape)\n",
    "print(vectorized_info.shape)\n",
    "print(vectorized_relations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "label_words_to_index = {}\n",
    "label_index_to_words = {}\n",
    "label_index = 0\n",
    "label_words_to_index[\"\\t\"]=label_index\n",
    "label_index_to_words[label_index]=\"\\t\"\n",
    "label_index += 1\n",
    "label_words_to_index[\"<PAD>\"]=label_index\n",
    "label_index_to_words[label_index]=\"<PAD>\"\n",
    "new_label_list = []\n",
    "decoder_input_list = [] #in this version, we will use teacher enforcing, so we need a shifted target data\n",
    "label_pad_up_to = 10\n",
    "for sentence in labels_list:\n",
    "    substitute_sentence = []\n",
    "    decoder_subs_sentence = [] \n",
    "    decoder_subs_sentence.append(label_words_to_index[\"\\t\"]) #decoder input data starts with a \\t character\n",
    "    sent = sentence.split()\n",
    "    for char in sent: #char could be a word or group of characters\n",
    "        if char in label_words_to_index.keys():\n",
    "            substitute_sentence.append(label_words_to_index[char])\n",
    "            decoder_subs_sentence.append(label_words_to_index[char])\n",
    "        else:\n",
    "            label_index += 1\n",
    "            label_words_to_index[char]=label_index\n",
    "            label_index_to_words[label_index]=char\n",
    "            substitute_sentence.append(label_words_to_index[char])\n",
    "            decoder_subs_sentence.append(label_words_to_index[char])\n",
    "    for i in range(len(substitute_sentence),label_pad_up_to): #pad to regular\n",
    "        substitute_sentence.append(label_words_to_index[\"<PAD>\"])\n",
    "    for i in range(len(decoder_subs_sentence),label_pad_up_to): #pad to regular\n",
    "        decoder_subs_sentence.append(label_words_to_index[\"<PAD>\"])\n",
    "        \n",
    "    new_label_list.append(substitute_sentence)\n",
    "    decoder_input_list.append(decoder_subs_sentence)\n",
    "    \n",
    "#vectorize labels\n",
    "vectorized_label_list = []\n",
    "for sentence in new_label_list:\n",
    "    sentence_vector = []\n",
    "    for word in sentence:\n",
    "        vector = [0]*len(label_words_to_index)\n",
    "        vector[word] = 1\n",
    "        sentence_vector.append(vector)\n",
    "    vectorized_label_list.append(sentence_vector)\n",
    "\n",
    "label_array = np.asarray(vectorized_label_list)\n",
    "\n",
    "#vectorize decoder inputs\n",
    "vectorized_decoder_list = []\n",
    "for sentence in decoder_input_list:\n",
    "    sentence_vector = []\n",
    "    for word in sentence:\n",
    "        vector = [0]*len(label_words_to_index)\n",
    "        vector[word] = 1\n",
    "        sentence_vector.append(vector)\n",
    "    vectorized_decoder_list.append(sentence_vector)\n",
    "    \n",
    "decoder_input_data = np.asarray(vectorized_decoder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 10, 12)\n",
      "(80, 10, 12)\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(label_array.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(len(label_words_to_index))\n",
    "print(len(label_index_to_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, dictionary):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"    \n",
    "    return ' '.join([label_index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cascaded_reasoning(info_shape, questions_shape, facts_shape \\\n",
    "                       , relations_shape, labels_index_len):\n",
    "    \"\"\"\n",
    "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement\n",
    "    learning_rate = 0.01\n",
    "    hidden_units = 128\n",
    "    latent_dim = 128 \n",
    "    # TODO: Build the layers\n",
    "    \n",
    "    LSTM_info_inputs = Input(shape=(None, info_shape[2]))\n",
    "    LSTM_info = LSTM(hidden_units,return_state=True)\n",
    "    LSTM_info_output, info_h, info_c=LSTM_info(LSTM_info_inputs)\n",
    "    info_states = [info_h,info_c]\n",
    "    \n",
    "    LSTM_questions_inputs = Input(shape=(None, questions_shape[2]))\n",
    "    LSTM_questions = LSTM(hidden_units,return_state=True)\n",
    "    LSTM_questions_output, questions_h, questions_c=LSTM_questions(LSTM_questions_inputs)\n",
    "    questions_states= [questions_h,questions_c]\n",
    "    \n",
    "    LSTM_facts_inputs = Input(shape=(None, facts_shape[2]))\n",
    "    LSTM_facts = LSTM(hidden_units,return_state=True)\n",
    "    LSTM_facts_output, facts_h, facts_c=LSTM_facts(LSTM_facts_inputs)\n",
    "    facts_states= [facts_h,facts_c]\n",
    "    \n",
    "    LSTM_rela_inputs = Input(shape=(None, relations_shape[2]))\n",
    "    LSTM_rela = LSTM(hidden_units,return_state=True)\n",
    "    LSTM_rela_output,rela_h,rela_c=LSTM_rela(LSTM_rela_inputs)\n",
    "    rela_states= [rela_h,rela_c]\n",
    "    \n",
    "    added_h = keras.layers.Add()([info_h,questions_h,facts_h,rela_h])\n",
    "    added_c = keras.layers.Add()([info_c,questions_c,facts_c,rela_c])\n",
    "    encoder_states = [added_h,added_c]\n",
    "    \n",
    "   # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None, labels_index_len))\n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "    decoder_dense = Dense(labels_index_len, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define and compile model as previously\n",
    "    model_T = Model([LSTM_info_inputs, LSTM_questions_inputs, LSTM_facts_inputs, \\\n",
    "                     LSTM_rela_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    model_T.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model_T\n",
    "\n",
    "#Example inputs: X1 = \"There are four apples at the top of the tree.\" X2 = \"What do you need to get the apples?\"\n",
    "# X3 = \"Trees are high.\"  Label result = \"Trees -> High\"\n",
    "#Example inputs: X1 = \"There are four apples at the top of the tree.\" X2 = \"What do you need to get the apples?\"\n",
    "# X3 = \"Pick apples from tree.\"  Label result = \"Apples -> On tree\"\n",
    "#Example inputs: X1 = \"Apples->On tree, Tree->High\" X2 = \"What do you need to get the apples?\"\n",
    "# X3 = \"You can go on tree with a ladder.\"  Label result = \"Ladder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "cascaded_reasoning loaded\n",
      "Train on 72 samples, validate on 8 samples\n",
      "Epoch 1/250\n",
      "72/72 [==============================] - 14s 200ms/step - loss: 2.3949 - acc: 0.3417 - val_loss: 1.7294 - val_acc: 0.8250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4849 - acc: 0.7111 - val_loss: 0.6342 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.8787 - acc: 0.7889 - val_loss: 0.5888 - val_acc: 0.8250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/250\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.8949 - acc: 0.7417 - val_loss: 0.6127 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.7784 - acc: 0.7889 - val_loss: 0.6591 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/250\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.7714 - acc: 0.7889 - val_loss: 0.6016 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/250\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.7469 - acc: 0.7875 - val_loss: 0.6038 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.7262 - acc: 0.7972 - val_loss: 0.4954 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.7217 - acc: 0.7889 - val_loss: 0.5828 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.7082 - acc: 0.7972 - val_loss: 0.4877 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.7558 - acc: 0.7694 - val_loss: 0.4787 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/250\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.7408 - acc: 0.7833 - val_loss: 0.5113 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.6952 - acc: 0.7972 - val_loss: 0.5077 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/250\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.6874 - acc: 0.7972 - val_loss: 0.5149 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.6756 - acc: 0.7972 - val_loss: 0.5414 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.6868 - acc: 0.7972 - val_loss: 0.4536 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.6807 - acc: 0.7847 - val_loss: 0.5179 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/250\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.6571 - acc: 0.7972 - val_loss: 0.4764 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/250\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.6817 - acc: 0.7972 - val_loss: 0.4472 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.6687 - acc: 0.7819 - val_loss: 0.5095 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.6412 - acc: 0.7972 - val_loss: 0.5228 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/250\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.6378 - acc: 0.7972 - val_loss: 0.5375 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.6264 - acc: 0.7972 - val_loss: 0.4556 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/250\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.6360 - acc: 0.7972 - val_loss: 0.4556 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/250\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 0.6188 - acc: 0.8000 - val_loss: 0.5304 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/250\n",
      "72/72 [==============================] - 5s 75ms/step - loss: 0.6379 - acc: 0.8000 - val_loss: 0.5848 - val_acc: 0.8250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/250\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 0.6332 - acc: 0.8264 - val_loss: 0.4948 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/250\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.6031 - acc: 0.7972 - val_loss: 0.5006 - val_acc: 0.8250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/250\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.6007 - acc: 0.8125 - val_loss: 0.5030 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.5864 - acc: 0.8181 - val_loss: 0.4398 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 31/250\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.5849 - acc: 0.8014 - val_loss: 0.5989 - val_acc: 0.7625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 32/250\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.6086 - acc: 0.8042 - val_loss: 0.4699 - val_acc: 0.8250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 33/250\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.5740 - acc: 0.8111 - val_loss: 0.4936 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 34/250\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.5664 - acc: 0.8167 - val_loss: 0.4432 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 35/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.5767 - acc: 0.8389 - val_loss: 0.3957 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 36/250\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.6428 - acc: 0.7792 - val_loss: 0.3931 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 37/250\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.5628 - acc: 0.8208 - val_loss: 0.4505 - val_acc: 0.8250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 38/250\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.5466 - acc: 0.8333 - val_loss: 0.4307 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 39/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.5377 - acc: 0.8347 - val_loss: 0.4422 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 40/250\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.5317 - acc: 0.8347 - val_loss: 0.4388 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 41/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.5250 - acc: 0.8389 - val_loss: 0.3880 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 42/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.5290 - acc: 0.8361 - val_loss: 0.3832 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 43/250\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.5293 - acc: 0.8111 - val_loss: 0.3820 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 44/250\n",
      "72/72 [==============================] - 5s 75ms/step - loss: 0.5319 - acc: 0.8111 - val_loss: 0.3827 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 45/250\n",
      "72/72 [==============================] - 5s 76ms/step - loss: 0.5144 - acc: 0.8264 - val_loss: 0.4376 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 46/250\n",
      "72/72 [==============================] - 5s 75ms/step - loss: 0.5088 - acc: 0.8403 - val_loss: 0.4622 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 47/250\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 0.5067 - acc: 0.8319 - val_loss: 0.4009 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 48/250\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.4948 - acc: 0.8375 - val_loss: 0.4312 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 49/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.5355 - acc: 0.8125 - val_loss: 0.5273 - val_acc: 0.7750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 50/250\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.5242 - acc: 0.8319 - val_loss: 0.3815 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 51/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.4828 - acc: 0.8431 - val_loss: 0.4374 - val_acc: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 52/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.4778 - acc: 0.8361 - val_loss: 0.3737 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 53/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.4728 - acc: 0.8444 - val_loss: 0.4160 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 54/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.4900 - acc: 0.8431 - val_loss: 0.4490 - val_acc: 0.8250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 55/250\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.5218 - acc: 0.8306 - val_loss: 0.4534 - val_acc: 0.7875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 56/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.4737 - acc: 0.8292 - val_loss: 0.3679 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 57/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.4651 - acc: 0.8417 - val_loss: 0.3484 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 58/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.4669 - acc: 0.8375 - val_loss: 0.3395 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 59/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.4614 - acc: 0.8403 - val_loss: 0.3467 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 60/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.4958 - acc: 0.8361 - val_loss: 0.3349 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 61/250\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.4763 - acc: 0.8319 - val_loss: 0.3428 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 62/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.4462 - acc: 0.8458 - val_loss: 0.3445 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 63/250\n",
      "72/72 [==============================] - 5s 72ms/step - loss: 0.4360 - acc: 0.8458 - val_loss: 0.3702 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 64/250\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.4313 - acc: 0.8431 - val_loss: 0.3361 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 65/250\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 0.4383 - acc: 0.8486 - val_loss: 0.3301 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 66/250\n",
      "72/72 [==============================] - 6s 76ms/step - loss: 0.4295 - acc: 0.8472 - val_loss: 0.3646 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 67/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.4279 - acc: 0.8556 - val_loss: 0.3191 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 68/250\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.4404 - acc: 0.8431 - val_loss: 0.3323 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 69/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.4544 - acc: 0.8500 - val_loss: 0.3176 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 70/250\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.4553 - acc: 0.8458 - val_loss: 0.3270 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 71/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.4202 - acc: 0.8458 - val_loss: 0.3294 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 72/250\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.4102 - acc: 0.8514 - val_loss: 0.3393 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 73/250\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.4136 - acc: 0.8556 - val_loss: 0.3056 - val_acc: 0.8875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 74/250\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.4201 - acc: 0.8542 - val_loss: 0.3193 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 75/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.4299 - acc: 0.8361 - val_loss: 0.3088 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 76/250\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.4236 - acc: 0.8458 - val_loss: 0.3218 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 77/250\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.4010 - acc: 0.8472 - val_loss: 0.3284 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 78/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.3971 - acc: 0.8569 - val_loss: 0.3332 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 79/250\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.4027 - acc: 0.8556 - val_loss: 0.3403 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 80/250\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.4179 - acc: 0.8514 - val_loss: 0.4109 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 81/250\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.4248 - acc: 0.8528 - val_loss: 0.3059 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 82/250\n",
      "72/72 [==============================] - 5s 72ms/step - loss: 0.3936 - acc: 0.8611 - val_loss: 0.3082 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 83/250\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.3965 - acc: 0.8583 - val_loss: 0.2951 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 84/250\n",
      "72/72 [==============================] - 6s 78ms/step - loss: 0.3939 - acc: 0.8625 - val_loss: 0.2970 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 85/250\n",
      "72/72 [==============================] - 6s 78ms/step - loss: 0.3825 - acc: 0.8556 - val_loss: 0.3220 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 86/250\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.3801 - acc: 0.8597 - val_loss: 0.3054 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 87/250\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.3817 - acc: 0.8611 - val_loss: 0.2936 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 88/250\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.4027 - acc: 0.8500 - val_loss: 0.2990 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 89/250\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.3880 - acc: 0.8528 - val_loss: 0.2986 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 90/250\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.3750 - acc: 0.8653 - val_loss: 0.3085 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 91/250\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.3755 - acc: 0.8639 - val_loss: 0.2924 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 92/250\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.3847 - acc: 0.8569 - val_loss: 0.2940 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 93/250\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.3732 - acc: 0.8597 - val_loss: 0.3571 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 94/250\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.4016 - acc: 0.8556 - val_loss: 0.3070 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 95/250\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.3719 - acc: 0.8653 - val_loss: 0.2969 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 96/250\n",
      "72/72 [==============================] - 5s 72ms/step - loss: 0.3642 - acc: 0.8667 - val_loss: 0.2976 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 97/250\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 0.3825 - acc: 0.8583 - val_loss: 0.3633 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 98/250\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.3845 - acc: 0.8625 - val_loss: 0.2954 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 99/250\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.3596 - acc: 0.8681 - val_loss: 0.3038 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 100/250\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.3617 - acc: 0.8681 - val_loss: 0.3226 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 101/250\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.3593 - acc: 0.8667 - val_loss: 0.2822 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 102/250\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.3605 - acc: 0.8653 - val_loss: 0.2764 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 103/250\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.4037 - acc: 0.8458 - val_loss: 0.2833 - val_acc: 0.8875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 104/250\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.3625 - acc: 0.8708 - val_loss: 0.3073 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 105/250\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.3629 - acc: 0.8681 - val_loss: 0.3338 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 106/250\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.3643 - acc: 0.8722 - val_loss: 0.3013 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 107/250\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.3567 - acc: 0.8681 - val_loss: 0.3293 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 108/250\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.3645 - acc: 0.8611 - val_loss: 0.3092 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 109/250\n",
      "72/72 [==============================] - 6s 78ms/step - loss: 0.3543 - acc: 0.8708 - val_loss: 0.2879 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 110/250\n",
      "72/72 [==============================] - 6s 87ms/step - loss: 0.3468 - acc: 0.8694 - val_loss: 0.3011 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 111/250\n",
      "72/72 [==============================] - 6s 88ms/step - loss: 0.3511 - acc: 0.8694 - val_loss: 0.2924 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 112/250\n",
      "72/72 [==============================] - 7s 91ms/step - loss: 0.3514 - acc: 0.8694 - val_loss: 0.3251 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 113/250\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.3530 - acc: 0.8722 - val_loss: 0.2708 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 114/250\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.3426 - acc: 0.8694 - val_loss: 0.3153 - val_acc: 0.8500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 115/250\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.3583 - acc: 0.8653 - val_loss: 0.3177 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 116/250\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.3591 - acc: 0.8708 - val_loss: 0.2948 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 117/250\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.3443 - acc: 0.8708 - val_loss: 0.3088 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 118/250\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.3434 - acc: 0.8708 - val_loss: 0.2959 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 119/250\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.3437 - acc: 0.8722 - val_loss: 0.2778 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 120/250\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 0.3510 - acc: 0.8597 - val_loss: 0.2612 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 121/250\n",
      "72/72 [==============================] - 6s 85ms/step - loss: 0.3639 - acc: 0.8597 - val_loss: 0.2699 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 122/250\n",
      "72/72 [==============================] - 7s 93ms/step - loss: 0.3354 - acc: 0.8681 - val_loss: 0.2843 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 123/250\n",
      "72/72 [==============================] - 7s 93ms/step - loss: 0.3336 - acc: 0.8708 - val_loss: 0.2732 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 124/250\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 0.3403 - acc: 0.8653 - val_loss: 0.2656 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 125/250\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.3382 - acc: 0.8667 - val_loss: 0.2707 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 126/250\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.3308 - acc: 0.8708 - val_loss: 0.3014 - val_acc: 0.8875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 127/250\n",
      "72/72 [==============================] - 5s 72ms/step - loss: 0.3372 - acc: 0.8722 - val_loss: 0.2652 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 128/250\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 0.3293 - acc: 0.8764 - val_loss: 0.2956 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 129/250\n",
      "72/72 [==============================] - 7s 93ms/step - loss: 0.3351 - acc: 0.8708 - val_loss: 0.2987 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 130/250\n",
      "72/72 [==============================] - 7s 92ms/step - loss: 0.3346 - acc: 0.8681 - val_loss: 0.2999 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 131/250\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.3312 - acc: 0.8722 - val_loss: 0.2903 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 132/250\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.3257 - acc: 0.8708 - val_loss: 0.2840 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 133/250\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.3355 - acc: 0.8681 - val_loss: 0.2680 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 134/250\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.3301 - acc: 0.8736 - val_loss: 0.2983 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 135/250\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.3327 - acc: 0.8708 - val_loss: 0.3087 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 136/250\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.3220 - acc: 0.8778 - val_loss: 0.2688 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 137/250\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.3286 - acc: 0.8653 - val_loss: 0.2624 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 138/250\n",
      "72/72 [==============================] - 5s 72ms/step - loss: 0.3309 - acc: 0.8681 - val_loss: 0.2714 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 139/250\n",
      "72/72 [==============================] - 5s 72ms/step - loss: 0.3194 - acc: 0.8736 - val_loss: 0.2796 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 140/250\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.3259 - acc: 0.8681 - val_loss: 0.3076 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 141/250\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.3245 - acc: 0.8806 - val_loss: 0.2689 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 142/250\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.3202 - acc: 0.8625 - val_loss: 0.3002 - val_acc: 0.8875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 143/250\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.3173 - acc: 0.8750 - val_loss: 0.2800 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 144/250\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.3147 - acc: 0.8750 - val_loss: 0.2890 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 145/250\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.3373 - acc: 0.8722 - val_loss: 0.3323 - val_acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 146/250\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.3465 - acc: 0.8667 - val_loss: 0.2767 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 147/250\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 0.3152 - acc: 0.8736 - val_loss: 0.2706 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 148/250\n",
      "72/72 [==============================] - 7s 97ms/step - loss: 0.3164 - acc: 0.8722 - val_loss: 0.2718 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 149/250\n",
      "72/72 [==============================] - 7s 93ms/step - loss: 0.3186 - acc: 0.8750 - val_loss: 0.2890 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 150/250\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.3195 - acc: 0.8708 - val_loss: 0.2760 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 151/250\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 0.3100 - acc: 0.8750 - val_loss: 0.2645 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 152/250\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 0.3163 - acc: 0.8736 - val_loss: 0.2549 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 153/250\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 0.3164 - acc: 0.8694 - val_loss: 0.2579 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 154/250\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 0.3126 - acc: 0.8722 - val_loss: 0.2778 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 155/250\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.3126 - acc: 0.8750 - val_loss: 0.2805 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 156/250\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.3142 - acc: 0.8764 - val_loss: 0.2632 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 157/250\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.3177 - acc: 0.8694 - val_loss: 0.2767 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 158/250\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 0.3083 - acc: 0.8750 - val_loss: 0.2763 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 159/250\n",
      "72/72 [==============================] - 5s 75ms/step - loss: 0.3190 - acc: 0.8625 - val_loss: 0.3093 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 160/250\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.3219 - acc: 0.8750 - val_loss: 0.2792 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 161/250\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 0.3147 - acc: 0.8750 - val_loss: 0.2946 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 162/250\n",
      "72/72 [==============================] - 7s 95ms/step - loss: 0.3064 - acc: 0.8764 - val_loss: 0.2608 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 163/250\n",
      "72/72 [==============================] - 7s 99ms/step - loss: 0.3074 - acc: 0.8653 - val_loss: 0.3011 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 164/250\n",
      "72/72 [==============================] - 6s 89ms/step - loss: 0.3112 - acc: 0.8722 - val_loss: 0.2682 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 165/250\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 0.3073 - acc: 0.8722 - val_loss: 0.3001 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 166/250\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 0.3043 - acc: 0.8764 - val_loss: 0.2559 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 167/250\n",
      "72/72 [==============================] - 5s 76ms/step - loss: 0.3148 - acc: 0.8667 - val_loss: 0.2533 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 168/250\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 0.3151 - acc: 0.8722 - val_loss: 0.2747 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 169/250\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 0.3100 - acc: 0.8778 - val_loss: 0.2649 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 170/250\n",
      "72/72 [==============================] - 5s 76ms/step - loss: 0.3075 - acc: 0.8764 - val_loss: 0.2926 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 171/250\n",
      "72/72 [==============================] - 6s 78ms/step - loss: 0.3070 - acc: 0.8736 - val_loss: 0.2694 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 172/250\n",
      "72/72 [==============================] - 5s 76ms/step - loss: 0.3015 - acc: 0.8778 - val_loss: 0.2894 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 173/250\n",
      "72/72 [==============================] - 7s 99ms/step - loss: 0.3051 - acc: 0.8764 - val_loss: 0.2733 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 174/250\n",
      "72/72 [==============================] - 7s 101ms/step - loss: 0.3015 - acc: 0.8778 - val_loss: 0.2767 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 175/250\n",
      "72/72 [==============================] - 6s 77ms/step - loss: 0.2986 - acc: 0.8778 - val_loss: 0.2838 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 176/250\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.3084 - acc: 0.8667 - val_loss: 0.2910 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 177/250\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.3137 - acc: 0.8778 - val_loss: 0.2710 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 178/250\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.2988 - acc: 0.8792 - val_loss: 0.2564 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 179/250\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.3004 - acc: 0.8736 - val_loss: 0.2918 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 180/250\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.3008 - acc: 0.8736 - val_loss: 0.2781 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 181/250\n",
      "72/72 [==============================] - 6s 79ms/step - loss: 0.2992 - acc: 0.8778 - val_loss: 0.2729 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 182/250\n",
      "72/72 [==============================] - 8s 106ms/step - loss: 0.2985 - acc: 0.8778 - val_loss: 0.2592 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 183/250\n",
      "72/72 [==============================] - 7s 104ms/step - loss: 0.3005 - acc: 0.8764 - val_loss: 0.2530 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 184/250\n",
      "72/72 [==============================] - 5s 72ms/step - loss: 0.2996 - acc: 0.8750 - val_loss: 0.2673 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 185/250\n",
      "72/72 [==============================] - 5s 76ms/step - loss: 0.3030 - acc: 0.8708 - val_loss: 0.2599 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 186/250\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.2996 - acc: 0.8764 - val_loss: 0.2592 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 187/250\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.2937 - acc: 0.8778 - val_loss: 0.2779 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 188/250\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.2958 - acc: 0.8778 - val_loss: 0.2743 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 189/250\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.2951 - acc: 0.8792 - val_loss: 0.2781 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 190/250\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.3028 - acc: 0.8722 - val_loss: 0.3024 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 191/250\n",
      "72/72 [==============================] - 7s 99ms/step - loss: 0.3136 - acc: 0.8639 - val_loss: 0.2990 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 192/250\n",
      "72/72 [==============================] - 8s 108ms/step - loss: 0.3075 - acc: 0.8722 - val_loss: 0.2819 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 193/250\n",
      "72/72 [==============================] - 8s 106ms/step - loss: 0.2984 - acc: 0.8806 - val_loss: 0.2836 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 194/250\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.2969 - acc: 0.8764 - val_loss: 0.2651 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 195/250\n",
      "72/72 [==============================] - 6s 85ms/step - loss: 0.2966 - acc: 0.8750 - val_loss: 0.2678 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 196/250\n",
      "72/72 [==============================] - 6s 84ms/step - loss: 0.2994 - acc: 0.8778 - val_loss: 0.2768 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 197/250\n",
      "72/72 [==============================] - 6s 77ms/step - loss: 0.3044 - acc: 0.8792 - val_loss: 0.2897 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 198/250\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.2946 - acc: 0.8792 - val_loss: 0.2717 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 199/250\n",
      "72/72 [==============================] - 6s 87ms/step - loss: 0.2969 - acc: 0.8736 - val_loss: 0.2534 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 200/250\n",
      "72/72 [==============================] - 6s 81ms/step - loss: 0.2956 - acc: 0.8736 - val_loss: 0.2657 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 201/250\n",
      "72/72 [==============================] - 6s 82ms/step - loss: 0.3032 - acc: 0.8736 - val_loss: 0.2713 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 202/250\n",
      "72/72 [==============================] - 6s 90ms/step - loss: 0.2925 - acc: 0.8750 - val_loss: 0.2630 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 203/250\n",
      "72/72 [==============================] - 8s 117ms/step - loss: 0.2918 - acc: 0.8792 - val_loss: 0.2724 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 204/250\n",
      "72/72 [==============================] - 8s 115ms/step - loss: 0.2901 - acc: 0.8806 - val_loss: 0.2720 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 205/250\n",
      "72/72 [==============================] - 6s 86ms/step - loss: 0.2905 - acc: 0.8806 - val_loss: 0.2917 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 206/250\n",
      "72/72 [==============================] - 6s 90ms/step - loss: 0.2957 - acc: 0.8736 - val_loss: 0.2777 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 207/250\n",
      "72/72 [==============================] - 6s 90ms/step - loss: 0.2950 - acc: 0.8750 - val_loss: 0.2853 - val_acc: 0.8875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 208/250\n",
      "72/72 [==============================] - 6s 80ms/step - loss: 0.3024 - acc: 0.8764 - val_loss: 0.2752 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 209/250\n",
      "72/72 [==============================] - 6s 83ms/step - loss: 0.3064 - acc: 0.8764 - val_loss: 0.2714 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 210/250\n",
      "72/72 [==============================] - 6s 83ms/step - loss: 0.2936 - acc: 0.8736 - val_loss: 0.2838 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 211/250\n",
      "72/72 [==============================] - 6s 88ms/step - loss: 0.2894 - acc: 0.8792 - val_loss: 0.2607 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 212/250\n",
      "72/72 [==============================] - 7s 93ms/step - loss: 0.2885 - acc: 0.8778 - val_loss: 0.2708 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 213/250\n",
      "72/72 [==============================] - 8s 113ms/step - loss: 0.3059 - acc: 0.8764 - val_loss: 0.2839 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 214/250\n",
      "72/72 [==============================] - 8s 113ms/step - loss: 0.2953 - acc: 0.8736 - val_loss: 0.2627 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 215/250\n",
      "72/72 [==============================] - 6s 87ms/step - loss: 0.2903 - acc: 0.8792 - val_loss: 0.2504 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 216/250\n",
      "72/72 [==============================] - 6s 84ms/step - loss: 0.2924 - acc: 0.8792 - val_loss: 0.2645 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 217/250\n",
      "72/72 [==============================] - 6s 87ms/step - loss: 0.2887 - acc: 0.8861 - val_loss: 0.2669 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 218/250\n",
      "72/72 [==============================] - 6s 87ms/step - loss: 0.2876 - acc: 0.8806 - val_loss: 0.2923 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 219/250\n",
      "72/72 [==============================] - 6s 88ms/step - loss: 0.2893 - acc: 0.8806 - val_loss: 0.2662 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 220/250\n",
      "72/72 [==============================] - 6s 84ms/step - loss: 0.2918 - acc: 0.8750 - val_loss: 0.2934 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 221/250\n",
      "72/72 [==============================] - 6s 84ms/step - loss: 0.2856 - acc: 0.8861 - val_loss: 0.2578 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 222/250\n",
      "72/72 [==============================] - 7s 95ms/step - loss: 0.2981 - acc: 0.8708 - val_loss: 0.2575 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 223/250\n",
      "72/72 [==============================] - 9s 119ms/step - loss: 0.2890 - acc: 0.8806 - val_loss: 0.2609 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 224/250\n",
      "72/72 [==============================] - 8s 118ms/step - loss: 0.2879 - acc: 0.8792 - val_loss: 0.2638 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 225/250\n",
      "72/72 [==============================] - 6s 86ms/step - loss: 0.2861 - acc: 0.8847 - val_loss: 0.2761 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 226/250\n",
      "72/72 [==============================] - 6s 85ms/step - loss: 0.2884 - acc: 0.8764 - val_loss: 0.2729 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 227/250\n",
      "72/72 [==============================] - 6s 85ms/step - loss: 0.2858 - acc: 0.8833 - val_loss: 0.2639 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 228/250\n",
      "72/72 [==============================] - 6s 86ms/step - loss: 0.2842 - acc: 0.8833 - val_loss: 0.2689 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 229/250\n",
      "72/72 [==============================] - 6s 89ms/step - loss: 0.2877 - acc: 0.8778 - val_loss: 0.2722 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 230/250\n",
      "72/72 [==============================] - 8s 117ms/step - loss: 0.2911 - acc: 0.8764 - val_loss: 0.2580 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 231/250\n",
      "72/72 [==============================] - 8s 113ms/step - loss: 0.2893 - acc: 0.8792 - val_loss: 0.2674 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 232/250\n",
      "72/72 [==============================] - 6s 85ms/step - loss: 0.2946 - acc: 0.8806 - val_loss: 0.2852 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 233/250\n",
      "72/72 [==============================] - 6s 84ms/step - loss: 0.2928 - acc: 0.8792 - val_loss: 0.2720 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 234/250\n",
      "72/72 [==============================] - 6s 84ms/step - loss: 0.2861 - acc: 0.8792 - val_loss: 0.2763 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 235/250\n",
      "72/72 [==============================] - 6s 90ms/step - loss: 0.2837 - acc: 0.8819 - val_loss: 0.2601 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 236/250\n",
      "72/72 [==============================] - 6s 85ms/step - loss: 0.2870 - acc: 0.8778 - val_loss: 0.2890 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 237/250\n",
      "72/72 [==============================] - 6s 84ms/step - loss: 0.2921 - acc: 0.8722 - val_loss: 0.2851 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 238/250\n",
      "72/72 [==============================] - 7s 97ms/step - loss: 0.2864 - acc: 0.8778 - val_loss: 0.2703 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 239/250\n",
      "72/72 [==============================] - 8s 113ms/step - loss: 0.2857 - acc: 0.8778 - val_loss: 0.2810 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 240/250\n",
      "72/72 [==============================] - 8s 105ms/step - loss: 0.2896 - acc: 0.8792 - val_loss: 0.2828 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 241/250\n",
      "72/72 [==============================] - 6s 83ms/step - loss: 0.2830 - acc: 0.8806 - val_loss: 0.2735 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 242/250\n",
      "72/72 [==============================] - 6s 86ms/step - loss: 0.2842 - acc: 0.8833 - val_loss: 0.2611 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 243/250\n",
      "72/72 [==============================] - 6s 85ms/step - loss: 0.2903 - acc: 0.8722 - val_loss: 0.2496 - val_acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 244/250\n",
      "72/72 [==============================] - 6s 86ms/step - loss: 0.2954 - acc: 0.8722 - val_loss: 0.2538 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 245/250\n",
      "72/72 [==============================] - 6s 87ms/step - loss: 0.2901 - acc: 0.8778 - val_loss: 0.2583 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 246/250\n",
      "72/72 [==============================] - 7s 93ms/step - loss: 0.2886 - acc: 0.8833 - val_loss: 0.2817 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 247/250\n",
      "72/72 [==============================] - 8s 116ms/step - loss: 0.2862 - acc: 0.8722 - val_loss: 0.2738 - val_acc: 0.8625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 248/250\n",
      "72/72 [==============================] - 8s 118ms/step - loss: 0.2822 - acc: 0.8806 - val_loss: 0.2741 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 249/250\n",
      "72/72 [==============================] - 7s 91ms/step - loss: 0.2803 - acc: 0.8833 - val_loss: 0.2590 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 250/250\n",
      "72/72 [==============================] - 6s 86ms/step - loss: 0.2811 - acc: 0.8819 - val_loss: 0.2726 - val_acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "model fit\n"
     ]
    }
   ],
   "source": [
    "#tests.test_model_final(model_final)\n",
    "batch_size = 40\n",
    "\n",
    "print(len(label_index_to_words))\n",
    "\n",
    "cascaded_reasoning= cascaded_reasoning(vectorized_info.shape, vectorized_questions.shape, \\\n",
    "                       vectorized_fact_list.shape, vectorized_relations.shape, len(label_index_to_words))\n",
    "\n",
    "print('cascaded_reasoning loaded')\n",
    "\n",
    "cascaded_reasoning.fit([vectorized_info, vectorized_questions, \\\n",
    "                        vectorized_fact_list, vectorized_relations, decoder_input_data], \\\n",
    "                       label_array, batch_size=batch_size, epochs=250, validation_split=0.1)\n",
    "\n",
    "print(\"model fit\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hidden_units = 128\n",
    "latent_dim = 128 \n",
    "labels_index_len = len(label_index_to_words)\n",
    "    \n",
    "LSTM_info_inputs = Input(shape=(None, vectorized_info.shape[2]))\n",
    "LSTM_info = LSTM(hidden_units,return_state=True)\n",
    "LSTM_info_output, info_h, info_c=LSTM_info(LSTM_info_inputs)\n",
    "info_states = [info_h,info_c]\n",
    "    \n",
    "LSTM_questions_inputs = Input(shape=(None, vectorized_questions.shape[2]))\n",
    "LSTM_questions = LSTM(hidden_units,return_state=True)\n",
    "LSTM_questions_output, questions_h, questions_c=LSTM_questions(LSTM_questions_inputs)\n",
    "questions_states= [questions_h,questions_c]\n",
    "    \n",
    "LSTM_facts_inputs = Input(shape=(None, vectorized_fact_list.shape[2]))\n",
    "LSTM_facts = LSTM(hidden_units,return_state=True)\n",
    "LSTM_facts_output, facts_h, facts_c=LSTM_facts(LSTM_facts_inputs)\n",
    "facts_states= [facts_h,facts_c]\n",
    "    \n",
    "LSTM_rela_inputs = Input(shape=(None, vectorized_relations.shape[2]))\n",
    "LSTM_rela = LSTM(hidden_units,return_state=True)\n",
    "LSTM_rela_output,rela_h,rela_c=LSTM_rela(LSTM_rela_inputs)\n",
    "rela_states= [rela_h,rela_c]\n",
    "    \n",
    "added_h = keras.layers.Add()([info_h,questions_h,facts_h,rela_h])\n",
    "added_c = keras.layers.Add()([info_c,questions_c,facts_c,rela_c])\n",
    "states = [added_h,added_c]\n",
    "\n",
    "encoder_model = Model([LSTM_info_inputs,LSTM_questions_inputs,LSTM_facts_inputs,LSTM_rela_inputs],states)\n",
    "\n",
    "fact_model = Model(LSTM_facts_inputs, facts_states)\n",
    "ques_model = Model(LSTM_questions_inputs, questions_states)\n",
    "info_model = Model(LSTM_info_inputs, info_states)\n",
    "rela_model = Model(LSTM_rela_inputs, rela_states)\n",
    "\n",
    "decoder_inputs = Input(shape=(1, labels_index_len))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_dense = Dense(labels_index_len, activation='softmax')\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decode_sequence(info_input, facts_input, ques_input, rela_input,label_words_to_index=label_words_to_index, \\\n",
    "                                        label_index_to_words=label_index_to_words, label_pad_up_to=label_pad_up_to):\n",
    "    \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict([info_input, facts_input, ques_input, rela_input])\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, len(label_words_to_index)))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, label_words_to_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = label_index_to_words[sampled_token_index]\n",
    "        decoded_sentence += sampled_char + \" \"\n",
    "\n",
    "        # Exit condition: hit max length\n",
    "        if len(decoded_sentence) > label_pad_up_to * 2:\n",
    "            print(\"len of sentence = \", len(decoded_sentence))\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, len(label_words_to_index)))\n",
    "        target_seq[0, 0, label_words_to_index['\\t']] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of sentence =  22\n"
     ]
    }
   ],
   "source": [
    "test_info =  vectorized_info[0,:,:]\n",
    "test_info = test_info.reshape(1,*test_info.shape) \n",
    "test_fact = vectorized_fact_list[0,:,:]\n",
    "test_fact = test_fact.reshape(1,*test_fact.shape)\n",
    "test_ques = vectorized_questions[0,:,:]\n",
    "test_ques = test_ques.reshape(1,*test_ques.shape)\n",
    "test_rela = vectorized_relations[0,:,:]\n",
    "test_rela = test_rela.reshape(1,*test_rela.shape)\n",
    "\n",
    "decoded_sentence = decode_sequence(test_info, test_fact, test_ques, test_rela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN1 - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NONE'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['N3', 'MEANS', 'MORE'], ['NONE'], ['NONE'], ['NONE'], ['return', 'MAKES', 'ADD', ';'], ['buy', 'MAKES', 'SUBTRACT'], ['changed', 'PAST-TENSE', 'change', ';', 'change', 'ADD-OR-SUBTRACT'], ['changed', 'PAST-TENSE', 'change', ';', 'change', 'ADD-OR-SUBTRACT'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['N4', 'PLURAL', 'N5'], ['N4', 'PLURAL', 'N5'], ['N1', 'PLURAL', 'N3'], ['N1', 'PLURAL', 'N3'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'A1'], ['V1', 'MAKES', 'A1'], ['V1', 'MAKES', 'A1'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['NONE'], ['NONE'], ['NONE'], ['V5', 'PAST-TENSE', 'V3', ';', 'V4', 'MAKES', 'V3'], ['NONE'], ['NONE'], ['NONE'], ['opened', 'PAST-TENSE', 'open'], ['NONE'], ['NONE'], ['NONE'], ['opened', 'PAST-TENSE', 'open'], ['N2', 'IN', 'N5', ';', 'N3', 'IN', 'N5', ';', 'N4', 'IN', 'N5'], ['N2', 'IN', 'N5', ';', 'N3', 'IN', 'N5', ';', 'N4', 'IN', 'N5'], ['N2', 'IN', 'N5', ';', 'N3', 'IN', 'N5', ';', 'N4', 'IN', 'N5'], ['V1', 'MEANS', 'HAVE'], ['V1', 'MEANS', 'HAVE'], ['V1', 'MEANS', 'HAVE'], ['V1', 'MEANS', 'HAVE'], ['V1', 'MEANS', 'HAVE'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['NONE']]\n"
     ]
    }
   ],
   "source": [
    "print(facts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['how', 'many', 'N3', 'are', 'there', '?'], ['how', 'many', 'N3', 'are', 'there', '?'], ['how', 'many', 'N5', 'are', 'in', 'N1', '?'], ['how', 'many', 'N3', 'are', 'there', '?'], ['how', 'many', 'N6', 'are', 'there', '?'], ['how', 'many', 'N2', 'are', 'there', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N2', 'are', 'there', '?'], ['how', 'many', 'N2', 'are', 'in', 'first', 'N1', '?'], ['how', 'many', 'N2', 'are', 'in', 'second', 'N1', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N1', 'will', 'there', 'be', 'when', 'N4', 'comes', '?'], ['how', 'many', 'N2', 'are', 'in', 'N4', '?'], ['how', 'many', 'N1', 'went', 'on', 'the', 'N3', '?'], ['how', 'many', 'N3', 'are', 'in', 'N1', '?'], ['how', 'many', 'N5', 'are', 'in', 'N1', '?'], ['how', 'many', 'N5', 'are', 'there', '?'], ['how', 'many', 'N2', 'are', 'in', 'N1', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N1', 'are', 'in', 'the', 'N4', '?'], ['how', 'many', 'N1', 'are', 'in', 'first', 'N5', '?'], ['how', 'many', 'N1', 'are', 'in', 'second', 'N5', '?'], ['how', 'many', 'N4', 'are', 'in', 'the', 'N1', '?'], ['how', 'many', 'N4', 'are', 'in', 'each', 'N3', '?'], ['how', 'many', 'N6', 'are', 'there', '?'], ['how', 'many', 'N4', 'are', 'there', '?'], ['how', 'many', 'N5', 'are', 'there', '?'], ['how', 'many', 'A1', 'N6', 'are', 'there', '?'], ['how', 'many', 'A1', 'N4', 'are', 'there', '?'], ['how', 'many', 'A1', 'N5', 'are', 'there', '?'], ['how', 'many', 'N3', 'are', 'there', '?'], ['how', 'many', 'N2', 'are', 'there', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N1', 'did', 'they', 'V1', 'in', 'the', 'first', 'week', '?'], ['how', 'many', 'N2', 'did', 'they', 'V1', 'in', 'the', 'first', 'week', '?'], ['how', 'many', 'N1', 'did', 'they', 'V1', 'in', 'the', 'second', 'week', '?'], ['how', 'many', 'N2', 'did', 'they', 'V1', 'in', 'the', 'second', 'week', '?'], ['how', 'many', 'N3', 'did', 'they', 'V1', 'in', 'the', 'first', 'week', '?'], ['how', 'many', 'N3', 'did', 'they', 'V1', 'in', 'the', 'second', 'week', '?'], ['how', 'many', 'UNITS', 'did', 'they', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'did', 'they', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'did', 'N1', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'did', 'N1', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'of', 'N2', 'did', 'they', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'of', 'N3', 'did', 'they', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'of', 'N2', 'did', 'they', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'of', 'N3', 'did', 'they', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'of', 'N1', 'are', 'there', '?'], ['how', 'many', 'UNITS', 'of', 'N1', 'were', 'in', 'N2', 'last', 'month', '?'], ['how', 'many', 'UNITS', 'of', 'N1', 'did', 'they', 'V1', 'last', 'month', '?'], ['how', 'many', 'UNITS', 'of', 'N4', 'are', 'there', '?'], ['how', 'many', 'UNITS', 'of', 'N2', 'are', 'there', '?'], ['how', 'many', 'UNITS', 'of', 'N3', 'are', 'there', '?'], ['how', 'many', 'N2', 'were', 'V5', '?'], ['how', 'many', 'N2', 'did', 'N1', 'V2', 'to', 'V3', '?'], ['how', 'many', 'women', 'V4', '?'], ['how', 'many', 'men', 'V4', '?'], ['how', 'many', 'days', 'was', 'it', 'open', 'in', 'N2', 'an', 'N3', '?'], ['how', 'many', 'days', 'will', 'it', 'be', 'open', 'in', 'N4', '?'], ['how', 'many', 'days', 'will', 'N1', 'be', 'open', 'in', 'N4', '?'], ['how', 'many', 'days', 'was', 'N1', 'open', 'in', 'N2', 'an', 'N3', '?'], ['how', 'many', 'days', 'will', 'N1', 'have', 'been', 'open', '?'], ['how', 'many', 'N1', 'are', 'on', 'the', 'N5', '?'], ['how', 'many', 'N1', 'are', 'in', 'the', 'N5', '?'], ['how', 'many', 'UNITS', 'of', 'N1', 'are', 'there', 'on', 'the', 'N5', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N2', 'are', 'there', 'in', 'the', 'first', 'two', 'N1', '?'], ['how', 'many', 'N2', 'are', 'there', 'in', 'the', 'last', 'N1', '?'], ['how', 'many', 'N2', 'are', 'there', 'in', 'total', '?'], ['how', 'many', 'N2', 'are', 'there', '?'], ['how', 'many', 'UNITS', 'of', 'N5', 'were', 'V1', '?'], ['how', 'many', 'UNITS', 'of', 'N2', 'were', 'V1', '?'], ['how', 'many', 'UNITS', 'of', 'N2', 'were', 'V1', '?'], ['how', 'many', 'UNITS', 'of', 'N3', 'were', 'V1', '?'], ['how', 'many', 'UNITS', 'of', 'N3', 'were', 'V1', '?'], ['how', 'many', 'UNITS', 'of', 'N4', 'were', 'V1', '?'], ['how', 'many', 'UNITS', 'of', 'N4', 'were', 'V1', '?'], ['how', 'many', 'N2', 'are', 'there', '?']]\n"
     ]
    }
   ],
   "source": [
    "print(questions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['N1', 'KIND-OF', 'N3', ';', 'N2', 'KIND-OF', 'N3'], ['N2', 'KIND-OF', 'N3', ';', 'N1', 'KIND-OF', 'N3'], ['N2', 'KIND-OF', 'N5', ';', 'N4', 'KIND-OF', 'N5'], ['N1', 'KIND-OF', 'N3'], ['N2', 'KIND-OF', 'N6', ';', 'N4', 'KIND-OF', 'N6'], ['NONE'], ['NONE'], ['N2', 'NOT', 'KIND-OF', 'N1'], ['NONE'], ['NONE'], ['NONE'], ['last', 'week', 'BEFORE', 'today'], ['NONE'], ['last', 'week', 'BEFORE', 'yesterday', ';', 'yesterday', 'BEFORE', 'today', ';', 'V1', 'MAKES', 'N4'], ['last', 'week', 'BEFORE', 'yesterday', ';', 'yesterday', 'BEFORE', 'today', ';', 'V1', 'MAKES', 'N4'], ['V1', 'MAKES', 'SUBSTRACT'], ['N4', 'KIND-OF', 'N1'], ['N2', 'KIND-OF', 'N5', ';', 'N3', 'KIND-OF', 'N5'], ['N2', 'KIND-OF', 'N5', ';', 'N3', 'KIND-OF', 'N5'], ['N3', 'NOT', 'KIND-OF', 'N2'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['N4', 'KIND-OF', 'N6', ';', 'N5', 'KIND-OF', 'N6'], ['NONE'], ['NONE'], ['N4', 'KIND-OF', 'N6', ';', 'N5', 'KIND-OF', 'N6'], ['NONE'], ['NONE'], ['N1', 'KIND-OF', 'N3', ';', 'N2', 'KIND-OF', 'N3'], ['N1', 'NOT', 'KIND-OF', 'N2'], ['N2', 'NOT', 'KIND-OF', 'N1'], ['N1', 'NOT', 'KIND-OF', 'N2'], ['N2', 'NOT', 'KIND-OF', 'N1'], ['N1', 'NOT', 'KIND-OF', 'N2'], ['N2', 'NOT', 'KIND-OF', 'N1'], ['N1', 'KIND-OF', 'N3', ';', 'N2', 'KIND-OF', 'N3'], ['N1', 'KIND-OF', 'N3', ';', 'N2', 'KIND-OF', 'N3'], ['they', '=', 'N1'], ['they', '=', 'N1'], ['NONE'], ['NONE'], ['they', '=', 'N1'], ['they', '=', 'N1'], ['they', '=', 'N1'], ['they', '=', 'N1'], ['NONE'], ['N2', 'PLACE'], ['NONE'], ['N2', 'KIND-OF', 'N4', ';', 'N3', 'KIND-OF', 'N4'], ['NONE'], ['NONE'], ['men', 'KIND-OF', 'PEOPLE', ';', 'women', 'KIND-OF', 'PEOPLE', ';', 'N2', 'KIND-OF', 'PEOPLE'], ['NONE'], ['NONE'], ['NONE'], ['it', '=', 'N1', ';', 'N2', 'KIND-OF', 'month', ';', 'N3', 'KIND-OF', 'month'], ['it', '=', 'N1', ';', 'N4', 'KIND-OF', 'month'], ['it', '=', 'N1', ';', 'N4', 'KIND-OF', 'month'], ['N2', 'KIND-OF', 'month', ';', 'N3', 'KIND-OF', 'month'], ['N2', 'KIND-OF', 'month', ';', 'N3', 'KIND-OF', 'month'], ['N2', 'IN', 'N5', ';', 'N3', 'IN', 'N5', ';', 'N4', 'IN', 'N5'], ['N2', 'IN', 'N5', ';', 'N3', 'IN', 'N5', ';', 'N4', 'IN', 'N5'], ['N2', 'COUNT', '1', ';', 'N3', 'COUNT', '1', ';', 'N4', 'COUNT', '1'], ['N1', 'NUM-OF-TYPES', '3'], ['N1', 'NUM-OF-TYPES', '3'], ['N1', 'NUM-OF-TYPES', '3'], ['N1', 'NUM-OF-TYPES', '3'], ['N1', 'NUM-OF-TYPES', '3'], ['N2', 'KIND-OF', 'N5', ';', 'N3', 'KIND-OF', 'N5', ';', 'N4', 'KIND-OF', 'N5'], ['N2', 'KIND-OF', 'N5', ';', 'N3', 'KIND-OF', 'N5', ';', 'N4', 'KIND-OF', 'N5'], ['NONE'], ['N2', 'KIND-OF', 'N5', ';', 'N3', 'KIND-OF', 'N5', ';', 'N4', 'KIND-OF', 'N5'], ['NONE'], ['N2', 'KIND-OF', 'N5', ';', 'N3', 'KIND-OF', 'N5', ';', 'N4', 'KIND-OF', 'N5'], ['NONE'], ['NONE']]\n"
     ]
    }
   ],
   "source": [
    "print(relations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['there', 'are', 'IN1', 'N1', 'and', 'IN2', 'N2', '.'], ['there', 'are', 'IN1', 'N2', 'and', 'IN2', 'N1', '.'], ['in', 'the', 'N1', ',', 'there', 'are', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['there', 'are', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.'], ['at', 'the', 'N1', ',', 'there', 'are', 'IN1', 'UNITS', 'of', 'N2', 'with', 'N3', 'and', 'IN2', 'UNITS', 'of', 'N4', 'with', 'N5', '.'], ['next', 'to', 'the', 'IN1', 'N1', ',', 'there', 'are', 'IN2', 'N2', '.', 'on', 'the', 'other', 'side', 'of', 'the', 'N3', ',', 'there', 'are', 'IN3', 'N2', '.'], ['there', 'are', 'IN1', 'N1', 'in', 'the', 'N2', 'and', 'IN2', 'N1', 'on', 'N3', '.'], ['there', 'are', 'IN1', 'N1', 'and', 'IN2', 'N2', 'from', 'the', 'N3', '.', 'the', 'N4', 'has', 'IN3', 'N1', 'already', '.'], ['in', 'one', 'N1', ',', 'there', 'are', 'IN1', 'N2', '.', 'in', 'the', 'other', 'N1', ',', 'there', 'are', 'IN2', 'N2', '.'], ['in', 'one', 'N1', ',', 'there', 'are', 'IN1', 'N2', '.', 'in', 'the', 'other', 'N1', ',', 'there', 'are', 'IN2', 'N2', '.'], ['in', 'one', 'N1', ',', 'there', 'are', 'IN1', 'N2', '.', 'in', 'the', 'other', 'N1', ',', 'there', 'are', 'IN2', 'N2', '.'], ['there', 'were', 'IN1', 'UNITS', 'of', 'N1', 'in', 'the', 'N2', '.', 'a', 'N3', 'comes', 'in', 'to', 'return', 'IN2', 'UNITS', 'of', 'N1', 'he', 'bought', 'last', 'week', '.'], ['there', 'were', 'IN1', 'UNITS', 'of', 'N1', 'in', 'the', 'N2', '.', 'a', 'N3', 'comes', 'in', 'to', 'buy', 'IN2', 'UNITS', '.'], ['N1', 'V1', 'IN1', 'N2', 'last', 'week', '.', 'yesterday', ',', 'he', 'called', 'the', 'N3', 'and', 'changed', 'the', 'N4', 'to', 'add', 'IN2', 'more', 'N2', '.'], ['N1', 'V1', 'IN1', 'N2', 'last', 'week', '.', 'yesterday', ',', 'he', 'called', 'the', 'N3', 'and', 'changed', 'the', 'N4', 'to', 'subtract', 'IN2', 'N2', '.'], ['IN1', 'N1', 'in', 'N2', 'went', 'on', 'the', 'N3', 'and', 'IN2', 'N1', 'V1', 'and', 'could', 'not', 'go', 'on', 'the', 'N3', '.'], ['in', 'the', 'N1', ',', 'there', 'were', 'IN1', 'N2', 'and', 'IN2', 'N3', '.', 'on', 'the', 'other', 'side', 'of', 'the', 'N4', ',', 'there', 'were', 'IN3', 'N3', 'for', 'V1', '.'], ['in', 'the', 'N1', ',', 'there', 'were', 'IN1', 'N2', 'and', 'IN2', 'N3', '.', 'on', 'the', 'other', 'side', 'of', 'the', 'N4', ',', 'there', 'were', 'IN3', 'N3', 'for', 'V1', '.'], ['in', 'the', 'N1', ',', 'there', 'were', 'IN1', 'N2', 'and', 'IN2', 'N3', '.', 'on', 'the', 'other', 'side', 'of', 'the', 'N4', ',', 'there', 'were', 'IN3', 'N3', 'for', 'V1', '.'], ['in', 'the', 'N1', ',', 'there', 'were', 'IN1', 'N2', 'and', 'IN2', 'N3', '.', 'on', 'the', 'other', 'side', 'of', 'the', 'N4', ',', 'there', 'were', 'IN3', 'N3', 'for', 'V1', '.'], ['N1', 'were', 'V1', 'for', 'N2', '.', 'as', 'there', 'were', 'IN1', 'N3', ',', 'the', 'N1', 'V1', 'in', 'IN2', 'N4', '.', 'there', 'were', 'IN3', 'N1', 'in', 'one', 'N5', 'and', 'IN4', 'N1', 'in', 'another', 'N5'], ['N1', 'were', 'V1', 'for', 'N2', '.', 'as', 'there', 'were', 'IN1', 'N3', ',', 'the', 'N1', 'V1', 'in', 'IN2', 'N4', '.', 'there', 'were', 'IN3', 'N1', 'in', 'one', 'N5', 'and', 'IN4', 'N1', 'in', 'another', 'N5'], ['N1', 'were', 'V1', 'for', 'N2', '.', 'as', 'there', 'were', 'IN1', 'N3', ',', 'the', 'N1', 'V1', 'in', 'IN2', 'N4', '.', 'there', 'were', 'IN3', 'N1', 'in', 'one', 'N5', 'and', 'IN4', 'N1', 'in', 'another', 'N5'], ['N1', 'were', 'V1', 'for', 'N2', '.', 'as', 'there', 'were', 'IN1', 'N3', ',', 'the', 'N1', 'V1', 'in', 'IN2', 'N4', '.', 'there', 'were', 'IN3', 'N1', 'in', 'one', 'N5', 'and', 'IN4', 'N1', 'in', 'another', 'N5'], ['there', 'were', 'IN1', 'N1', 'in', 'the', 'N2', '.', 'each', 'N3', 'V1', 'IN2', 'N4', '.'], ['there', 'were', 'IN1', 'N1', 'in', 'the', 'N2', '.', 'each', 'N3', 'V1', 'IN2', 'N4', '.'], ['the', 'N1', 'V1', 'some', 'N2', 'for', 'the', 'N3', '.', 'there', 'were', 'IN1', 'UNITS', 'of', 'N4', 'and', 'IN2', 'UNITS', 'of', 'N5', '.'], ['the', 'N1', 'V1', 'some', 'N2', 'for', 'the', 'N3', '.', 'there', 'were', 'IN1', 'UNITS', 'of', 'N4', 'and', 'IN2', 'UNITS', 'of', 'N5', '.'], ['the', 'N1', 'V1', 'some', 'N2', 'for', 'the', 'N3', '.', 'there', 'were', 'IN1', 'UNITS', 'of', 'N4', 'and', 'IN2', 'UNITS', 'of', 'N5', '.'], ['the', 'N1', 'V1', 'with', 'the', 'N2', 'at', 'the', 'N3', ',', 'there', 'are', 'A1', 'IN1', 'UNITS', 'of', 'N4', 'and', 'IN2', 'UNITS', 'of', 'N5', '.'], ['the', 'N1', 'V1', 'with', 'the', 'N2', 'at', 'the', 'N3', ',', 'there', 'are', 'A1', 'IN1', 'UNITS', 'of', 'N4', 'and', 'IN2', 'UNITS', 'of', 'N5', '.'], ['the', 'N1', 'V1', 'with', 'the', 'N2', 'at', 'the', 'N3', ',', 'there', 'are', 'A1', 'IN1', 'UNITS', 'of', 'N4', 'and', 'IN2', 'UNITS', 'of', 'N5', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['during', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'during', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['in', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['in', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['during', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'during', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['during', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'during', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['during', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'during', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['in', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['in', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['they', 'had', 'IN1', 'UNITS', 'of', 'N1', 'in', 'N2', 'and', 'V1', 'IN2', 'more', 'UNITS', 'last', 'month', '.'], ['they', 'had', 'IN1', 'UNITS', 'of', 'N1', 'in', 'N2', 'and', 'V1', 'IN2', 'more', 'UNITS', 'last', 'month', '.'], ['they', 'had', 'IN1', 'UNITS', 'of', 'N1', 'in', 'N2', 'and', 'V1', 'IN2', 'more', 'UNITS', 'last', 'month', '.'], ['in', 'the', 'N1', ',', 'there', 'are', 'IN1', 'UNITS', 'of', 'N2', '.', 'there', 'were', 'IN2', 'more', 'UNITS', 'of', 'N3', 'than', 'N2', '.'], ['in', 'the', 'N1', ',', 'there', 'are', 'IN1', 'UNITS', 'of', 'N2', '.', 'there', 'were', 'IN2', 'more', 'UNITS', 'of', 'N3', 'than', 'N2', '.'], ['in', 'the', 'N1', ',', 'there', 'are', 'IN1', 'UNITS', 'of', 'N2', '.', 'there', 'were', 'IN2', 'more', 'UNITS', 'of', 'N3', 'than', 'N2', '.'], ['the', 'N1', 'V2', 'to', 'V3', 'IN1', 'N2', '.', 'IN2', 'men', 'and', 'IN3', 'women', 'V4', '.'], ['the', 'N1', 'V2', 'to', 'V3', 'IN1', 'N2', '.', 'IN2', 'men', 'and', 'IN3', 'women', 'V4', '.'], ['the', 'N1', 'V2', 'to', 'V3', 'IN1', 'N2', '.', 'IN2', 'men', 'and', 'IN3', 'women', 'V4', '.'], ['the', 'N1', 'V2', 'to', 'V3', 'IN1', 'N2', '.', 'IN2', 'men', 'and', 'IN3', 'women', 'V4', '.'], ['the', 'N1', 'opened', 'IN1', 'days', 'in', 'N2', 'and', 'IN2', 'days', 'in', 'N3', '.', 'it', 'will', 'be', 'opened', 'for', 'IN3', 'days', 'in', 'N4', '.'], ['the', 'N1', 'opened', 'IN1', 'days', 'in', 'N2', 'and', 'IN2', 'days', 'in', 'N3', '.', 'it', 'will', 'be', 'opened', 'for', 'IN3', 'days', 'in', 'N4', '.'], ['the', 'N1', 'opened', 'IN1', 'days', 'in', 'N2', 'and', 'IN2', 'days', 'in', 'N3', '.', 'it', 'will', 'be', 'opened', 'for', 'IN3', 'days', 'in', 'N4', '.'], ['the', 'N1', 'opened', 'IN1', 'days', 'in', 'N2', 'and', 'IN2', 'days', 'in', 'N3', '.', 'it', 'will', 'be', 'opened', 'for', 'IN3', 'days', 'in', 'N4', '.'], ['the', 'N1', 'opened', 'IN1', 'days', 'in', 'N2', 'and', 'IN2', 'days', 'in', 'N3', '.', 'it', 'will', 'be', 'opened', 'for', 'IN3', 'days', 'in', 'N4', '.'], ['there', 'are', 'IN1', 'N1', 'in', 'N2', ',', 'IN2', 'N1', 'in', 'the', 'N3', 'and', 'IN3', 'N1', 'in', 'the', 'N4', '.'], ['there', 'are', 'IN1', 'N1', 'in', 'N2', ',', 'IN2', 'N1', 'in', 'the', 'N3', 'and', 'IN3', 'N1', 'in', 'the', 'N4', '.'], ['there', 'are', 'IN1', 'UNITS', 'of', 'N1', 'in', 'each', 'of', 'N2', 'and', 'N3', 'and', 'there', 'are', 'IN2', 'UNITS', 'of', 'N1', 'in', 'N4', '.'], ['there', 'are', 'IN1', 'N1', 'for', 'N2', 'and', 'each', 'N1', 'has', 'a', 'capacity', 'of', 'IN2', 'UNITS', 'of', 'N2', '.', 'the', 'first', 'IN3', 'N1', 'are', 'full', 'and', 'the', 'last', 'IN4', 'V1', 'IN5', 'UNITS', 'of', 'N2', '.'], ['there', 'are', 'IN1', 'N1', 'for', 'N2', 'and', 'each', 'N1', 'has', 'a', 'capacity', 'of', 'IN2', 'UNITS', 'of', 'N2', '.', 'the', 'first', 'IN3', 'N1', 'are', 'full', 'and', 'the', 'last', 'IN4', 'V1', 'IN5', 'UNITS', 'of', 'N2', '.'], ['there', 'are', 'IN1', 'N1', 'for', 'N2', 'and', 'each', 'N1', 'has', 'a', 'capacity', 'of', 'IN2', 'UNITS', 'of', 'N2', '.', 'the', 'first', 'IN3', 'N1', 'are', 'full', 'and', 'the', 'last', 'IN4', 'V1', 'IN5', 'UNITS', 'of', 'N2', '.'], ['there', 'are', 'IN1', 'N1', 'for', 'N2', 'and', 'each', 'N1', 'has', 'a', 'capacity', 'of', 'IN2', 'UNITS', 'of', 'N2', '.', 'the', 'first', 'IN3', 'N1', 'are', 'full', 'and', 'the', 'last', 'IN4', 'V1', 'IN5', 'UNITS', 'of', 'N2', '.'], ['there', 'are', 'IN1', 'N1', 'for', 'N2', 'and', 'each', 'N1', 'has', 'a', 'capacity', 'of', 'IN2', 'UNITS', 'of', 'N2', '.', 'the', 'first', 'IN3', 'N1', 'are', 'full', 'and', 'the', 'last', 'IN4', 'V1', 'IN5', 'UNITS', 'of', 'N2', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['there', 'are', 'IN1', 'N1', '.', 'each', 'N1', 'has', 'IN2', 'N2', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IN1 + IN2\\n', 'IN2 + IN1\\n', 'IN1 + IN3\\n', 'IN1\\n', 'IN1 + IN2\\n', 'IN2 + IN3\\n', 'IN1 + IN2\\n', 'IN1 + IN3\\n', 'IN1 + IN2\\n', 'IN1\\n', 'IN2\\n', 'IN1 + IN2\\n', 'IN1 - IN2\\n', 'IN1 + IN2\\n', 'IN1 - IN2\\n', 'IN1 - IN2\\n', 'IN1 + IN3\\n', 'IN1 + IN2 + IN3\\n', 'IN1 + IN2 + IN3\\n', 'IN1\\n', 'IN3 + IN4\\n', 'IN3 + IN4\\n', 'IN3\\n', 'IN4\\n', 'IN1 * IN2\\n', 'IN2\\n', 'IN1 + IN2\\n', 'IN1\\n', 'IN2\\n', 'IN1 + IN2\\n', 'IN1\\n', 'IN2\\n', 'IN1 + IN2 + IN3 + IN4\\n', 'IN2 + IN4\\n', 'IN1 + IN3\\n', 'IN1\\n', 'IN2\\n', 'IN3\\n', 'IN4\\n', 'IN1 + IN2\\n', 'IN3 + IN4\\n', 'IN1 + IN2 + IN3 + IN4\\n', 'IN1 + IN2 + IN3 + IN4\\n', 'IN1 + IN2 + IN3 + IN4\\n', 'IN1 + IN2 + IN3 + IN4\\n', 'IN1 + IN3\\n', 'IN2 + IN4\\n', 'IN1 + IN3\\n', 'IN2 + IN4\\n', 'IN1 + IN2\\n', 'IN1\\n', 'IN2\\n', 'IN1 + IN1 + IN2\\n', 'IN1\\n', 'IN1 + IN2\\n', 'IN2 + IN3\\n', 'IN1\\n', 'IN3\\n', 'IN2\\n', 'IN1 + IN2\\n', 'IN3\\n', 'IN3\\n', 'IN1 + IN2\\n', 'IN1 + IN2 + IN3\\n', 'IN1 + IN2 + IN3\\n', 'IN1 + IN2 + IN3\\n', 'IN1 * RN1 + IN1 * RN2 + IN2\\n', 'IN1\\n', 'IN2 + IN2\\n', 'IN5\\n', 'IN2 + IN2 + IN5\\n', 'IN2 + IN2 + IN5\\n', 'IN1 + IN2 + IN3\\n', 'IN1\\n', 'IN1\\n', 'IN2\\n', 'IN2\\n', 'IN3\\n', 'IN3\\n', 'IN1 * IN2']\n"
     ]
    }
   ],
   "source": [
    "print(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
