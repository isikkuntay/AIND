{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import sys\n",
    "import numpy\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Merge\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "questions = open('abstract_math_questions.txt','r')\n",
    "labels = open('abstract_math_labels.txt','r')\n",
    "info_sentences = open('abstract_math_info.txt','r')\n",
    "fact_sentences = open('abstract_math_facts.txt','r')\n",
    "standard_relations = open('abstract_math_relations.txt','r')\n",
    "\n",
    "questions_list = []\n",
    "labels_list = []\n",
    "info_list = []\n",
    "relations_list = []\n",
    "facts_list = []\n",
    "\n",
    "for sentence in questions:\n",
    "    questions_list.append(sentence)\n",
    "    \n",
    "for sentence in labels:\n",
    "    labels_list.append(sentence)\n",
    "    \n",
    "for sentence in info_sentences:\n",
    "    info_list.append(sentence)\n",
    "\n",
    "for sentence in fact_sentences:\n",
    "    facts_list.append(sentence)\n",
    "    \n",
    "for sentence in standard_relations:\n",
    "    relations_list.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "10\n",
      "26\n",
      "5\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(questions_list[0]))\n",
    "print(len(labels_list[0]))\n",
    "print(len(info_list[0]))\n",
    "print(len(facts_list[0]))\n",
    "print(len(relations_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#in this version, we put placeholders for numbers, such as QN1, QN2, etc.. for question numbers\n",
    "\n",
    "fact_num_dict_list = []\n",
    "ques_num_dict_list = []\n",
    "info_num_dict_list = []\n",
    "rela_num_dict_list = []\n",
    "\n",
    "changed_facts_list = []\n",
    "changed_questions_list = []\n",
    "changed_info_list = []\n",
    "changed_relations_list = []\n",
    "\n",
    "#store the numbers in a list of dicts\n",
    "#for facts list: (we will only process the info list, as others do not have numbers this time)\n",
    "for sentence in facts_list:\n",
    "    fact_num_dict = {}\n",
    "    changed_fact_sentence = []\n",
    "    indx_num = 1\n",
    "    for word in sentence.split():\n",
    "        changed_fact_sentence.append(word)\n",
    "    changed_facts_list.append(changed_fact_sentence)\n",
    "    fact_num_dict_list.append(fact_num_dict)\n",
    "\n",
    "#repeat for questions\n",
    "for sentence in questions_list:\n",
    "    quest_num_dict = {}\n",
    "    changed_qu_sentence = []\n",
    "    indx_num = 1\n",
    "    for word in sentence.split():\n",
    "        changed_qu_sentence.append(word)\n",
    "    changed_questions_list.append(changed_qu_sentence)\n",
    "    ques_num_dict_list.append(quest_num_dict)   \n",
    "\n",
    "#repeat for information\n",
    "for sentence in info_list:\n",
    "    info_num_dict = {}\n",
    "    changed_info_sentence = []\n",
    "    indx_num = 1\n",
    "    for word in sentence.split():\n",
    "        if word.isdigit():\n",
    "            if indx_num == 1:\n",
    "                new_word = \"IN1\"\n",
    "            elif indx_num == 2:\n",
    "                new_word = \"IN2\"\n",
    "            elif indx_num == 3:\n",
    "                new_word = \"IN3\"\n",
    "            elif indx_num == 4:\n",
    "                new_word = \"IN4\"\n",
    "            elif indx_num == 5:\n",
    "                new_word = \"IN5\"\n",
    "            info_num_dict[word] = new_word\n",
    "            changed_info_sentence.append(new_word)\n",
    "            indx_num += 1\n",
    "        else:\n",
    "            changed_info_sentence.append(word)\n",
    "    changed_info_list.append(changed_info_sentence)\n",
    "    info_num_dict_list.append(info_num_dict)   \n",
    "\n",
    "#repeat for information\n",
    "for sentence in relations_list:\n",
    "    rela_num_dict = {}\n",
    "    changed_rela_sentence = []\n",
    "    indx_num = 1\n",
    "    for word in sentence.split():\n",
    "        changed_rela_sentence.append(word)\n",
    "    changed_relations_list.append(changed_rela_sentence)\n",
    "    rela_num_dict_list.append(info_num_dict)   \n",
    "    \n",
    "facts_list = changed_facts_list\n",
    "questions_list = changed_questions_list\n",
    "info_list = changed_info_list\n",
    "relations_list = changed_relations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "list_of_all_variables = []\n",
    "\n",
    "### Let's make a list of all variables and prepare them for one-hot-coding\n",
    "\n",
    "# Start by assigning numbers to the standard variables:\n",
    "\n",
    "list_of_all_variables.append(\"QN1\")\n",
    "list_of_all_variables.append(\"QN2\")\n",
    "list_of_all_variables.append(\"QN3\")\n",
    "list_of_all_variables.append(\"QN4\")\n",
    "list_of_all_variables.append(\"QN5\")\n",
    "list_of_all_variables.append(\"QN6\")\n",
    "list_of_all_variables.append(\"QN7\")\n",
    "list_of_all_variables.append(\"QN8\")\n",
    "list_of_all_variables.append(\"FN1\")\n",
    "list_of_all_variables.append(\"FN2\")\n",
    "list_of_all_variables.append(\"FN3\")\n",
    "list_of_all_variables.append(\"FN4\")\n",
    "list_of_all_variables.append(\"FN5\")\n",
    "list_of_all_variables.append(\"FN6\")\n",
    "list_of_all_variables.append(\"FN7\")\n",
    "list_of_all_variables.append(\"FN8\")\n",
    "list_of_all_variables.append(\"IN1\")\n",
    "list_of_all_variables.append(\"IN2\")\n",
    "list_of_all_variables.append(\"IN3\")\n",
    "list_of_all_variables.append(\"IN4\")\n",
    "list_of_all_variables.append(\"IN5\")\n",
    "list_of_all_variables.append(\"IN6\")\n",
    "list_of_all_variables.append(\"IN7\")\n",
    "list_of_all_variables.append(\"IN8\")\n",
    "list_of_all_variables.append(\"N1\")\n",
    "list_of_all_variables.append(\"N2\")\n",
    "list_of_all_variables.append(\"N3\")\n",
    "list_of_all_variables.append(\"N4\")\n",
    "list_of_all_variables.append(\"N5\")\n",
    "list_of_all_variables.append(\"N6\")\n",
    "list_of_all_variables.append(\"N7\")\n",
    "list_of_all_variables.append(\"N8\")\n",
    "list_of_all_variables.append(\"N9\")\n",
    "list_of_all_variables.append(\"V1\")\n",
    "list_of_all_variables.append(\"V2\")\n",
    "list_of_all_variables.append(\"V3\")\n",
    "list_of_all_variables.append(\"V4\")\n",
    "list_of_all_variables.append(\"V5\")\n",
    "list_of_all_variables.append(\"V6\")\n",
    "list_of_all_variables.append(\"V7\")\n",
    "list_of_all_variables.append(\"V8\")\n",
    "list_of_all_variables.append(\"V9\")\n",
    "\n",
    "for sentence in facts_list:\n",
    "    for word in sentence:\n",
    "        if word not in list_of_all_variables:\n",
    "            list_of_all_variables.append(word)\n",
    "    \n",
    "for sentence in info_list:\n",
    "    for word in sentence:\n",
    "        if word not in list_of_all_variables:\n",
    "            list_of_all_variables.append(word) \n",
    "\n",
    "for sentence in questions_list:\n",
    "    for word in sentence:\n",
    "        if word not in list_of_all_variables:\n",
    "            list_of_all_variables.append(word)\n",
    "\n",
    "for sentence in relations_list:\n",
    "    for word in sentence:\n",
    "        if word not in list_of_all_variables:\n",
    "            list_of_all_variables.append(word)      \n",
    "            \n",
    "list_of_all_variables.append(\"<PAD>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QN1', 'QN2', 'QN3', 'QN4', 'QN5', 'QN6', 'QN7', 'QN8', 'FN1', 'FN2', 'FN3', 'FN4', 'FN5', 'FN6', 'FN7', 'FN8', 'IN1', 'IN2', 'IN3', 'IN4', 'IN5', 'IN6', 'IN7', 'IN8', 'N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 'N9', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'NONE', 'MEANS', 'MORE', 'return', 'MAKES', 'ADD', ';', 'buy', 'SUBTRACT', 'changed', 'PAST-TENSE', 'change', 'ADD-OR-SUBTRACT', 'PLURAL', 'A1', 'opened', 'open', 'IN', 'HAVE', 'there', 'are', 'and', '.', 'in', 'the', ',', 'UNITS', 'of', 'at', 'with', 'next', 'to', 'on', 'other', 'side', 'from', 'has', 'already', 'one', 'were', 'a', 'comes', 'he', 'bought', 'last', 'week', 'yesterday', 'called', 'add', 'more', 'subtract', 'went', 'could', 'not', 'go', 'for', 'as', 'another', 'each', 'some', 'first', 'they', 'second', 'during', 'had', 'month', 'than', 'men', 'women', 'days', 'it', 'will', 'be', 'capacity', 'full', 'how', 'many', '?', 'when', 'did', 'total', 'was', 'an', 'have', 'been', 'two', 'KIND-OF', 'NOT', 'BEFORE', 'today', 'SUBSTRACT', '=', 'PLACE', 'PEOPLE', 'COUNT', '1', 'NUM-OF-TYPES', '3', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "\n",
    "word_index = 0\n",
    "\n",
    "for word in list_of_all_variables:\n",
    "    word_to_index[word] = word_index\n",
    "    index_to_word[word_index] = word\n",
    "    word_index += 1\n",
    "print(list_of_all_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_facts_list = []\n",
    "new_questions_list = []\n",
    "new_info_list = []\n",
    "new_relations_list = []\n",
    "\n",
    "pad_up_to = 100\n",
    "pad_index = word_to_index[\"<PAD>\"]\n",
    "\n",
    "for sentence in facts_list:\n",
    "    substitute_sentence = []\n",
    "    for word in sentence:\n",
    "        substitute_sentence.append(word_to_index[word])\n",
    "    for i in range(len(substitute_sentence),pad_up_to):\n",
    "        substitute_sentence.append(pad_index)\n",
    "    new_facts_list.append(substitute_sentence)\n",
    "\n",
    "for sentence in questions_list:\n",
    "    substitute_sentence = []\n",
    "    for word in sentence:\n",
    "        substitute_sentence.append(word_to_index[word])\n",
    "    for i in range(len(substitute_sentence),pad_up_to):\n",
    "        substitute_sentence.append(pad_index)\n",
    "    new_questions_list.append(substitute_sentence)\n",
    "        \n",
    "for sentence in info_list:\n",
    "    substitute_sentence = []\n",
    "    for word in sentence:\n",
    "        substitute_sentence.append(word_to_index[word])\n",
    "    for i in range(len(substitute_sentence),pad_up_to):\n",
    "        substitute_sentence.append(pad_index)\n",
    "    new_info_list.append(substitute_sentence)\n",
    "\n",
    "for sentence in relations_list:\n",
    "    substitute_sentence = []\n",
    "    for word in sentence:\n",
    "        substitute_sentence.append(word_to_index[word])\n",
    "    for i in range(len(substitute_sentence),pad_up_to):\n",
    "        substitute_sentence.append(pad_index)\n",
    "    new_relations_list.append(substitute_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(new_facts_list))\n",
    "print(len(new_questions_list))\n",
    "print(len(new_info_list))\n",
    "print(len(new_relations_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "one_hot_facts = []\n",
    "one_hot_questions = []\n",
    "one_hot_info = []\n",
    "one_hot_relations = []\n",
    "\n",
    "one_hot_length = len(word_to_index)\n",
    "\n",
    "for sentence in new_facts_list:\n",
    "    substitute_sentence = []\n",
    "    for word_ind in sentence:\n",
    "        substitute_word = []\n",
    "        for i in range(one_hot_length):\n",
    "            if i == word_ind:\n",
    "                substitute_word.append(1)\n",
    "            else:\n",
    "                substitute_word.append(0)\n",
    "        substitute_sentence.append(substitute_word)\n",
    "    one_hot_facts.append(substitute_sentence)\n",
    "\n",
    "for sentence in new_questions_list:\n",
    "    substitute_sentence = []\n",
    "    for word_ind in sentence:\n",
    "        substitute_word = []\n",
    "        for i in range(one_hot_length):\n",
    "            if i == word_ind:\n",
    "                substitute_word.append(1)\n",
    "            else:\n",
    "                substitute_word.append(0)\n",
    "        substitute_sentence.append(substitute_word)\n",
    "    one_hot_questions.append(substitute_sentence)\n",
    "\n",
    "for sentence in new_info_list:\n",
    "    substitute_sentence = []\n",
    "    for word_ind in sentence:\n",
    "        substitute_word = []\n",
    "        for i in range(one_hot_length):\n",
    "            if i == word_ind:\n",
    "                substitute_word.append(1)\n",
    "            else:\n",
    "                substitute_word.append(0)\n",
    "        substitute_sentence.append(substitute_word)\n",
    "    one_hot_info.append(substitute_sentence)\n",
    "    \n",
    "for sentence in new_relations_list:\n",
    "    substitute_sentence = []\n",
    "    for word_ind in sentence:\n",
    "        substitute_word = []\n",
    "        for i in range(one_hot_length):\n",
    "            if i == word_ind:\n",
    "                substitute_word.append(1)\n",
    "            else:\n",
    "                substitute_word.append(0)\n",
    "        substitute_sentence.append(substitute_word)\n",
    "    one_hot_relations.append(substitute_sentence)\n",
    "    \n",
    "vectorized_fact_list = np.asarray(one_hot_facts)\n",
    "vectorized_questions = np.asarray(one_hot_questions) \n",
    "vectorized_info = np.asarray(one_hot_info)\n",
    "vectorized_relations = np.asarray(one_hot_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 100, 141)\n",
      "(80, 100, 141)\n",
      "(80, 100, 141)\n",
      "(80, 100, 141)\n"
     ]
    }
   ],
   "source": [
    "print(vectorized_fact_list.shape)\n",
    "print(vectorized_questions.shape)\n",
    "print(vectorized_info.shape)\n",
    "print(vectorized_relations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "label_words_to_index = {}\n",
    "label_index_to_words = {}\n",
    "label_index = 0\n",
    "label_words_to_index[\"\\t\"]=label_index\n",
    "label_index_to_words[label_index]=\"\\t\"\n",
    "label_index += 1\n",
    "label_words_to_index[\"<PAD>\"]=label_index\n",
    "label_index_to_words[label_index]=\"<PAD>\"\n",
    "new_label_list = []\n",
    "decoder_input_list = [] #in this version, we will use teacher enforcing, so we need a shifted target data\n",
    "label_pad_up_to = 10\n",
    "for sentence in labels_list:\n",
    "    substitute_sentence = []\n",
    "    decoder_subs_sentence = [] \n",
    "    decoder_subs_sentence.append(label_words_to_index[\"\\t\"]) #decoder input data starts with a \\t character\n",
    "    sent = sentence.split()\n",
    "    for char in sent: #char could be a word or group of characters\n",
    "        if char in label_words_to_index.keys():\n",
    "            substitute_sentence.append(label_words_to_index[char])\n",
    "            decoder_subs_sentence.append(label_words_to_index[char])\n",
    "        else:\n",
    "            label_index += 1\n",
    "            label_words_to_index[char]=label_index\n",
    "            label_index_to_words[label_index]=char\n",
    "            substitute_sentence.append(label_words_to_index[char])\n",
    "            decoder_subs_sentence.append(label_words_to_index[char])\n",
    "    for i in range(len(substitute_sentence),label_pad_up_to): #pad to regular\n",
    "        substitute_sentence.append(label_words_to_index[\"<PAD>\"])\n",
    "    for i in range(len(decoder_subs_sentence),label_pad_up_to): #pad to regular\n",
    "        decoder_subs_sentence.append(label_words_to_index[\"<PAD>\"])\n",
    "        \n",
    "    new_label_list.append(substitute_sentence)\n",
    "    decoder_input_list.append(decoder_subs_sentence)\n",
    "    \n",
    "#vectorize labels\n",
    "vectorized_label_list = []\n",
    "for sentence in new_label_list:\n",
    "    sentence_vector = []\n",
    "    for word in sentence:\n",
    "        vector = [0]*len(label_words_to_index)\n",
    "        vector[word] = 1\n",
    "        sentence_vector.append(vector)\n",
    "    vectorized_label_list.append(sentence_vector)\n",
    "\n",
    "label_array = np.asarray(vectorized_label_list)\n",
    "\n",
    "#vectorize decoder inputs\n",
    "vectorized_decoder_list = []\n",
    "for sentence in decoder_input_list:\n",
    "    sentence_vector = []\n",
    "    for word in sentence:\n",
    "        vector = [0]*len(label_words_to_index)\n",
    "        vector[word] = 1\n",
    "        sentence_vector.append(vector)\n",
    "    vectorized_decoder_list.append(sentence_vector)\n",
    "    \n",
    "decoder_input_data = np.asarray(vectorized_decoder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 10, 12)\n",
      "(80, 10, 12)\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(label_array.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(len(label_words_to_index))\n",
    "print(len(label_index_to_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, dictionary):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"    \n",
    "    return ' '.join([label_index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Implement\n",
    "learning_rate = 0.01\n",
    "hidden_units = 128\n",
    "latent_dim = 128 \n",
    "# TODO: Build the layers\n",
    "\n",
    "labels_index_len = len(label_index_to_words)\n",
    "info_shape = vectorized_info.shape\n",
    "questions_shape = vectorized_questions.shape\n",
    "facts_shape = vectorized_fact_list.shape\n",
    "relations_shape = vectorized_relations.shape\n",
    "    \n",
    "LSTM_info_inputs = Input(shape=(None, info_shape[2]))\n",
    "LSTM_info = LSTM(hidden_units,return_state=True)\n",
    "LSTM_info_output, info_h, info_c=LSTM_info(LSTM_info_inputs)\n",
    "info_states = [info_h,info_c]\n",
    "    \n",
    "LSTM_questions_inputs = Input(shape=(None, questions_shape[2]))\n",
    "LSTM_questions = LSTM(hidden_units,return_state=True)\n",
    "LSTM_questions_output, questions_h, questions_c=LSTM_questions(LSTM_questions_inputs)\n",
    "questions_states= [questions_h,questions_c]\n",
    "    \n",
    "LSTM_facts_inputs = Input(shape=(None, facts_shape[2]))\n",
    "LSTM_facts = LSTM(hidden_units,return_state=True)\n",
    "LSTM_facts_output, facts_h, facts_c=LSTM_facts(LSTM_facts_inputs)\n",
    "facts_states= [facts_h,facts_c]\n",
    "    \n",
    "LSTM_rela_inputs = Input(shape=(None, relations_shape[2]))\n",
    "LSTM_rela = LSTM(hidden_units,return_state=True)\n",
    "LSTM_rela_output,rela_h,rela_c=LSTM_rela(LSTM_rela_inputs)\n",
    "rela_states= [rela_h,rela_c]\n",
    "    \n",
    "added_h = keras.layers.Add()([info_h,questions_h,facts_h,rela_h])\n",
    "added_c = keras.layers.Add()([info_c,questions_c,facts_c,rela_c])\n",
    "encoder_states = [added_h,added_c]\n",
    "    \n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, labels_index_len))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(labels_index_len, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define and compile model as previously\n",
    "model_T = Model([LSTM_info_inputs, LSTM_questions_inputs, LSTM_facts_inputs, \\\n",
    "                     LSTM_rela_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model_T.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Example inputs: X1 = \"There are four apples at the top of the tree.\" X2 = \"What do you need to get the apples?\"\n",
    "# X3 = \"Trees are high.\"  Label result = \"Trees -> High\"\n",
    "#Example inputs: X1 = \"There are four apples at the top of the tree.\" X2 = \"What do you need to get the apples?\"\n",
    "# X3 = \"Pick apples from tree.\"  Label result = \"Apples -> On tree\"\n",
    "#Example inputs: X1 = \"Apples->On tree, Tree->High\" X2 = \"What do you need to get the apples?\"\n",
    "# X3 = \"You can go on tree with a ladder.\"  Label result = \"Ladder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72 samples, validate on 8 samples\n",
      "Epoch 1/400\n",
      "72/72 [==============================] - 11s 155ms/step - loss: 2.4496 - acc: 0.0056 - val_loss: 2.1012 - val_acc: 0.8250\n",
      "Epoch 2/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 2.1761 - acc: 0.7111 - val_loss: 1.4683 - val_acc: 0.8250\n",
      "Epoch 3/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 1.6543 - acc: 0.7111 - val_loss: 0.7022 - val_acc: 0.8250\n",
      "Epoch 4/400\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 1.1788 - acc: 0.7111 - val_loss: 0.8736 - val_acc: 0.8750\n",
      "Epoch 5/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 1.0392 - acc: 0.7736 - val_loss: 0.5665 - val_acc: 0.8750\n",
      "Epoch 6/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.8632 - acc: 0.7736 - val_loss: 0.6898 - val_acc: 0.8000\n",
      "Epoch 7/400\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.8350 - acc: 0.7389 - val_loss: 0.5479 - val_acc: 0.8250\n",
      "Epoch 8/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.8512 - acc: 0.7111 - val_loss: 0.6369 - val_acc: 0.8125\n",
      "Epoch 9/400\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.7906 - acc: 0.7972 - val_loss: 0.5440 - val_acc: 0.8750\n",
      "Epoch 10/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.7756 - acc: 0.7736 - val_loss: 0.6193 - val_acc: 0.8125\n",
      "Epoch 11/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.7652 - acc: 0.7972 - val_loss: 0.5265 - val_acc: 0.8750\n",
      "Epoch 12/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.7666 - acc: 0.7736 - val_loss: 0.6476 - val_acc: 0.8125\n",
      "Epoch 13/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.7639 - acc: 0.7972 - val_loss: 0.5101 - val_acc: 0.8750\n",
      "Epoch 14/400\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.7786 - acc: 0.7736 - val_loss: 0.6343 - val_acc: 0.8125\n",
      "Epoch 15/400\n",
      "72/72 [==============================] - 3s 37ms/step - loss: 0.7500 - acc: 0.7972 - val_loss: 0.5086 - val_acc: 0.8750\n",
      "Epoch 16/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.7466 - acc: 0.7736 - val_loss: 0.6093 - val_acc: 0.8125\n",
      "Epoch 17/400\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.7333 - acc: 0.7972 - val_loss: 0.5095 - val_acc: 0.8750\n",
      "Epoch 18/400\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.7309 - acc: 0.7736 - val_loss: 0.6026 - val_acc: 0.8125\n",
      "Epoch 19/400\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.7244 - acc: 0.7972 - val_loss: 0.5023 - val_acc: 0.8750\n",
      "Epoch 20/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.7259 - acc: 0.7736 - val_loss: 0.6083 - val_acc: 0.8125\n",
      "Epoch 21/400\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.7208 - acc: 0.7972 - val_loss: 0.4929 - val_acc: 0.8750\n",
      "Epoch 22/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.7240 - acc: 0.7736 - val_loss: 0.6091 - val_acc: 0.8125\n",
      "Epoch 23/400\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.7155 - acc: 0.7972 - val_loss: 0.4870 - val_acc: 0.8750\n",
      "Epoch 24/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 0.7160 - acc: 0.7736 - val_loss: 0.5981 - val_acc: 0.8125\n",
      "Epoch 25/400\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.7062 - acc: 0.7972 - val_loss: 0.4861 - val_acc: 0.8750\n",
      "Epoch 26/400\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.7050 - acc: 0.7736 - val_loss: 0.5886 - val_acc: 0.8125\n",
      "Epoch 27/400\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.6982 - acc: 0.7972 - val_loss: 0.4844 - val_acc: 0.8750\n",
      "Epoch 28/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.6982 - acc: 0.7736 - val_loss: 0.5835 - val_acc: 0.8125\n",
      "Epoch 29/400\n",
      "72/72 [==============================] - 3s 37ms/step - loss: 0.6923 - acc: 0.7972 - val_loss: 0.4820 - val_acc: 0.8625\n",
      "Epoch 30/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.6930 - acc: 0.8014 - val_loss: 0.5754 - val_acc: 0.8125\n",
      "Epoch 31/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.6857 - acc: 0.7972 - val_loss: 0.4828 - val_acc: 0.8375\n",
      "Epoch 32/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.6852 - acc: 0.8042 - val_loss: 0.5618 - val_acc: 0.8125\n",
      "Epoch 33/400\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.6774 - acc: 0.7972 - val_loss: 0.4855 - val_acc: 0.8125\n",
      "Epoch 34/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.6757 - acc: 0.8014 - val_loss: 0.5506 - val_acc: 0.8125\n",
      "Epoch 35/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.6694 - acc: 0.7972 - val_loss: 0.4820 - val_acc: 0.8125\n",
      "Epoch 36/400\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.6682 - acc: 0.7972 - val_loss: 0.5515 - val_acc: 0.8125\n",
      "Epoch 37/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.6638 - acc: 0.7972 - val_loss: 0.4668 - val_acc: 0.8125\n",
      "Epoch 38/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.6659 - acc: 0.8014 - val_loss: 0.5771 - val_acc: 0.8125\n",
      "Epoch 39/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 0.6665 - acc: 0.7972 - val_loss: 0.4491 - val_acc: 0.8750\n",
      "Epoch 40/400\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.6849 - acc: 0.7736 - val_loss: 0.6166 - val_acc: 0.8125\n",
      "Epoch 41/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.6864 - acc: 0.7972 - val_loss: 0.4488 - val_acc: 0.8625\n",
      "Epoch 42/400\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.6663 - acc: 0.8014 - val_loss: 0.5437 - val_acc: 0.8125\n",
      "Epoch 43/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.6481 - acc: 0.7972 - val_loss: 0.4632 - val_acc: 0.8125\n",
      "Epoch 44/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.6409 - acc: 0.7972 - val_loss: 0.5225 - val_acc: 0.8125\n",
      "Epoch 45/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.6352 - acc: 0.7972 - val_loss: 0.4610 - val_acc: 0.8125\n",
      "Epoch 46/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.6328 - acc: 0.7972 - val_loss: 0.5250 - val_acc: 0.8125\n",
      "Epoch 47/400\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.6306 - acc: 0.7972 - val_loss: 0.4494 - val_acc: 0.8125\n",
      "Epoch 48/400\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.6336 - acc: 0.8000 - val_loss: 0.5424 - val_acc: 0.8125\n",
      "Epoch 49/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.6320 - acc: 0.7972 - val_loss: 0.4374 - val_acc: 0.8375\n",
      "Epoch 50/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.6368 - acc: 0.8042 - val_loss: 0.5401 - val_acc: 0.8125\n",
      "Epoch 51/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.6254 - acc: 0.7972 - val_loss: 0.4334 - val_acc: 0.8125\n",
      "Epoch 52/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.6235 - acc: 0.8014 - val_loss: 0.5261 - val_acc: 0.8125\n",
      "Epoch 53/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.6145 - acc: 0.7972 - val_loss: 0.4311 - val_acc: 0.8125\n",
      "Epoch 54/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.6133 - acc: 0.8014 - val_loss: 0.5266 - val_acc: 0.8125\n",
      "Epoch 55/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.6104 - acc: 0.7972 - val_loss: 0.4274 - val_acc: 0.8125\n",
      "Epoch 56/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.6061 - acc: 0.8014 - val_loss: 0.5171 - val_acc: 0.8125\n",
      "Epoch 57/400\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.6013 - acc: 0.7972 - val_loss: 0.4232 - val_acc: 0.8125\n",
      "Epoch 58/400\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.5970 - acc: 0.8014 - val_loss: 0.5097 - val_acc: 0.8375\n",
      "Epoch 59/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.5940 - acc: 0.8389 - val_loss: 0.4202 - val_acc: 0.8125\n",
      "Epoch 60/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.5972 - acc: 0.8014 - val_loss: 0.5154 - val_acc: 0.8375\n",
      "Epoch 61/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.5943 - acc: 0.8389 - val_loss: 0.4193 - val_acc: 0.8125\n",
      "Epoch 62/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.5966 - acc: 0.8014 - val_loss: 0.4968 - val_acc: 0.8375\n",
      "Epoch 63/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.5808 - acc: 0.8389 - val_loss: 0.4197 - val_acc: 0.8125\n",
      "Epoch 64/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 0.5757 - acc: 0.8014 - val_loss: 0.4801 - val_acc: 0.8375\n",
      "Epoch 65/400\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.5690 - acc: 0.8389 - val_loss: 0.4159 - val_acc: 0.8125\n",
      "Epoch 66/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.5662 - acc: 0.8014 - val_loss: 0.4774 - val_acc: 0.8375\n",
      "Epoch 67/400\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.5617 - acc: 0.8389 - val_loss: 0.4068 - val_acc: 0.8125\n",
      "Epoch 68/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.5613 - acc: 0.8014 - val_loss: 0.4872 - val_acc: 0.8375\n",
      "Epoch 69/400\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.5593 - acc: 0.8389 - val_loss: 0.3944 - val_acc: 0.8375\n",
      "Epoch 70/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.5633 - acc: 0.8042 - val_loss: 0.5010 - val_acc: 0.8125\n",
      "Epoch 71/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.5605 - acc: 0.8250 - val_loss: 0.3896 - val_acc: 0.8375\n",
      "Epoch 72/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.5607 - acc: 0.8042 - val_loss: 0.4876 - val_acc: 0.8125\n",
      "Epoch 73/400\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.5503 - acc: 0.8250 - val_loss: 0.3892 - val_acc: 0.8375\n",
      "Epoch 74/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.5434 - acc: 0.8042 - val_loss: 0.4690 - val_acc: 0.8375\n",
      "Epoch 75/400\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.5368 - acc: 0.8389 - val_loss: 0.3891 - val_acc: 0.8375\n",
      "Epoch 76/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.5349 - acc: 0.8347 - val_loss: 0.4639 - val_acc: 0.8375\n",
      "Epoch 77/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.5305 - acc: 0.8389 - val_loss: 0.3866 - val_acc: 0.8375\n",
      "Epoch 78/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 0.5300 - acc: 0.8347 - val_loss: 0.4603 - val_acc: 0.8125\n",
      "Epoch 79/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.5247 - acc: 0.8250 - val_loss: 0.3849 - val_acc: 0.8125\n",
      "Epoch 80/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.5256 - acc: 0.8014 - val_loss: 0.4590 - val_acc: 0.7875\n",
      "Epoch 81/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.5208 - acc: 0.8153 - val_loss: 0.3832 - val_acc: 0.8125\n",
      "Epoch 82/400\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.5209 - acc: 0.8014 - val_loss: 0.4539 - val_acc: 0.7875\n",
      "Epoch 83/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.5123 - acc: 0.8153 - val_loss: 0.3731 - val_acc: 0.8625\n",
      "Epoch 84/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.5107 - acc: 0.8375 - val_loss: 0.4536 - val_acc: 0.8125\n",
      "Epoch 85/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.5058 - acc: 0.8250 - val_loss: 0.3668 - val_acc: 0.8625\n",
      "Epoch 86/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.5054 - acc: 0.8417 - val_loss: 0.4539 - val_acc: 0.8125\n",
      "Epoch 87/400\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.5012 - acc: 0.8250 - val_loss: 0.3632 - val_acc: 0.8625\n",
      "Epoch 88/400\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.4996 - acc: 0.8458 - val_loss: 0.4441 - val_acc: 0.8125\n",
      "Epoch 89/400\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.4931 - acc: 0.8250 - val_loss: 0.3639 - val_acc: 0.8625\n",
      "Epoch 90/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.4912 - acc: 0.8458 - val_loss: 0.4363 - val_acc: 0.8125\n",
      "Epoch 91/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.4868 - acc: 0.8250 - val_loss: 0.3621 - val_acc: 0.8625\n",
      "Epoch 92/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.4874 - acc: 0.8417 - val_loss: 0.4341 - val_acc: 0.8125\n",
      "Epoch 93/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.4829 - acc: 0.8250 - val_loss: 0.3597 - val_acc: 0.8625\n",
      "Epoch 94/400\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.4828 - acc: 0.8417 - val_loss: 0.4282 - val_acc: 0.8125\n",
      "Epoch 95/400\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.4770 - acc: 0.8250 - val_loss: 0.3586 - val_acc: 0.8625\n",
      "Epoch 96/400\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.4759 - acc: 0.8458 - val_loss: 0.4205 - val_acc: 0.8125\n",
      "Epoch 97/400\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.4703 - acc: 0.8250 - val_loss: 0.3566 - val_acc: 0.8625\n",
      "Epoch 98/400\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.4701 - acc: 0.8458 - val_loss: 0.4114 - val_acc: 0.8375\n",
      "Epoch 99/400\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.4629 - acc: 0.8389 - val_loss: 0.3520 - val_acc: 0.8375\n",
      "Epoch 100/400\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.4619 - acc: 0.8431 - val_loss: 0.4109 - val_acc: 0.8250\n",
      "Epoch 101/400\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.4583 - acc: 0.8389 - val_loss: 0.3423 - val_acc: 0.8625\n",
      "Epoch 102/400\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.4611 - acc: 0.8417 - val_loss: 0.4371 - val_acc: 0.7750\n",
      "Epoch 103/400\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.4666 - acc: 0.8222 - val_loss: 0.3359 - val_acc: 0.8625\n",
      "Epoch 104/400\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.4661 - acc: 0.8014 - val_loss: 0.4266 - val_acc: 0.8000\n",
      "Epoch 105/400\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.4585 - acc: 0.8292 - val_loss: 0.3366 - val_acc: 0.8625\n",
      "Epoch 106/400\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.4512 - acc: 0.8458 - val_loss: 0.4012 - val_acc: 0.8500\n",
      "Epoch 107/400\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.4467 - acc: 0.8528 - val_loss: 0.3429 - val_acc: 0.8375\n",
      "Epoch 108/400\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.4474 - acc: 0.8431 - val_loss: 0.3909 - val_acc: 0.8500\n",
      "Epoch 109/400\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.4421 - acc: 0.8569 - val_loss: 0.3438 - val_acc: 0.8375\n",
      "Epoch 110/400\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.4416 - acc: 0.8431 - val_loss: 0.3823 - val_acc: 0.8500\n",
      "Epoch 111/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.4345 - acc: 0.8569 - val_loss: 0.3373 - val_acc: 0.8625\n",
      "Epoch 112/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.4336 - acc: 0.8458 - val_loss: 0.3868 - val_acc: 0.8500\n",
      "Epoch 113/400\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.4324 - acc: 0.8542 - val_loss: 0.3287 - val_acc: 0.8625\n",
      "Epoch 114/400\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.4353 - acc: 0.8417 - val_loss: 0.4030 - val_acc: 0.8250\n",
      "Epoch 115/400\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.4375 - acc: 0.8403 - val_loss: 0.3229 - val_acc: 0.8625\n",
      "Epoch 116/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.4375 - acc: 0.8375 - val_loss: 0.4017 - val_acc: 0.8250\n",
      "Epoch 117/400\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.4335 - acc: 0.8403 - val_loss: 0.3197 - val_acc: 0.8625\n",
      "Epoch 118/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.4267 - acc: 0.8458 - val_loss: 0.3834 - val_acc: 0.8500\n",
      "Epoch 119/400\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.4224 - acc: 0.8611 - val_loss: 0.3222 - val_acc: 0.8625\n",
      "Epoch 120/400\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.4209 - acc: 0.8458 - val_loss: 0.3726 - val_acc: 0.8500\n",
      "Epoch 121/400\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.4195 - acc: 0.8653 - val_loss: 0.3280 - val_acc: 0.8375\n",
      "Epoch 122/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.4210 - acc: 0.8431 - val_loss: 0.3617 - val_acc: 0.8500\n",
      "Epoch 123/400\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.4150 - acc: 0.8653 - val_loss: 0.3275 - val_acc: 0.8375\n",
      "Epoch 124/400\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.4135 - acc: 0.8431 - val_loss: 0.3585 - val_acc: 0.8500\n",
      "Epoch 125/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.4351 - acc: 0.8611 - val_loss: 0.3280 - val_acc: 0.8375\n",
      "Epoch 126/400\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.4076 - acc: 0.8431 - val_loss: 0.3418 - val_acc: 0.8500\n",
      "Epoch 127/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.4001 - acc: 0.8653 - val_loss: 0.3245 - val_acc: 0.8375\n",
      "Epoch 128/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.3976 - acc: 0.8431 - val_loss: 0.3396 - val_acc: 0.8500\n",
      "Epoch 129/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3964 - acc: 0.8653 - val_loss: 0.3144 - val_acc: 0.8625\n",
      "Epoch 130/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.4002 - acc: 0.8458 - val_loss: 0.3920 - val_acc: 0.8125\n",
      "Epoch 131/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.4228 - acc: 0.8597 - val_loss: 0.3118 - val_acc: 0.8750\n",
      "Epoch 132/400\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.4595 - acc: 0.7736 - val_loss: 0.4223 - val_acc: 0.8125\n",
      "Epoch 133/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.4355 - acc: 0.8472 - val_loss: 0.3067 - val_acc: 0.8625\n",
      "Epoch 134/400\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.4010 - acc: 0.8458 - val_loss: 0.3441 - val_acc: 0.8500\n",
      "Epoch 135/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.3899 - acc: 0.8653 - val_loss: 0.3153 - val_acc: 0.8750\n",
      "Epoch 136/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.3860 - acc: 0.8667 - val_loss: 0.3293 - val_acc: 0.8500\n",
      "Epoch 137/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.3838 - acc: 0.8653 - val_loss: 0.3157 - val_acc: 0.8500\n",
      "Epoch 138/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.3822 - acc: 0.8639 - val_loss: 0.3262 - val_acc: 0.8500\n",
      "Epoch 139/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3811 - acc: 0.8667 - val_loss: 0.3126 - val_acc: 0.8750\n",
      "Epoch 140/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3810 - acc: 0.8597 - val_loss: 0.3312 - val_acc: 0.8500\n",
      "Epoch 141/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3824 - acc: 0.8653 - val_loss: 0.3088 - val_acc: 0.8625\n",
      "Epoch 142/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.4258 - acc: 0.8333 - val_loss: 0.3135 - val_acc: 0.8750\n",
      "Epoch 143/400\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.3759 - acc: 0.8667 - val_loss: 0.3225 - val_acc: 0.8500\n",
      "Epoch 144/400\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.3735 - acc: 0.8667 - val_loss: 0.3022 - val_acc: 0.8750\n",
      "Epoch 145/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.3742 - acc: 0.8667 - val_loss: 0.3614 - val_acc: 0.8375\n",
      "Epoch 146/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.3939 - acc: 0.8625 - val_loss: 0.3010 - val_acc: 0.8750\n",
      "Epoch 147/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.4541 - acc: 0.7792 - val_loss: 0.4567 - val_acc: 0.7750\n",
      "Epoch 148/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.4952 - acc: 0.8083 - val_loss: 0.2994 - val_acc: 0.8875\n",
      "Epoch 149/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.3949 - acc: 0.8472 - val_loss: 0.3087 - val_acc: 0.8750\n",
      "Epoch 150/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3691 - acc: 0.8778 - val_loss: 0.2971 - val_acc: 0.8750\n",
      "Epoch 151/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.3621 - acc: 0.8694 - val_loss: 0.3007 - val_acc: 0.8750\n",
      "Epoch 152/400\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.3581 - acc: 0.8792 - val_loss: 0.2960 - val_acc: 0.8750\n",
      "Epoch 153/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3555 - acc: 0.8792 - val_loss: 0.3006 - val_acc: 0.8750\n",
      "Epoch 154/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3562 - acc: 0.8722 - val_loss: 0.2855 - val_acc: 0.9000\n",
      "Epoch 155/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.3549 - acc: 0.8708 - val_loss: 0.3087 - val_acc: 0.8750\n",
      "Epoch 156/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.3552 - acc: 0.8778 - val_loss: 0.2796 - val_acc: 0.9000\n",
      "Epoch 157/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.3581 - acc: 0.8708 - val_loss: 0.3311 - val_acc: 0.8500\n",
      "Epoch 158/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3668 - acc: 0.8708 - val_loss: 0.2810 - val_acc: 0.9000\n",
      "Epoch 159/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 0.4010 - acc: 0.8389 - val_loss: 0.3241 - val_acc: 0.8500\n",
      "Epoch 160/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3647 - acc: 0.8750 - val_loss: 0.2869 - val_acc: 0.8875\n",
      "Epoch 161/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.3595 - acc: 0.8639 - val_loss: 0.3170 - val_acc: 0.8750\n",
      "Epoch 162/400\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.3587 - acc: 0.8736 - val_loss: 0.2807 - val_acc: 0.8875\n",
      "Epoch 163/400\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.3561 - acc: 0.8639 - val_loss: 0.3189 - val_acc: 0.8750\n",
      "Epoch 164/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.3569 - acc: 0.8736 - val_loss: 0.2800 - val_acc: 0.8875\n",
      "Epoch 165/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.3552 - acc: 0.8639 - val_loss: 0.3084 - val_acc: 0.8750\n",
      "Epoch 166/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3505 - acc: 0.8736 - val_loss: 0.2798 - val_acc: 0.8875\n",
      "Epoch 167/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.3467 - acc: 0.8639 - val_loss: 0.2982 - val_acc: 0.8750\n",
      "Epoch 168/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.3426 - acc: 0.8750 - val_loss: 0.2792 - val_acc: 0.9000\n",
      "Epoch 169/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3405 - acc: 0.8694 - val_loss: 0.2956 - val_acc: 0.8750\n",
      "Epoch 170/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.3391 - acc: 0.8750 - val_loss: 0.2772 - val_acc: 0.9000\n",
      "Epoch 171/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.3390 - acc: 0.8708 - val_loss: 0.3058 - val_acc: 0.8750\n",
      "Epoch 172/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3430 - acc: 0.8736 - val_loss: 0.2785 - val_acc: 0.8875\n",
      "Epoch 173/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3516 - acc: 0.8611 - val_loss: 0.3324 - val_acc: 0.8500\n",
      "Epoch 174/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.3649 - acc: 0.8681 - val_loss: 0.2830 - val_acc: 0.9000\n",
      "Epoch 175/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.3573 - acc: 0.8431 - val_loss: 0.3080 - val_acc: 0.8750\n",
      "Epoch 176/400\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.3451 - acc: 0.8736 - val_loss: 0.2775 - val_acc: 0.9000\n",
      "Epoch 177/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3365 - acc: 0.8722 - val_loss: 0.2958 - val_acc: 0.8750\n",
      "Epoch 178/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.3333 - acc: 0.8764 - val_loss: 0.2776 - val_acc: 0.9000\n",
      "Epoch 179/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3328 - acc: 0.8694 - val_loss: 0.2985 - val_acc: 0.8750\n",
      "Epoch 180/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.3350 - acc: 0.8778 - val_loss: 0.2739 - val_acc: 0.8875\n",
      "Epoch 181/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 0.3371 - acc: 0.8639 - val_loss: 0.3409 - val_acc: 0.8500\n",
      "Epoch 182/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.3651 - acc: 0.8792 - val_loss: 0.2692 - val_acc: 0.9000\n",
      "Epoch 183/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3299 - acc: 0.8722 - val_loss: 0.3061 - val_acc: 0.8750\n",
      "Epoch 184/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3294 - acc: 0.8764 - val_loss: 0.2667 - val_acc: 0.8875\n",
      "Epoch 185/400\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3262 - acc: 0.8792 - val_loss: 0.2957 - val_acc: 0.8750\n",
      "Epoch 186/400\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.3292 - acc: 0.8750 - val_loss: 0.2757 - val_acc: 0.9000\n",
      "Epoch 187/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.3265 - acc: 0.8736 - val_loss: 0.3084 - val_acc: 0.8500\n",
      "Epoch 188/400\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.3438 - acc: 0.8736 - val_loss: 0.2786 - val_acc: 0.9000\n",
      "Epoch 189/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3447 - acc: 0.8486 - val_loss: 0.3148 - val_acc: 0.8500\n",
      "Epoch 190/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3372 - acc: 0.8764 - val_loss: 0.2677 - val_acc: 0.9000\n",
      "Epoch 191/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.3195 - acc: 0.8792 - val_loss: 0.2821 - val_acc: 0.8750\n",
      "Epoch 192/400\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.3164 - acc: 0.8806 - val_loss: 0.2701 - val_acc: 0.9000\n",
      "Epoch 193/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3125 - acc: 0.8903 - val_loss: 0.2791 - val_acc: 0.8750\n",
      "Epoch 194/400\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.3105 - acc: 0.8806 - val_loss: 0.2686 - val_acc: 0.9000\n",
      "Epoch 195/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.3096 - acc: 0.8903 - val_loss: 0.2770 - val_acc: 0.8750\n",
      "Epoch 196/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 0.3097 - acc: 0.8806 - val_loss: 0.2716 - val_acc: 0.9000\n",
      "Epoch 197/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.3111 - acc: 0.8972 - val_loss: 0.2796 - val_acc: 0.8750\n",
      "Epoch 198/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3168 - acc: 0.8792 - val_loss: 0.2757 - val_acc: 0.9000\n",
      "Epoch 199/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3216 - acc: 0.8847 - val_loss: 0.2852 - val_acc: 0.8750\n",
      "Epoch 200/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.3234 - acc: 0.8819 - val_loss: 0.2923 - val_acc: 0.8750\n",
      "Epoch 201/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.3329 - acc: 0.8764 - val_loss: 0.2683 - val_acc: 0.9000\n",
      "Epoch 202/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.3342 - acc: 0.8722 - val_loss: 0.3021 - val_acc: 0.8750\n",
      "Epoch 203/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.3362 - acc: 0.8750 - val_loss: 0.2723 - val_acc: 0.9000\n",
      "Epoch 204/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.3366 - acc: 0.8528 - val_loss: 0.2982 - val_acc: 0.8750\n",
      "Epoch 205/400\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.3128 - acc: 0.8806 - val_loss: 0.2638 - val_acc: 0.9000\n",
      "Epoch 206/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.3206 - acc: 0.8736 - val_loss: 0.2929 - val_acc: 0.8750\n",
      "Epoch 207/400\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.3107 - acc: 0.8778 - val_loss: 0.2634 - val_acc: 0.9000\n",
      "Epoch 208/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3008 - acc: 0.8903 - val_loss: 0.2746 - val_acc: 0.8750\n",
      "Epoch 209/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2974 - acc: 0.8819 - val_loss: 0.2607 - val_acc: 0.9000\n",
      "Epoch 210/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2953 - acc: 0.8917 - val_loss: 0.2700 - val_acc: 0.8750\n",
      "Epoch 211/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.2944 - acc: 0.8819 - val_loss: 0.2596 - val_acc: 0.9000\n",
      "Epoch 212/400\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.2942 - acc: 0.8944 - val_loss: 0.2722 - val_acc: 0.8750\n",
      "Epoch 213/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2978 - acc: 0.8833 - val_loss: 0.2617 - val_acc: 0.9000\n",
      "Epoch 214/400\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.2973 - acc: 0.8931 - val_loss: 0.2719 - val_acc: 0.8750\n",
      "Epoch 215/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.2988 - acc: 0.8806 - val_loss: 0.2659 - val_acc: 0.9000\n",
      "Epoch 216/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.2990 - acc: 0.8944 - val_loss: 0.2683 - val_acc: 0.9000\n",
      "Epoch 217/400\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.2989 - acc: 0.8875 - val_loss: 0.2633 - val_acc: 0.9000\n",
      "Epoch 218/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.2983 - acc: 0.8944 - val_loss: 0.2867 - val_acc: 0.8750\n",
      "Epoch 219/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.3025 - acc: 0.8806 - val_loss: 0.2687 - val_acc: 0.9000\n",
      "Epoch 220/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.3087 - acc: 0.8597 - val_loss: 0.3037 - val_acc: 0.8750\n",
      "Epoch 221/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.3150 - acc: 0.8819 - val_loss: 0.2576 - val_acc: 0.9000\n",
      "Epoch 222/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.3038 - acc: 0.8556 - val_loss: 0.2724 - val_acc: 0.8750\n",
      "Epoch 223/400\n",
      "72/72 [==============================] - 6s 89ms/step - loss: 0.2912 - acc: 0.8861 - val_loss: 0.2531 - val_acc: 0.9000\n",
      "Epoch 224/400\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.2906 - acc: 0.8792 - val_loss: 0.3032 - val_acc: 0.8625\n",
      "Epoch 225/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.3196 - acc: 0.8653 - val_loss: 0.2563 - val_acc: 0.9000\n",
      "Epoch 226/400\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.3056 - acc: 0.8722 - val_loss: 0.2685 - val_acc: 0.9000\n",
      "Epoch 227/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2946 - acc: 0.8903 - val_loss: 0.2567 - val_acc: 0.9000\n",
      "Epoch 228/400\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.2892 - acc: 0.8889 - val_loss: 0.2650 - val_acc: 0.8750\n",
      "Epoch 229/400\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.2815 - acc: 0.8861 - val_loss: 0.2622 - val_acc: 0.9000\n",
      "Epoch 230/400\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.2833 - acc: 0.8931 - val_loss: 0.2557 - val_acc: 0.9000\n",
      "Epoch 231/400\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.2889 - acc: 0.8931 - val_loss: 0.2664 - val_acc: 0.9000\n",
      "Epoch 232/400\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.2811 - acc: 0.8958 - val_loss: 0.2520 - val_acc: 0.9000\n",
      "Epoch 233/400\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.2780 - acc: 0.8944 - val_loss: 0.2589 - val_acc: 0.9000\n",
      "Epoch 234/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.2801 - acc: 0.8903 - val_loss: 0.2594 - val_acc: 0.9000\n",
      "Epoch 235/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.2853 - acc: 0.8958 - val_loss: 0.2651 - val_acc: 0.8750\n",
      "Epoch 236/400\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.2952 - acc: 0.8847 - val_loss: 0.2630 - val_acc: 0.9000\n",
      "Epoch 237/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.2922 - acc: 0.8806 - val_loss: 0.2781 - val_acc: 0.8750\n",
      "Epoch 238/400\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.2911 - acc: 0.8833 - val_loss: 0.2564 - val_acc: 0.9125\n",
      "Epoch 239/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2899 - acc: 0.8708 - val_loss: 0.2910 - val_acc: 0.8750\n",
      "Epoch 240/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2881 - acc: 0.8875 - val_loss: 0.2437 - val_acc: 0.9125\n",
      "Epoch 241/400\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.2826 - acc: 0.8806 - val_loss: 0.2661 - val_acc: 0.8750\n",
      "Epoch 242/400\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.2761 - acc: 0.8972 - val_loss: 0.2477 - val_acc: 0.9000\n",
      "Epoch 243/400\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.2727 - acc: 0.8958 - val_loss: 0.2889 - val_acc: 0.8875\n",
      "Epoch 244/400\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.2725 - acc: 0.8958 - val_loss: 0.2480 - val_acc: 0.9000\n",
      "Epoch 245/400\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.2813 - acc: 0.8847 - val_loss: 0.2919 - val_acc: 0.8750\n",
      "Epoch 246/400\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.2840 - acc: 0.8958 - val_loss: 0.2488 - val_acc: 0.9000\n",
      "Epoch 247/400\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.2843 - acc: 0.8889 - val_loss: 0.3062 - val_acc: 0.8625\n",
      "Epoch 248/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.3138 - acc: 0.8639 - val_loss: 0.2560 - val_acc: 0.9000\n",
      "Epoch 249/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3019 - acc: 0.8722 - val_loss: 0.2783 - val_acc: 0.8750\n",
      "Epoch 250/400\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2959 - acc: 0.8806 - val_loss: 0.2529 - val_acc: 0.9125\n",
      "Epoch 251/400\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2940 - acc: 0.8667 - val_loss: 0.2673 - val_acc: 0.8750\n",
      "Epoch 252/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2768 - acc: 0.8889 - val_loss: 0.2479 - val_acc: 0.9000\n",
      "Epoch 253/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.2709 - acc: 0.9000 - val_loss: 0.2587 - val_acc: 0.9000\n",
      "Epoch 254/400\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.2676 - acc: 0.8944 - val_loss: 0.2441 - val_acc: 0.9000\n",
      "Epoch 255/400\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.2649 - acc: 0.9000 - val_loss: 0.2532 - val_acc: 0.9000\n",
      "Epoch 256/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2631 - acc: 0.8958 - val_loss: 0.2449 - val_acc: 0.9000\n",
      "Epoch 257/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2617 - acc: 0.8986 - val_loss: 0.2505 - val_acc: 0.9000\n",
      "Epoch 258/400\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.2609 - acc: 0.8986 - val_loss: 0.2445 - val_acc: 0.9000\n",
      "Epoch 259/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2604 - acc: 0.8986 - val_loss: 0.2504 - val_acc: 0.9000\n",
      "Epoch 260/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2603 - acc: 0.9014 - val_loss: 0.2437 - val_acc: 0.9000\n",
      "Epoch 261/400\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.2604 - acc: 0.9000 - val_loss: 0.2524 - val_acc: 0.9000\n",
      "Epoch 262/400\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.2619 - acc: 0.8986 - val_loss: 0.2446 - val_acc: 0.9000\n",
      "Epoch 263/400\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.2629 - acc: 0.9000 - val_loss: 0.2611 - val_acc: 0.8750\n",
      "Epoch 264/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 0.2666 - acc: 0.8903 - val_loss: 0.2504 - val_acc: 0.9125\n",
      "Epoch 265/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.2700 - acc: 0.8889 - val_loss: 0.2608 - val_acc: 0.8750\n",
      "Epoch 266/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2721 - acc: 0.8861 - val_loss: 0.2514 - val_acc: 0.9000\n",
      "Epoch 267/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.2714 - acc: 0.8861 - val_loss: 0.2627 - val_acc: 0.8750\n",
      "Epoch 268/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.2658 - acc: 0.8903 - val_loss: 0.2411 - val_acc: 0.9125\n",
      "Epoch 269/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.2662 - acc: 0.8861 - val_loss: 0.2647 - val_acc: 0.8750\n",
      "Epoch 270/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.2608 - acc: 0.8972 - val_loss: 0.2393 - val_acc: 0.9000\n",
      "Epoch 271/400\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2576 - acc: 0.9014 - val_loss: 0.2512 - val_acc: 0.9000\n",
      "Epoch 272/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2553 - acc: 0.9000 - val_loss: 0.2395 - val_acc: 0.9000\n",
      "Epoch 273/400\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.2550 - acc: 0.9028 - val_loss: 0.2510 - val_acc: 0.9000\n",
      "Epoch 274/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2564 - acc: 0.9000 - val_loss: 0.2372 - val_acc: 0.9000\n",
      "Epoch 275/400\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.2592 - acc: 0.8917 - val_loss: 0.2561 - val_acc: 0.9000\n",
      "Epoch 276/400\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.2564 - acc: 0.8972 - val_loss: 0.2365 - val_acc: 0.9000\n",
      "Epoch 277/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2543 - acc: 0.9000 - val_loss: 0.2499 - val_acc: 0.9000\n",
      "Epoch 278/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2527 - acc: 0.9000 - val_loss: 0.2370 - val_acc: 0.9000\n",
      "Epoch 279/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2521 - acc: 0.9042 - val_loss: 0.2502 - val_acc: 0.9000\n",
      "Epoch 280/400\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.2515 - acc: 0.8986 - val_loss: 0.2350 - val_acc: 0.9000\n",
      "Epoch 281/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2504 - acc: 0.9028 - val_loss: 0.2518 - val_acc: 0.9000\n",
      "Epoch 282/400\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2500 - acc: 0.9014 - val_loss: 0.2341 - val_acc: 0.9000\n",
      "Epoch 283/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.2506 - acc: 0.9042 - val_loss: 0.2565 - val_acc: 0.9000\n",
      "Epoch 284/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2533 - acc: 0.9028 - val_loss: 0.2385 - val_acc: 0.9125\n",
      "Epoch 285/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2551 - acc: 0.8958 - val_loss: 0.2671 - val_acc: 0.8750\n",
      "Epoch 286/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2692 - acc: 0.8931 - val_loss: 0.2694 - val_acc: 0.9000\n",
      "Epoch 287/400\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.2861 - acc: 0.8792 - val_loss: 0.2616 - val_acc: 0.8875\n",
      "Epoch 288/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2763 - acc: 0.8861 - val_loss: 0.2484 - val_acc: 0.9125\n",
      "Epoch 289/400\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.2543 - acc: 0.8931 - val_loss: 0.2498 - val_acc: 0.9000\n",
      "Epoch 290/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2466 - acc: 0.9056 - val_loss: 0.2407 - val_acc: 0.9000\n",
      "Epoch 291/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2447 - acc: 0.9069 - val_loss: 0.2462 - val_acc: 0.9000\n",
      "Epoch 292/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2437 - acc: 0.9083 - val_loss: 0.2418 - val_acc: 0.9000\n",
      "Epoch 293/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2430 - acc: 0.9069 - val_loss: 0.2428 - val_acc: 0.9000\n",
      "Epoch 294/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2425 - acc: 0.9083 - val_loss: 0.2416 - val_acc: 0.9000\n",
      "Epoch 295/400\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.2423 - acc: 0.9056 - val_loss: 0.2421 - val_acc: 0.9000\n",
      "Epoch 296/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2424 - acc: 0.9069 - val_loss: 0.2424 - val_acc: 0.9000\n",
      "Epoch 297/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2435 - acc: 0.9042 - val_loss: 0.2434 - val_acc: 0.9000\n",
      "Epoch 298/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2454 - acc: 0.9028 - val_loss: 0.2447 - val_acc: 0.9000\n",
      "Epoch 299/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2483 - acc: 0.9042 - val_loss: 0.2428 - val_acc: 0.9000\n",
      "Epoch 300/400\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2456 - acc: 0.9028 - val_loss: 0.2426 - val_acc: 0.9000\n",
      "Epoch 301/400\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2453 - acc: 0.9042 - val_loss: 0.2431 - val_acc: 0.9000\n",
      "Epoch 302/400\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2430 - acc: 0.9028 - val_loss: 0.2395 - val_acc: 0.9000\n",
      "Epoch 303/400\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2442 - acc: 0.9042 - val_loss: 0.2465 - val_acc: 0.9000\n",
      "Epoch 304/400\n",
      "72/72 [==============================] - 3s 41ms/step - loss: 0.2462 - acc: 0.9000 - val_loss: 0.2334 - val_acc: 0.9000\n",
      "Epoch 305/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2435 - acc: 0.9042 - val_loss: 0.2526 - val_acc: 0.9000\n",
      "Epoch 306/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 0.2416 - acc: 0.9056 - val_loss: 0.2323 - val_acc: 0.9125\n",
      "Epoch 307/400\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.2442 - acc: 0.8986 - val_loss: 0.2630 - val_acc: 0.8750\n",
      "Epoch 308/400\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.2492 - acc: 0.9014 - val_loss: 0.2542 - val_acc: 0.9125\n",
      "Epoch 309/400\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.2643 - acc: 0.8931 - val_loss: 0.2628 - val_acc: 0.8750\n",
      "Epoch 310/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2720 - acc: 0.8875 - val_loss: 0.2546 - val_acc: 0.9125\n",
      "Epoch 311/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2541 - acc: 0.8931 - val_loss: 0.2469 - val_acc: 0.9000\n",
      "Epoch 312/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2437 - acc: 0.9069 - val_loss: 0.2421 - val_acc: 0.9000\n",
      "Epoch 313/400\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.2376 - acc: 0.9056 - val_loss: 0.2403 - val_acc: 0.9000\n",
      "Epoch 314/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2359 - acc: 0.9097 - val_loss: 0.2401 - val_acc: 0.9000\n",
      "Epoch 315/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2351 - acc: 0.9097 - val_loss: 0.2393 - val_acc: 0.9000\n",
      "Epoch 316/400\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2347 - acc: 0.9097 - val_loss: 0.2392 - val_acc: 0.9000\n",
      "Epoch 317/400\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2343 - acc: 0.9097 - val_loss: 0.2393 - val_acc: 0.9000\n",
      "Epoch 318/400\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2344 - acc: 0.9097 - val_loss: 0.2383 - val_acc: 0.9000\n",
      "Epoch 319/400\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2352 - acc: 0.9083 - val_loss: 0.2421 - val_acc: 0.9000\n",
      "Epoch 320/400\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2385 - acc: 0.9069 - val_loss: 0.2376 - val_acc: 0.9000\n",
      "Epoch 321/400\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2416 - acc: 0.9056 - val_loss: 0.2468 - val_acc: 0.9000\n",
      "Epoch 322/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2463 - acc: 0.9028 - val_loss: 0.2349 - val_acc: 0.9000\n",
      "Epoch 323/400\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.2376 - acc: 0.9097 - val_loss: 0.2420 - val_acc: 0.9000\n",
      "Epoch 324/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2374 - acc: 0.9042 - val_loss: 0.2484 - val_acc: 0.8750\n",
      "Epoch 325/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2427 - acc: 0.9028 - val_loss: 0.2478 - val_acc: 0.9125\n",
      "Epoch 326/400\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.2475 - acc: 0.8958 - val_loss: 0.2820 - val_acc: 0.8875\n",
      "Epoch 327/400\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.2473 - acc: 0.9000 - val_loss: 0.2447 - val_acc: 0.9125\n",
      "Epoch 328/400\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.2418 - acc: 0.8972 - val_loss: 0.2443 - val_acc: 0.9000\n",
      "Epoch 329/400\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.2375 - acc: 0.9069 - val_loss: 0.2394 - val_acc: 0.9000\n",
      "Epoch 330/400\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.2347 - acc: 0.9056 - val_loss: 0.2425 - val_acc: 0.9000\n",
      "Epoch 331/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2335 - acc: 0.9069 - val_loss: 0.2605 - val_acc: 0.8875\n",
      "Epoch 332/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2324 - acc: 0.9083 - val_loss: 0.2439 - val_acc: 0.8750\n",
      "Epoch 333/400\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2324 - acc: 0.9069 - val_loss: 0.2879 - val_acc: 0.8625\n",
      "Epoch 334/400\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2322 - acc: 0.9056 - val_loss: 0.2758 - val_acc: 0.8500\n",
      "Epoch 335/400\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2332 - acc: 0.9069 - val_loss: 0.2966 - val_acc: 0.8750\n",
      "Epoch 336/400\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2336 - acc: 0.9056 - val_loss: 0.2344 - val_acc: 0.9000\n",
      "Epoch 337/400\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2351 - acc: 0.9056 - val_loss: 0.3061 - val_acc: 0.8500\n",
      "Epoch 338/400\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2346 - acc: 0.9056 - val_loss: 0.2309 - val_acc: 0.9000\n",
      "Epoch 339/400\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.2356 - acc: 0.9083 - val_loss: 0.3154 - val_acc: 0.8500\n",
      "Epoch 340/400\n",
      "72/72 [==============================] - 5s 73ms/step - loss: 0.2354 - acc: 0.9042 - val_loss: 0.2666 - val_acc: 0.8500\n",
      "Epoch 341/400\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.2358 - acc: 0.9000 - val_loss: 0.3164 - val_acc: 0.8500\n",
      "Epoch 342/400\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.2374 - acc: 0.9028 - val_loss: 0.2326 - val_acc: 0.9125\n",
      "Epoch 343/400\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.2402 - acc: 0.8972 - val_loss: 0.3161 - val_acc: 0.8375\n",
      "Epoch 344/400\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.2438 - acc: 0.8986 - val_loss: 0.2418 - val_acc: 0.9000\n",
      "Epoch 345/400\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.2396 - acc: 0.8958 - val_loss: 0.3018 - val_acc: 0.8375\n",
      "Epoch 346/400\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 0.2368 - acc: 0.9042 - val_loss: 0.2417 - val_acc: 0.9000\n",
      "Epoch 347/400\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2370 - acc: 0.9056 - val_loss: 0.3033 - val_acc: 0.8625\n",
      "Epoch 348/400\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.2364 - acc: 0.9069 - val_loss: 0.2393 - val_acc: 0.9000\n",
      "Epoch 349/400\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2359 - acc: 0.9042 - val_loss: 0.2456 - val_acc: 0.9000\n",
      "Epoch 350/400\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2375 - acc: 0.9042 - val_loss: 0.2333 - val_acc: 0.9000\n",
      "Epoch 351/400\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2330 - acc: 0.9097 - val_loss: 0.2341 - val_acc: 0.9000\n",
      "Epoch 352/400\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2297 - acc: 0.9083 - val_loss: 0.2415 - val_acc: 0.9000\n",
      "Epoch 353/400\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.2283 - acc: 0.9097 - val_loss: 0.2363 - val_acc: 0.9000\n",
      "Epoch 354/400\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.2284 - acc: 0.9083 - val_loss: 0.2393 - val_acc: 0.9000\n",
      "Epoch 355/400\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.2277 - acc: 0.9097 - val_loss: 0.2367 - val_acc: 0.9000\n",
      "Epoch 356/400\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.2277 - acc: 0.9083 - val_loss: 0.2382 - val_acc: 0.9000\n",
      "Epoch 357/400\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.2269 - acc: 0.9097 - val_loss: 0.2359 - val_acc: 0.9000\n",
      "Epoch 358/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.2269 - acc: 0.9083 - val_loss: 0.2382 - val_acc: 0.9000\n",
      "Epoch 359/400\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.2264 - acc: 0.9097 - val_loss: 0.2355 - val_acc: 0.9000\n",
      "Epoch 360/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.2269 - acc: 0.9083 - val_loss: 0.2403 - val_acc: 0.9000\n",
      "Epoch 361/400\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.2277 - acc: 0.9111 - val_loss: 0.2324 - val_acc: 0.9000\n",
      "Epoch 362/400\n",
      "72/72 [==============================] - 5s 69ms/step - loss: 0.2310 - acc: 0.9014 - val_loss: 0.3171 - val_acc: 0.8375\n",
      "Epoch 363/400\n",
      "72/72 [==============================] - 5s 74ms/step - loss: 0.2390 - acc: 0.9014 - val_loss: 0.2765 - val_acc: 0.8625\n",
      "Epoch 364/400\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.2432 - acc: 0.8958 - val_loss: 0.3122 - val_acc: 0.8375\n",
      "Epoch 365/400\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2389 - acc: 0.9042 - val_loss: 0.2917 - val_acc: 0.8625\n",
      "Epoch 366/400\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2310 - acc: 0.8986 - val_loss: 0.2394 - val_acc: 0.9000\n",
      "Epoch 367/400\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2490 - acc: 0.8986 - val_loss: 0.2386 - val_acc: 0.9000\n",
      "Epoch 368/400\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2268 - acc: 0.9056 - val_loss: 0.2344 - val_acc: 0.9000\n",
      "Epoch 369/400\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2241 - acc: 0.9097 - val_loss: 0.2378 - val_acc: 0.9000\n",
      "Epoch 370/400\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2231 - acc: 0.9097 - val_loss: 0.2348 - val_acc: 0.9000\n",
      "Epoch 371/400\n",
      "72/72 [==============================] - 4s 59ms/step - loss: 0.2227 - acc: 0.9097 - val_loss: 0.2379 - val_acc: 0.9000\n",
      "Epoch 372/400\n",
      "72/72 [==============================] - 4s 62ms/step - loss: 0.2225 - acc: 0.9097 - val_loss: 0.2909 - val_acc: 0.9000\n",
      "Epoch 373/400\n",
      "72/72 [==============================] - 4s 61ms/step - loss: 0.2955 - acc: 0.8833 - val_loss: 0.2364 - val_acc: 0.9000\n",
      "Epoch 374/400\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.2430 - acc: 0.9069 - val_loss: 0.2540 - val_acc: 0.9000\n",
      "Epoch 375/400\n",
      "72/72 [==============================] - 5s 63ms/step - loss: 0.2431 - acc: 0.9069 - val_loss: 0.2315 - val_acc: 0.9000\n",
      "Epoch 376/400\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.2430 - acc: 0.9014 - val_loss: 0.2495 - val_acc: 0.9000\n",
      "Epoch 377/400\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.2400 - acc: 0.9056 - val_loss: 0.2318 - val_acc: 0.9000\n",
      "Epoch 378/400\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.2431 - acc: 0.9056 - val_loss: 0.2441 - val_acc: 0.9000\n",
      "Epoch 379/400\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.2623 - acc: 0.8917 - val_loss: 0.2518 - val_acc: 0.8750\n",
      "Epoch 380/400\n",
      "72/72 [==============================] - 5s 64ms/step - loss: 0.2642 - acc: 0.8931 - val_loss: 0.2420 - val_acc: 0.9125\n",
      "Epoch 381/400\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2372 - acc: 0.8972 - val_loss: 0.2395 - val_acc: 0.9000\n",
      "Epoch 382/400\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2266 - acc: 0.9097 - val_loss: 0.2356 - val_acc: 0.9000\n",
      "Epoch 383/400\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2237 - acc: 0.9097 - val_loss: 0.2560 - val_acc: 0.9000\n",
      "Epoch 384/400\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2228 - acc: 0.9097 - val_loss: 0.2733 - val_acc: 0.8875\n",
      "Epoch 385/400\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.2222 - acc: 0.9097 - val_loss: 0.3388 - val_acc: 0.8375\n",
      "Epoch 386/400\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2239 - acc: 0.9097 - val_loss: 0.2317 - val_acc: 0.9000\n",
      "Epoch 387/400\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2490 - acc: 0.8972 - val_loss: 0.2439 - val_acc: 0.9000\n",
      "Epoch 388/400\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.2449 - acc: 0.8986 - val_loss: 0.2291 - val_acc: 0.9000\n",
      "Epoch 389/400\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.2411 - acc: 0.8972 - val_loss: 0.2442 - val_acc: 0.8750\n",
      "Epoch 390/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.2403 - acc: 0.9014 - val_loss: 0.2306 - val_acc: 0.9125\n",
      "Epoch 391/400\n",
      "72/72 [==============================] - 5s 67ms/step - loss: 0.2390 - acc: 0.8931 - val_loss: 0.2434 - val_acc: 0.8750\n",
      "Epoch 392/400\n",
      "72/72 [==============================] - 5s 68ms/step - loss: 0.2375 - acc: 0.9028 - val_loss: 0.2338 - val_acc: 0.9000\n",
      "Epoch 393/400\n",
      "72/72 [==============================] - 5s 66ms/step - loss: 0.2366 - acc: 0.9014 - val_loss: 0.2429 - val_acc: 0.8750\n",
      "Epoch 394/400\n",
      "72/72 [==============================] - 5s 65ms/step - loss: 0.2355 - acc: 0.9028 - val_loss: 0.2342 - val_acc: 0.9000\n",
      "Epoch 395/400\n",
      "72/72 [==============================] - 5s 70ms/step - loss: 0.2349 - acc: 0.9014 - val_loss: 0.2430 - val_acc: 0.8750\n",
      "Epoch 396/400\n",
      "72/72 [==============================] - 5s 71ms/step - loss: 0.2341 - acc: 0.9028 - val_loss: 0.2339 - val_acc: 0.9000\n",
      "Epoch 397/400\n",
      "72/72 [==============================] - 4s 60ms/step - loss: 0.2339 - acc: 0.9042 - val_loss: 0.2439 - val_acc: 0.8750\n",
      "Epoch 398/400\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2301 - acc: 0.9000 - val_loss: 0.2330 - val_acc: 0.9125\n",
      "Epoch 399/400\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.2275 - acc: 0.8986 - val_loss: 0.2434 - val_acc: 0.9000\n",
      "Epoch 400/400\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2259 - acc: 0.9069 - val_loss: 0.2332 - val_acc: 0.9000\n",
      "model fit\n"
     ]
    }
   ],
   "source": [
    "#tests.test_model_final(model_final)\n",
    "batch_size = 80\n",
    "\n",
    "model_T.fit([vectorized_info, vectorized_questions, \\\n",
    "                        vectorized_fact_list, vectorized_relations, decoder_input_data], \\\n",
    "                       label_array, batch_size=batch_size, epochs=400, validation_split=0.1)\n",
    "\n",
    "print(\"model fit\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hidden_units = 128\n",
    "latent_dim = 128 \n",
    "labels_index_len = len(label_index_to_words)\n",
    "    \n",
    "encoder_model = Model([LSTM_info_inputs,LSTM_questions_inputs,LSTM_facts_inputs,LSTM_rela_inputs],encoder_states)\n",
    "\n",
    "decoder_inputs = Input(shape=(1, labels_index_len))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_dense = Dense(labels_index_len, activation='softmax')\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decode_sequence(info_input, facts_input, ques_input, rela_input,label_words_to_index=label_words_to_index, \\\n",
    "                                        label_index_to_words=label_index_to_words, label_pad_up_to=label_pad_up_to):\n",
    "    \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict([info_input, ques_input, facts_input, rela_input])\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, len(label_words_to_index)))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, label_words_to_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = label_index_to_words[sampled_token_index]\n",
    "        print(\"sampled char \", sampled_char)\n",
    "        decoded_sentence += sampled_char + \" \"\n",
    "\n",
    "        # Exit condition: hit max length\n",
    "        if len(decoded_sentence) > label_pad_up_to * 4:\n",
    "            print(\"len of sentence = \", len(decoded_sentence))\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, len(label_words_to_index)))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled char  IN4\n",
      "sampled char  IN4\n",
      "sampled char  IN4\n",
      "sampled char  IN4\n",
      "sampled char  IN4\n",
      "sampled char  IN4\n",
      "sampled char  IN4\n",
      "sampled char  IN4\n",
      "sampled char  \t\n",
      "sampled char  \t\n",
      "sampled char  \t\n",
      "sampled char  \t\n",
      "sampled char  \t\n",
      "len of sentence =  42\n",
      "states value  [array([[ 0.52528644,  2.71062088,  2.32848549, -0.50312501,  0.56951767,\n",
      "        -1.13162088,  0.34072456, -1.92812324, -0.12323909,  0.70027864,\n",
      "         1.21941638, -0.80078167, -1.11370873, -2.86348057, -1.78044915,\n",
      "        -2.66526699,  0.40804183, -2.39201856, -1.0227679 , -0.93778896,\n",
      "         0.01403493,  0.91131139,  0.04186231, -0.96145749, -3.60099983,\n",
      "         2.25232053,  0.73164302,  0.08936828, -1.19693804,  1.73914933,\n",
      "         0.30691409,  1.60669506,  2.56883264, -0.70603693,  2.64822865,\n",
      "        -1.90900898, -0.39705122, -0.67773235,  0.46626887, -0.69848925,\n",
      "         0.25378025,  1.36123562,  3.4326098 , -0.10008374,  0.47002453,\n",
      "         2.85923433, -0.35645607, -2.65078568, -0.93460202, -0.77156639,\n",
      "        -1.18785751,  1.23533845,  0.09634799, -2.74625707,  0.61425632,\n",
      "        -1.2998848 , -0.50667393, -0.34663072, -2.8436842 ,  0.66674507,\n",
      "         2.18389153, -3.12573051,  0.61214948, -0.85886085, -2.05903316,\n",
      "         0.6458627 ,  1.86226988,  1.15215492,  1.9995563 , -1.0461055 ,\n",
      "         1.37116599,  0.50071597,  0.06416916,  0.03263102,  0.02821669,\n",
      "        -0.76870561,  1.36156678, -0.74891573,  0.19227411, -0.28080955,\n",
      "         0.37653628,  0.65240365, -0.61748487,  0.89996779,  0.11508707,\n",
      "         2.39591503,  1.02042651, -2.49591589,  0.46832123,  2.1315434 ,\n",
      "        -0.44995439,  1.61485612,  0.9911806 ,  1.0905323 ,  2.98063183,\n",
      "        -1.97510552,  1.52254057, -1.4077177 ,  1.83452702, -0.9930619 ,\n",
      "         1.172683  ,  1.08598471, -1.07280123,  0.06343357,  0.2664085 ,\n",
      "         0.16071314,  0.73706305,  0.01905528,  0.65918732,  1.61915004,\n",
      "        -0.43248552, -1.80552375,  0.93770605, -2.03303528, -0.14834583,\n",
      "        -1.54281497, -0.21650815, -1.30026054,  0.35058618,  1.1839571 ,\n",
      "         1.58985341,  1.21331787, -2.40174437,  2.68667793, -2.91473603,\n",
      "        -1.04758048,  0.17590186, -1.17703748]], dtype=float32), array([[   2.91475964,   47.74348068,   73.16784668,   -7.69510555,\n",
      "         -14.37928772,   -5.61971378,  -29.14518166,   -3.42022252,\n",
      "           0.22854733,   43.81550598,   -2.72946572,   51.19013977,\n",
      "          50.76605606,   46.02557373,  -61.74533844, -103.15046692,\n",
      "           0.88218254,  -54.31446838,   -2.4877882 ,  -11.3251915 ,\n",
      "          -4.80097866,   -6.14037323,    4.73160887,   -1.66643023,\n",
      "         -14.38625813,   23.79554939,    2.12815595,    0.20976944,\n",
      "         -38.57862854,    8.23443794,    2.00522137,   19.70842743,\n",
      "          26.59483719,  -15.17802334,   13.8024416 ,   -4.9978776 ,\n",
      "          -0.81939983,   -2.1889751 ,   52.27785492,   14.50350666,\n",
      "           2.1289649 ,   30.49137306,    9.22082138,    0.79822862,\n",
      "          41.15588379,    6.8238163 ,  -21.48502159,  -33.54445267,\n",
      "         -19.74703598,   -1.44361258,   -2.56807566,   -2.998487  ,\n",
      "           1.98117697,   -5.14644146,    0.8510083 ,   -2.99064827,\n",
      "          -3.21009636,   -2.67436886,    8.45351887,    1.73790991,\n",
      "          -4.09765196,  -99.02178955,   55.63982773,  -54.67955399,\n",
      "          54.28520584,    1.45980644,   65.93257141,    2.57966399,\n",
      "          19.8570385 ,   -6.42778587,    2.76244068,    2.930722  ,\n",
      "          50.98163986,    0.40257207,    0.88036859,  -42.14036179,\n",
      "          47.73143387,  -93.6565094 ,    0.13141921,   -0.85561883,\n",
      "          23.08612633,    1.49316502,   -1.08505964,    3.41996765,\n",
      "           2.18199658,   20.64551163,   83.11404419,  -10.51410484,\n",
      "           0.15901375,   12.68919754,   -1.36849213,   50.4082756 ,\n",
      "           2.04719162,    2.18469477,   85.63609314,   -8.80628872,\n",
      "           4.92877674,  -18.6073513 ,   62.66809082,   -9.40136623,\n",
      "           2.34706187,  -33.80317688,  -60.88761902,   -2.73606896,\n",
      "           0.30644977,    0.44358259,    7.27828217,   32.51900482,\n",
      "         -33.1709671 ,   18.94308853,   -0.43409133,  -22.4834938 ,\n",
      "           8.34808731,  -19.67807388,   -7.09533882,   -4.47059488,\n",
      "           0.24175464,   17.6354599 ,    0.85010064,    7.90673447,\n",
      "          96.37471008,    2.51260185,  -20.0050354 ,   47.18727112,\n",
      "         -44.89016342,  -15.57473278,    2.98717523,   -2.22702789]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "test_info =  vectorized_info[25,:,:]\n",
    "test_info = test_info.reshape(1,*test_info.shape) \n",
    "test_ques = vectorized_questions[25,:,:]\n",
    "test_ques = test_ques.reshape(1,*test_ques.shape)\n",
    "test_fact =  vectorized_fact_list[25,:,:]\n",
    "test_fact = test_fact.reshape(1,*test_fact.shape) \n",
    "test_rela =  vectorized_relations[25,:,:]\n",
    "test_rela = test_info.reshape(1,*test_rela.shape) \n",
    "\n",
    "decoded_sentence = decode_sequence(test_info, test_fact, test_ques, test_rela)\n",
    "check_states_value = encoder_model.predict([test_info, test_ques, test_fact, test_rela])\n",
    "print(\"states value \", check_states_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RN2 RN2 RN2 RN2 RN2 RN2 RN2 RN2 RN2 IN5 IN5 \n"
     ]
    }
   ],
   "source": [
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "ques [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"info \", test_info[0,1,:])\n",
    "print(\"ques\", test_ques[0,5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NONE'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['N3', 'MEANS', 'MORE'], ['NONE'], ['NONE'], ['NONE'], ['return', 'MAKES', 'ADD', ';'], ['buy', 'MAKES', 'SUBTRACT'], ['changed', 'PAST-TENSE', 'change', ';', 'change', 'ADD-OR-SUBTRACT'], ['changed', 'PAST-TENSE', 'change', ';', 'change', 'ADD-OR-SUBTRACT'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['NONE'], ['N4', 'PLURAL', 'N5'], ['N4', 'PLURAL', 'N5'], ['N1', 'PLURAL', 'N3'], ['N1', 'PLURAL', 'N3'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'A1'], ['V1', 'MAKES', 'A1'], ['V1', 'MAKES', 'A1'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V2', 'MAKES', 'ADD', ';', 'V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['NONE'], ['NONE'], ['NONE'], ['V5', 'PAST-TENSE', 'V3', ';', 'V4', 'MAKES', 'V3'], ['NONE'], ['NONE'], ['NONE'], ['opened', 'PAST-TENSE', 'open'], ['NONE'], ['NONE'], ['NONE'], ['opened', 'PAST-TENSE', 'open'], ['N2', 'IN', 'N5', ';', 'N3', 'IN', 'N5', ';', 'N4', 'IN', 'N5'], ['N2', 'IN', 'N5', ';', 'N3', 'IN', 'N5', ';', 'N4', 'IN', 'N5'], ['N2', 'IN', 'N5', ';', 'N3', 'IN', 'N5', ';', 'N4', 'IN', 'N5'], ['V1', 'MEANS', 'HAVE'], ['V1', 'MEANS', 'HAVE'], ['V1', 'MEANS', 'HAVE'], ['V1', 'MEANS', 'HAVE'], ['V1', 'MEANS', 'HAVE'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['NONE']]\n"
     ]
    }
   ],
   "source": [
    "print(facts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['how', 'many', 'N3', 'are', 'there', '?'], ['how', 'many', 'N3', 'are', 'there', '?'], ['how', 'many', 'N5', 'are', 'in', 'N1', '?'], ['how', 'many', 'N3', 'are', 'there', '?'], ['how', 'many', 'N6', 'are', 'there', '?'], ['how', 'many', 'N2', 'are', 'there', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N2', 'are', 'there', '?'], ['how', 'many', 'N2', 'are', 'in', 'first', 'N1', '?'], ['how', 'many', 'N2', 'are', 'in', 'second', 'N1', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N1', 'will', 'there', 'be', 'when', 'N4', 'comes', '?'], ['how', 'many', 'N2', 'are', 'in', 'N4', '?'], ['how', 'many', 'N1', 'went', 'on', 'the', 'N3', '?'], ['how', 'many', 'N3', 'are', 'in', 'N1', '?'], ['how', 'many', 'N5', 'are', 'in', 'N1', '?'], ['how', 'many', 'N5', 'are', 'there', '?'], ['how', 'many', 'N2', 'are', 'in', 'N1', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N1', 'are', 'in', 'the', 'N4', '?'], ['how', 'many', 'N1', 'are', 'in', 'first', 'N5', '?'], ['how', 'many', 'N1', 'are', 'in', 'second', 'N5', '?'], ['how', 'many', 'N4', 'are', 'in', 'the', 'N1', '?'], ['how', 'many', 'N4', 'are', 'in', 'each', 'N3', '?'], ['how', 'many', 'N6', 'are', 'there', '?'], ['how', 'many', 'N4', 'are', 'there', '?'], ['how', 'many', 'N5', 'are', 'there', '?'], ['how', 'many', 'A1', 'N6', 'are', 'there', '?'], ['how', 'many', 'A1', 'N4', 'are', 'there', '?'], ['how', 'many', 'A1', 'N5', 'are', 'there', '?'], ['how', 'many', 'N3', 'are', 'there', '?'], ['how', 'many', 'N2', 'are', 'there', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N1', 'did', 'they', 'V1', 'in', 'the', 'first', 'week', '?'], ['how', 'many', 'N2', 'did', 'they', 'V1', 'in', 'the', 'first', 'week', '?'], ['how', 'many', 'N1', 'did', 'they', 'V1', 'in', 'the', 'second', 'week', '?'], ['how', 'many', 'N2', 'did', 'they', 'V1', 'in', 'the', 'second', 'week', '?'], ['how', 'many', 'N3', 'did', 'they', 'V1', 'in', 'the', 'first', 'week', '?'], ['how', 'many', 'N3', 'did', 'they', 'V1', 'in', 'the', 'second', 'week', '?'], ['how', 'many', 'UNITS', 'did', 'they', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'did', 'they', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'did', 'N1', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'did', 'N1', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'of', 'N2', 'did', 'they', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'of', 'N3', 'did', 'they', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'of', 'N2', 'did', 'they', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'of', 'N3', 'did', 'they', 'V1', 'in', 'total', '?'], ['how', 'many', 'UNITS', 'of', 'N1', 'are', 'there', '?'], ['how', 'many', 'UNITS', 'of', 'N1', 'were', 'in', 'N2', 'last', 'month', '?'], ['how', 'many', 'UNITS', 'of', 'N1', 'did', 'they', 'V1', 'last', 'month', '?'], ['how', 'many', 'UNITS', 'of', 'N4', 'are', 'there', '?'], ['how', 'many', 'UNITS', 'of', 'N2', 'are', 'there', '?'], ['how', 'many', 'UNITS', 'of', 'N3', 'are', 'there', '?'], ['how', 'many', 'N2', 'were', 'V5', '?'], ['how', 'many', 'N2', 'did', 'N1', 'V2', 'to', 'V3', '?'], ['how', 'many', 'women', 'V4', '?'], ['how', 'many', 'men', 'V4', '?'], ['how', 'many', 'days', 'was', 'it', 'open', 'in', 'N2', 'an', 'N3', '?'], ['how', 'many', 'days', 'will', 'it', 'be', 'open', 'in', 'N4', '?'], ['how', 'many', 'days', 'will', 'N1', 'be', 'open', 'in', 'N4', '?'], ['how', 'many', 'days', 'was', 'N1', 'open', 'in', 'N2', 'an', 'N3', '?'], ['how', 'many', 'days', 'will', 'N1', 'have', 'been', 'open', '?'], ['how', 'many', 'N1', 'are', 'on', 'the', 'N5', '?'], ['how', 'many', 'N1', 'are', 'in', 'the', 'N5', '?'], ['how', 'many', 'UNITS', 'of', 'N1', 'are', 'there', 'on', 'the', 'N5', '?'], ['how', 'many', 'N1', 'are', 'there', '?'], ['how', 'many', 'N2', 'are', 'there', 'in', 'the', 'first', 'two', 'N1', '?'], ['how', 'many', 'N2', 'are', 'there', 'in', 'the', 'last', 'N1', '?'], ['how', 'many', 'N2', 'are', 'there', 'in', 'total', '?'], ['how', 'many', 'N2', 'are', 'there', '?'], ['how', 'many', 'UNITS', 'of', 'N5', 'were', 'V1', '?'], ['how', 'many', 'UNITS', 'of', 'N2', 'were', 'V1', '?'], ['how', 'many', 'UNITS', 'of', 'N2', 'were', 'V1', '?'], ['how', 'many', 'UNITS', 'of', 'N3', 'were', 'V1', '?'], ['how', 'many', 'UNITS', 'of', 'N3', 'were', 'V1', '?'], ['how', 'many', 'UNITS', 'of', 'N4', 'were', 'V1', '?'], ['how', 'many', 'UNITS', 'of', 'N4', 'were', 'V1', '?'], ['how', 'many', 'N2', 'are', 'there', '?']]\n"
     ]
    }
   ],
   "source": [
    "print(questions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['N1', 'KIND-OF', 'N3', ';', 'N2', 'KIND-OF', 'N3'], ['N2', 'KIND-OF', 'N3', ';', 'N1', 'KIND-OF', 'N3'], ['N2', 'KIND-OF', 'N5', ';', 'N4', 'KIND-OF', 'N5'], ['N1', 'KIND-OF', 'N3'], ['N2', 'KIND-OF', 'N6', ';', 'N4', 'KIND-OF', 'N6'], ['NONE'], ['NONE'], ['N2', 'NOT', 'KIND-OF', 'N1'], ['NONE'], ['NONE'], ['NONE'], ['last', 'week', 'BEFORE', 'today'], ['NONE'], ['last', 'week', 'BEFORE', 'yesterday', ';', 'yesterday', 'BEFORE', 'today', ';', 'V1', 'MAKES', 'N4'], ['last', 'week', 'BEFORE', 'yesterday', ';', 'yesterday', 'BEFORE', 'today', ';', 'V1', 'MAKES', 'N4'], ['V1', 'MAKES', 'SUBSTRACT'], ['N4', 'KIND-OF', 'N1'], ['N2', 'KIND-OF', 'N5', ';', 'N3', 'KIND-OF', 'N5'], ['N2', 'KIND-OF', 'N5', ';', 'N3', 'KIND-OF', 'N5'], ['N3', 'NOT', 'KIND-OF', 'N2'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['V1', 'MAKES', 'ADD'], ['N4', 'KIND-OF', 'N6', ';', 'N5', 'KIND-OF', 'N6'], ['NONE'], ['NONE'], ['N4', 'KIND-OF', 'N6', ';', 'N5', 'KIND-OF', 'N6'], ['NONE'], ['NONE'], ['N1', 'KIND-OF', 'N3', ';', 'N2', 'KIND-OF', 'N3'], ['N1', 'NOT', 'KIND-OF', 'N2'], ['N2', 'NOT', 'KIND-OF', 'N1'], ['N1', 'NOT', 'KIND-OF', 'N2'], ['N2', 'NOT', 'KIND-OF', 'N1'], ['N1', 'NOT', 'KIND-OF', 'N2'], ['N2', 'NOT', 'KIND-OF', 'N1'], ['N1', 'KIND-OF', 'N3', ';', 'N2', 'KIND-OF', 'N3'], ['N1', 'KIND-OF', 'N3', ';', 'N2', 'KIND-OF', 'N3'], ['they', '=', 'N1'], ['they', '=', 'N1'], ['NONE'], ['NONE'], ['they', '=', 'N1'], ['they', '=', 'N1'], ['they', '=', 'N1'], ['they', '=', 'N1'], ['NONE'], ['N2', 'PLACE'], ['NONE'], ['N2', 'KIND-OF', 'N4', ';', 'N3', 'KIND-OF', 'N4'], ['NONE'], ['NONE'], ['men', 'KIND-OF', 'PEOPLE', ';', 'women', 'KIND-OF', 'PEOPLE', ';', 'N2', 'KIND-OF', 'PEOPLE'], ['NONE'], ['NONE'], ['NONE'], ['it', '=', 'N1', ';', 'N2', 'KIND-OF', 'month', ';', 'N3', 'KIND-OF', 'month'], ['it', '=', 'N1', ';', 'N4', 'KIND-OF', 'month'], ['it', '=', 'N1', ';', 'N4', 'KIND-OF', 'month'], ['N2', 'KIND-OF', 'month', ';', 'N3', 'KIND-OF', 'month'], ['N2', 'KIND-OF', 'month', ';', 'N3', 'KIND-OF', 'month'], ['N2', 'IN', 'N5', ';', 'N3', 'IN', 'N5', ';', 'N4', 'IN', 'N5'], ['N2', 'IN', 'N5', ';', 'N3', 'IN', 'N5', ';', 'N4', 'IN', 'N5'], ['N2', 'COUNT', '1', ';', 'N3', 'COUNT', '1', ';', 'N4', 'COUNT', '1'], ['N1', 'NUM-OF-TYPES', '3'], ['N1', 'NUM-OF-TYPES', '3'], ['N1', 'NUM-OF-TYPES', '3'], ['N1', 'NUM-OF-TYPES', '3'], ['N1', 'NUM-OF-TYPES', '3'], ['N2', 'KIND-OF', 'N5', ';', 'N3', 'KIND-OF', 'N5', ';', 'N4', 'KIND-OF', 'N5'], ['N2', 'KIND-OF', 'N5', ';', 'N3', 'KIND-OF', 'N5', ';', 'N4', 'KIND-OF', 'N5'], ['NONE'], ['N2', 'KIND-OF', 'N5', ';', 'N3', 'KIND-OF', 'N5', ';', 'N4', 'KIND-OF', 'N5'], ['NONE'], ['N2', 'KIND-OF', 'N5', ';', 'N3', 'KIND-OF', 'N5', ';', 'N4', 'KIND-OF', 'N5'], ['NONE'], ['NONE']]\n"
     ]
    }
   ],
   "source": [
    "print(relations_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['there', 'are', 'IN1', 'N1', 'and', 'IN2', 'N2', '.'], ['there', 'are', 'IN1', 'N2', 'and', 'IN2', 'N1', '.'], ['in', 'the', 'N1', ',', 'there', 'are', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['there', 'are', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.'], ['at', 'the', 'N1', ',', 'there', 'are', 'IN1', 'UNITS', 'of', 'N2', 'with', 'N3', 'and', 'IN2', 'UNITS', 'of', 'N4', 'with', 'N5', '.'], ['next', 'to', 'the', 'IN1', 'N1', ',', 'there', 'are', 'IN2', 'N2', '.', 'on', 'the', 'other', 'side', 'of', 'the', 'N3', ',', 'there', 'are', 'IN3', 'N2', '.'], ['there', 'are', 'IN1', 'N1', 'in', 'the', 'N2', 'and', 'IN2', 'N1', 'on', 'N3', '.'], ['there', 'are', 'IN1', 'N1', 'and', 'IN2', 'N2', 'from', 'the', 'N3', '.', 'the', 'N4', 'has', 'IN3', 'N1', 'already', '.'], ['in', 'one', 'N1', ',', 'there', 'are', 'IN1', 'N2', '.', 'in', 'the', 'other', 'N1', ',', 'there', 'are', 'IN2', 'N2', '.'], ['in', 'one', 'N1', ',', 'there', 'are', 'IN1', 'N2', '.', 'in', 'the', 'other', 'N1', ',', 'there', 'are', 'IN2', 'N2', '.'], ['in', 'one', 'N1', ',', 'there', 'are', 'IN1', 'N2', '.', 'in', 'the', 'other', 'N1', ',', 'there', 'are', 'IN2', 'N2', '.'], ['there', 'were', 'IN1', 'UNITS', 'of', 'N1', 'in', 'the', 'N2', '.', 'a', 'N3', 'comes', 'in', 'to', 'return', 'IN2', 'UNITS', 'of', 'N1', 'he', 'bought', 'last', 'week', '.'], ['there', 'were', 'IN1', 'UNITS', 'of', 'N1', 'in', 'the', 'N2', '.', 'a', 'N3', 'comes', 'in', 'to', 'buy', 'IN2', 'UNITS', '.'], ['N1', 'V1', 'IN1', 'N2', 'last', 'week', '.', 'yesterday', ',', 'he', 'called', 'the', 'N3', 'and', 'changed', 'the', 'N4', 'to', 'add', 'IN2', 'more', 'N2', '.'], ['N1', 'V1', 'IN1', 'N2', 'last', 'week', '.', 'yesterday', ',', 'he', 'called', 'the', 'N3', 'and', 'changed', 'the', 'N4', 'to', 'subtract', 'IN2', 'N2', '.'], ['IN1', 'N1', 'in', 'N2', 'went', 'on', 'the', 'N3', 'and', 'IN2', 'N1', 'V1', 'and', 'could', 'not', 'go', 'on', 'the', 'N3', '.'], ['in', 'the', 'N1', ',', 'there', 'were', 'IN1', 'N2', 'and', 'IN2', 'N3', '.', 'on', 'the', 'other', 'side', 'of', 'the', 'N4', ',', 'there', 'were', 'IN3', 'N3', 'for', 'V1', '.'], ['in', 'the', 'N1', ',', 'there', 'were', 'IN1', 'N2', 'and', 'IN2', 'N3', '.', 'on', 'the', 'other', 'side', 'of', 'the', 'N4', ',', 'there', 'were', 'IN3', 'N3', 'for', 'V1', '.'], ['in', 'the', 'N1', ',', 'there', 'were', 'IN1', 'N2', 'and', 'IN2', 'N3', '.', 'on', 'the', 'other', 'side', 'of', 'the', 'N4', ',', 'there', 'were', 'IN3', 'N3', 'for', 'V1', '.'], ['in', 'the', 'N1', ',', 'there', 'were', 'IN1', 'N2', 'and', 'IN2', 'N3', '.', 'on', 'the', 'other', 'side', 'of', 'the', 'N4', ',', 'there', 'were', 'IN3', 'N3', 'for', 'V1', '.'], ['N1', 'were', 'V1', 'for', 'N2', '.', 'as', 'there', 'were', 'IN1', 'N3', ',', 'the', 'N1', 'V1', 'in', 'IN2', 'N4', '.', 'there', 'were', 'IN3', 'N1', 'in', 'one', 'N5', 'and', 'IN4', 'N1', 'in', 'another', 'N5'], ['N1', 'were', 'V1', 'for', 'N2', '.', 'as', 'there', 'were', 'IN1', 'N3', ',', 'the', 'N1', 'V1', 'in', 'IN2', 'N4', '.', 'there', 'were', 'IN3', 'N1', 'in', 'one', 'N5', 'and', 'IN4', 'N1', 'in', 'another', 'N5'], ['N1', 'were', 'V1', 'for', 'N2', '.', 'as', 'there', 'were', 'IN1', 'N3', ',', 'the', 'N1', 'V1', 'in', 'IN2', 'N4', '.', 'there', 'were', 'IN3', 'N1', 'in', 'one', 'N5', 'and', 'IN4', 'N1', 'in', 'another', 'N5'], ['N1', 'were', 'V1', 'for', 'N2', '.', 'as', 'there', 'were', 'IN1', 'N3', ',', 'the', 'N1', 'V1', 'in', 'IN2', 'N4', '.', 'there', 'were', 'IN3', 'N1', 'in', 'one', 'N5', 'and', 'IN4', 'N1', 'in', 'another', 'N5'], ['there', 'were', 'IN1', 'N1', 'in', 'the', 'N2', '.', 'each', 'N3', 'V1', 'IN2', 'N4', '.'], ['there', 'were', 'IN1', 'N1', 'in', 'the', 'N2', '.', 'each', 'N3', 'V1', 'IN2', 'N4', '.'], ['the', 'N1', 'V1', 'some', 'N2', 'for', 'the', 'N3', '.', 'there', 'were', 'IN1', 'UNITS', 'of', 'N4', 'and', 'IN2', 'UNITS', 'of', 'N5', '.'], ['the', 'N1', 'V1', 'some', 'N2', 'for', 'the', 'N3', '.', 'there', 'were', 'IN1', 'UNITS', 'of', 'N4', 'and', 'IN2', 'UNITS', 'of', 'N5', '.'], ['the', 'N1', 'V1', 'some', 'N2', 'for', 'the', 'N3', '.', 'there', 'were', 'IN1', 'UNITS', 'of', 'N4', 'and', 'IN2', 'UNITS', 'of', 'N5', '.'], ['the', 'N1', 'V1', 'with', 'the', 'N2', 'at', 'the', 'N3', ',', 'there', 'are', 'A1', 'IN1', 'UNITS', 'of', 'N4', 'and', 'IN2', 'UNITS', 'of', 'N5', '.'], ['the', 'N1', 'V1', 'with', 'the', 'N2', 'at', 'the', 'N3', ',', 'there', 'are', 'A1', 'IN1', 'UNITS', 'of', 'N4', 'and', 'IN2', 'UNITS', 'of', 'N5', '.'], ['the', 'N1', 'V1', 'with', 'the', 'N2', 'at', 'the', 'N3', ',', 'there', 'are', 'A1', 'IN1', 'UNITS', 'of', 'N4', 'and', 'IN2', 'UNITS', 'of', 'N5', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['in', 'the', 'first', 'week', ',', 'they', 'V1', 'IN1', 'UNITS', 'of', 'N1', 'and', 'IN2', 'UNITS', 'of', 'N2', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V1', 'IN3', 'UNITS', 'of', 'N1', 'and', 'IN4', 'UNITS', 'of', 'N2', '.'], ['during', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'during', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['in', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['in', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['during', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'during', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['during', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'during', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['during', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'during', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['in', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['in', 'the', 'first', 'week', ',', 'the', 'N1', 'V2', 'IN1', 'UNITS', 'of', 'N2', 'and', 'IN2', 'UNITS', 'of', 'N3', '.', 'in', 'the', 'second', 'week', ',', 'they', 'V2', 'IN3', 'UNITS', 'of', 'N2', 'and', 'IN4', 'UNITS', 'of', 'N3', '.'], ['they', 'had', 'IN1', 'UNITS', 'of', 'N1', 'in', 'N2', 'and', 'V1', 'IN2', 'more', 'UNITS', 'last', 'month', '.'], ['they', 'had', 'IN1', 'UNITS', 'of', 'N1', 'in', 'N2', 'and', 'V1', 'IN2', 'more', 'UNITS', 'last', 'month', '.'], ['they', 'had', 'IN1', 'UNITS', 'of', 'N1', 'in', 'N2', 'and', 'V1', 'IN2', 'more', 'UNITS', 'last', 'month', '.'], ['in', 'the', 'N1', ',', 'there', 'are', 'IN1', 'UNITS', 'of', 'N2', '.', 'there', 'were', 'IN2', 'more', 'UNITS', 'of', 'N3', 'than', 'N2', '.'], ['in', 'the', 'N1', ',', 'there', 'are', 'IN1', 'UNITS', 'of', 'N2', '.', 'there', 'were', 'IN2', 'more', 'UNITS', 'of', 'N3', 'than', 'N2', '.'], ['in', 'the', 'N1', ',', 'there', 'are', 'IN1', 'UNITS', 'of', 'N2', '.', 'there', 'were', 'IN2', 'more', 'UNITS', 'of', 'N3', 'than', 'N2', '.'], ['the', 'N1', 'V2', 'to', 'V3', 'IN1', 'N2', '.', 'IN2', 'men', 'and', 'IN3', 'women', 'V4', '.'], ['the', 'N1', 'V2', 'to', 'V3', 'IN1', 'N2', '.', 'IN2', 'men', 'and', 'IN3', 'women', 'V4', '.'], ['the', 'N1', 'V2', 'to', 'V3', 'IN1', 'N2', '.', 'IN2', 'men', 'and', 'IN3', 'women', 'V4', '.'], ['the', 'N1', 'V2', 'to', 'V3', 'IN1', 'N2', '.', 'IN2', 'men', 'and', 'IN3', 'women', 'V4', '.'], ['the', 'N1', 'opened', 'IN1', 'days', 'in', 'N2', 'and', 'IN2', 'days', 'in', 'N3', '.', 'it', 'will', 'be', 'opened', 'for', 'IN3', 'days', 'in', 'N4', '.'], ['the', 'N1', 'opened', 'IN1', 'days', 'in', 'N2', 'and', 'IN2', 'days', 'in', 'N3', '.', 'it', 'will', 'be', 'opened', 'for', 'IN3', 'days', 'in', 'N4', '.'], ['the', 'N1', 'opened', 'IN1', 'days', 'in', 'N2', 'and', 'IN2', 'days', 'in', 'N3', '.', 'it', 'will', 'be', 'opened', 'for', 'IN3', 'days', 'in', 'N4', '.'], ['the', 'N1', 'opened', 'IN1', 'days', 'in', 'N2', 'and', 'IN2', 'days', 'in', 'N3', '.', 'it', 'will', 'be', 'opened', 'for', 'IN3', 'days', 'in', 'N4', '.'], ['the', 'N1', 'opened', 'IN1', 'days', 'in', 'N2', 'and', 'IN2', 'days', 'in', 'N3', '.', 'it', 'will', 'be', 'opened', 'for', 'IN3', 'days', 'in', 'N4', '.'], ['there', 'are', 'IN1', 'N1', 'in', 'N2', ',', 'IN2', 'N1', 'in', 'the', 'N3', 'and', 'IN3', 'N1', 'in', 'the', 'N4', '.'], ['there', 'are', 'IN1', 'N1', 'in', 'N2', ',', 'IN2', 'N1', 'in', 'the', 'N3', 'and', 'IN3', 'N1', 'in', 'the', 'N4', '.'], ['there', 'are', 'IN1', 'UNITS', 'of', 'N1', 'in', 'each', 'of', 'N2', 'and', 'N3', 'and', 'there', 'are', 'IN2', 'UNITS', 'of', 'N1', 'in', 'N4', '.'], ['there', 'are', 'IN1', 'N1', 'for', 'N2', 'and', 'each', 'N1', 'has', 'a', 'capacity', 'of', 'IN2', 'UNITS', 'of', 'N2', '.', 'the', 'first', 'IN3', 'N1', 'are', 'full', 'and', 'the', 'last', 'IN4', 'V1', 'IN5', 'UNITS', 'of', 'N2', '.'], ['there', 'are', 'IN1', 'N1', 'for', 'N2', 'and', 'each', 'N1', 'has', 'a', 'capacity', 'of', 'IN2', 'UNITS', 'of', 'N2', '.', 'the', 'first', 'IN3', 'N1', 'are', 'full', 'and', 'the', 'last', 'IN4', 'V1', 'IN5', 'UNITS', 'of', 'N2', '.'], ['there', 'are', 'IN1', 'N1', 'for', 'N2', 'and', 'each', 'N1', 'has', 'a', 'capacity', 'of', 'IN2', 'UNITS', 'of', 'N2', '.', 'the', 'first', 'IN3', 'N1', 'are', 'full', 'and', 'the', 'last', 'IN4', 'V1', 'IN5', 'UNITS', 'of', 'N2', '.'], ['there', 'are', 'IN1', 'N1', 'for', 'N2', 'and', 'each', 'N1', 'has', 'a', 'capacity', 'of', 'IN2', 'UNITS', 'of', 'N2', '.', 'the', 'first', 'IN3', 'N1', 'are', 'full', 'and', 'the', 'last', 'IN4', 'V1', 'IN5', 'UNITS', 'of', 'N2', '.'], ['there', 'are', 'IN1', 'N1', 'for', 'N2', 'and', 'each', 'N1', 'has', 'a', 'capacity', 'of', 'IN2', 'UNITS', 'of', 'N2', '.', 'the', 'first', 'IN3', 'N1', 'are', 'full', 'and', 'the', 'last', 'IN4', 'V1', 'IN5', 'UNITS', 'of', 'N2', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['the', 'N1', 'V1', 'IN1', 'UNITS', 'of', 'N2', ',', 'IN2', 'UNITS', 'of', 'N3', 'and', 'IN3', 'UNITS', 'of', 'N4', '.'], ['there', 'are', 'IN1', 'N1', '.', 'each', 'N1', 'has', 'IN2', 'N2', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IN1 + IN2\\n', 'IN2 + IN1\\n', 'IN1 + IN3\\n', 'IN1\\n', 'IN1 + IN2\\n', 'IN2 + IN3\\n', 'IN1 + IN2\\n', 'IN1 + IN3\\n', 'IN1 + IN2\\n', 'IN1\\n', 'IN2\\n', 'IN1 + IN2\\n', 'IN1 - IN2\\n', 'IN1 + IN2\\n', 'IN1 - IN2\\n', 'IN1 - IN2\\n', 'IN1 + IN3\\n', 'IN1 + IN2 + IN3\\n', 'IN1 + IN2 + IN3\\n', 'IN1\\n', 'IN3 + IN4\\n', 'IN3 + IN4\\n', 'IN3\\n', 'IN4\\n', 'IN1 * IN2\\n', 'IN2\\n', 'IN1 + IN2\\n', 'IN1\\n', 'IN2\\n', 'IN1 + IN2\\n', 'IN1\\n', 'IN2\\n', 'IN1 + IN2 + IN3 + IN4\\n', 'IN2 + IN4\\n', 'IN1 + IN3\\n', 'IN1\\n', 'IN2\\n', 'IN3\\n', 'IN4\\n', 'IN1 + IN2\\n', 'IN3 + IN4\\n', 'IN1 + IN2 + IN3 + IN4\\n', 'IN1 + IN2 + IN3 + IN4\\n', 'IN1 + IN2 + IN3 + IN4\\n', 'IN1 + IN2 + IN3 + IN4\\n', 'IN1 + IN3\\n', 'IN2 + IN4\\n', 'IN1 + IN3\\n', 'IN2 + IN4\\n', 'IN1 + IN2\\n', 'IN1\\n', 'IN2\\n', 'IN1 + IN1 + IN2\\n', 'IN1\\n', 'IN1 + IN2\\n', 'IN2 + IN3\\n', 'IN1\\n', 'IN3\\n', 'IN2\\n', 'IN1 + IN2\\n', 'IN3\\n', 'IN3\\n', 'IN1 + IN2\\n', 'IN1 + IN2 + IN3\\n', 'IN1 + IN2 + IN3\\n', 'IN1 + IN2 + IN3\\n', 'IN1 * RN1 + IN1 * RN2 + IN2\\n', 'IN1\\n', 'IN2 + IN2\\n', 'IN5\\n', 'IN2 + IN2 + IN5\\n', 'IN2 + IN2 + IN5\\n', 'IN1 + IN2 + IN3\\n', 'IN1\\n', 'IN1\\n', 'IN2\\n', 'IN2\\n', 'IN3\\n', 'IN3\\n', 'IN1 * IN2']\n"
     ]
    }
   ],
   "source": [
    "print(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
