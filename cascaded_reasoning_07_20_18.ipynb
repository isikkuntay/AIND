{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import sys\n",
    "import numpy\n",
    "import numpy as np\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, TimeDistributed, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Merge\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "questions = open('abstract_math_questions.txt','r')\n",
    "labels = open('abstract_math_labels.txt','r')\n",
    "info_sentences = open('abstract_math_info.txt','r')\n",
    "fact_sentences = open('abstract_math_facts.txt','r')\n",
    "standard_relations = open('abstract_math_relations.txt','r')\n",
    "\n",
    "questions_list = []\n",
    "labels_list = []\n",
    "info_list = []\n",
    "relations_list = []\n",
    "facts_list = []\n",
    "\n",
    "for sentence in questions:\n",
    "    questions_list.append(sentence)\n",
    "    \n",
    "for sentence in labels:\n",
    "    labels_list.append(sentence)\n",
    "    \n",
    "for sentence in info_sentences:\n",
    "    info_list.append(sentence)\n",
    "\n",
    "for sentence in fact_sentences:\n",
    "    facts_list.append(sentence)\n",
    "    \n",
    "for sentence in standard_relations:\n",
    "    relations_list.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "10\n",
      "26\n",
      "5\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(questions_list[0]))\n",
    "print(len(labels_list[0]))\n",
    "print(len(info_list[0]))\n",
    "print(len(facts_list[0]))\n",
    "print(len(relations_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#in this version, we put placeholders for numbers, such as QN1, QN2, etc.. for question numbers\n",
    "\n",
    "fact_num_dict_list = []\n",
    "ques_num_dict_list = []\n",
    "info_num_dict_list = []\n",
    "\n",
    "#store the numbers in a list of dicts\n",
    "#for facts list:\n",
    "for sentence in facts_list:\n",
    "    fact_num_dict = {}\n",
    "    indx_num = 1\n",
    "    for word in sentence:\n",
    "         if word.isdigit():\n",
    "            fact_num_dict[word] = \"FN%d\".format(indx_num)\n",
    "            word = \"FN%d\".format(indx_num)\n",
    "            indx_num += 1\n",
    "    fact_num_dict_list.append(fact_num_dict)\n",
    "\n",
    "#repeat for questions\n",
    "for sentence in questions_list:\n",
    "    quest_num_dict = {}\n",
    "    indx_num = 1\n",
    "    for word in sentence:\n",
    "         if word.isdigit():\n",
    "            quest_num_dict[word] = \"QN%d\".format(indx_num)\n",
    "            word = \"QN%d\".format(indx_num)\n",
    "            indx_num += 1\n",
    "    ques_num_dict_list.append(quest_num_dict)   \n",
    "\n",
    "#repeat for information\n",
    "for sentence in info_list:\n",
    "    info_num_dict = {}\n",
    "    indx_num = 1\n",
    "    for word in sentence:\n",
    "         if word.isdigit():\n",
    "            info_num_dict[word] = \"IN%d\".format(indx_num)\n",
    "            word = \"IN%d\".format(indx_num)\n",
    "            indx_num += 1\n",
    "    info_num_dict_list.append(info_num_dict)   \n",
    "\n",
    "#relations do not need since it will already be in encoded format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "list_of_all_variables = []\n",
    "\n",
    "### Let's make a list of all variables and prepare them for one-hot-coding\n",
    "\n",
    "# Start by assigning numbers to the standard variables:\n",
    "\n",
    "list_of_all_variables.append(\"QN1\")\n",
    "list_of_all_variables.append(\"QN2\")\n",
    "list_of_all_variables.append(\"QN3\")\n",
    "list_of_all_variables.append(\"QN4\")\n",
    "list_of_all_variables.append(\"QN5\")\n",
    "list_of_all_variables.append(\"QN6\")\n",
    "list_of_all_variables.append(\"QN7\")\n",
    "list_of_all_variables.append(\"QN8\")\n",
    "list_of_all_variables.append(\"FN1\")\n",
    "list_of_all_variables.append(\"FN2\")\n",
    "list_of_all_variables.append(\"FN3\")\n",
    "list_of_all_variables.append(\"FN4\")\n",
    "list_of_all_variables.append(\"FN5\")\n",
    "list_of_all_variables.append(\"FN6\")\n",
    "list_of_all_variables.append(\"FN7\")\n",
    "list_of_all_variables.append(\"FN8\")\n",
    "list_of_all_variables.append(\"IN1\")\n",
    "list_of_all_variables.append(\"N2\")\n",
    "list_of_all_variables.append(\"IN3\")\n",
    "list_of_all_variables.append(\"IN4\")\n",
    "list_of_all_variables.append(\"IN5\")\n",
    "list_of_all_variables.append(\"IN6\")\n",
    "list_of_all_variables.append(\"IN7\")\n",
    "list_of_all_variables.append(\"IN8\")\n",
    "list_of_all_variables.append(\"N1\")\n",
    "list_of_all_variables.append(\"N2\")\n",
    "list_of_all_variables.append(\"N3\")\n",
    "list_of_all_variables.append(\"N4\")\n",
    "list_of_all_variables.append(\"N5\")\n",
    "list_of_all_variables.append(\"N6\")\n",
    "list_of_all_variables.append(\"N7\")\n",
    "list_of_all_variables.append(\"N8\")\n",
    "list_of_all_variables.append(\"N9\")\n",
    "list_of_all_variables.append(\"V1\")\n",
    "list_of_all_variables.append(\"V2\")\n",
    "list_of_all_variables.append(\"V3\")\n",
    "list_of_all_variables.append(\"V4\")\n",
    "list_of_all_variables.append(\"V5\")\n",
    "list_of_all_variables.append(\"V6\")\n",
    "list_of_all_variables.append(\"V7\")\n",
    "list_of_all_variables.append(\"V8\")\n",
    "list_of_all_variables.append(\"V9\")\n",
    "\n",
    "for sentence in facts_list:\n",
    "    for word in sentence.split():\n",
    "        if word not in list_of_all_variables:\n",
    "            list_of_all_variables.append(word)\n",
    "    \n",
    "for sentence in info_list:\n",
    "    for word in sentence.split():\n",
    "        if word not in list_of_all_variables:\n",
    "            list_of_all_variables.append(word) \n",
    "\n",
    "for sentence in questions_list:\n",
    "    for word in sentence.split():\n",
    "        if word not in list_of_all_variables:\n",
    "            list_of_all_variables.append(word)\n",
    "\n",
    "for sentence in relations_list:\n",
    "    for word in sentence.split():\n",
    "        if word not in list_of_all_variables:\n",
    "            list_of_all_variables.append(word)      \n",
    "            \n",
    "list_of_all_variables.append(\"<PAD>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QN1', 'QN2', 'QN3', 'QN4', 'QN5', 'QN6', 'QN7', 'QN8', 'FN1', 'FN2', 'FN3', 'FN4', 'FN5', 'FN6', 'FN7', 'FN8', 'IN1', 'N2', 'IN3', 'IN4', 'IN5', 'IN6', 'IN7', 'IN8', 'N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 'N9', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'NONE', 'MEANS', 'MORE', 'return', 'MAKES', 'ADD', ';', 'buy', 'SUBTRACT', 'changed', 'PAST-TENSE', 'change', 'ADD-OR-SUBTRACT', 'PLURAL', 'A1', 'opened', 'open', 'IN', 'HAVE', 'there', 'are', '6', 'and', '2', '.', 'in', 'the', ',', '4', 'UNITS', 'of', '7', '5', '9', '8', 'at', 'with', 'next', 'to', '3', 'on', 'other', 'side', 'from', 'has', 'already', 'one', 'were', 'a', 'comes', 'he', 'bought', 'last', 'week', 'yesterday', 'called', 'add', 'more', 'subtract', 'went', 'could', 'not', 'go', 'for', 'as', 'another', 'each', 'some', 'first', 'they', '12', '36', 'second', '25', '24', 'during', 'had', '40', '47', 'month', '16', '19', 'than', '60', '34', 'men', '45', 'women', '18', 'days', '21', 'it', 'will', 'be', '15', '11', '80', '32', 'capacity', 'full', '1', '50', '14', 'how', 'many', '?', 'when', 'comes?', 'did', 'total', 'was', 'an', 'have', 'been', 'N5?', 'two', 'KIND-OF', 'NOT', 'BEFORE', 'today', 'SUBSTRACT', '=', 'PLACE', 'PEOPLE', 'COUNT', 'NUM-OF-TYPES', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "\n",
    "word_index = 0\n",
    "\n",
    "for word in list_of_all_variables:\n",
    "    word_to_index[word] = word_index\n",
    "    index_to_word[word_index] = word\n",
    "    word_index += 1\n",
    "print(list_of_all_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_facts_list = []\n",
    "new_questions_list = []\n",
    "new_info_list = []\n",
    "new_relations_list = []\n",
    "\n",
    "pad_up_to = 100\n",
    "pad_index = word_to_index[\"<PAD>\"]\n",
    "\n",
    "for sentence in facts_list:\n",
    "    substitute_sentence = []\n",
    "    for word in sentence.split():\n",
    "        substitute_sentence.append(word_to_index[word])\n",
    "    for i in range(len(substitute_sentence),pad_up_to):\n",
    "        substitute_sentence.append(pad_index)\n",
    "    new_facts_list.append(substitute_sentence)\n",
    "\n",
    "for sentence in questions_list:\n",
    "    substitute_sentence = []\n",
    "    for word in sentence.split():\n",
    "        substitute_sentence.append(word_to_index[word])\n",
    "    for i in range(len(substitute_sentence),pad_up_to):\n",
    "        substitute_sentence.append(pad_index)\n",
    "    new_questions_list.append(substitute_sentence)\n",
    "        \n",
    "for sentence in info_list:\n",
    "    substitute_sentence = []\n",
    "    for word in sentence.split():\n",
    "        substitute_sentence.append(word_to_index[word])\n",
    "    for i in range(len(substitute_sentence),pad_up_to):\n",
    "        substitute_sentence.append(pad_index)\n",
    "    new_info_list.append(substitute_sentence)\n",
    "\n",
    "for sentence in relations_list:\n",
    "    substitute_sentence = []\n",
    "    for word in sentence.split():\n",
    "        substitute_sentence.append(word_to_index[word])\n",
    "    for i in range(len(substitute_sentence),pad_up_to):\n",
    "        substitute_sentence.append(pad_index)\n",
    "    new_relations_list.append(substitute_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "79\n",
      "79\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "print(len(new_facts_list))\n",
    "print(len(new_questions_list))\n",
    "print(len(new_info_list))\n",
    "print(len(new_relations_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "one_hot_facts = []\n",
    "one_hot_questions = []\n",
    "one_hot_info = []\n",
    "one_hot_relations = []\n",
    "\n",
    "one_hot_length = len(word_to_index)\n",
    "\n",
    "for sentence in new_facts_list:\n",
    "    substitute_sentence = []\n",
    "    for word_ind in sentence:\n",
    "        substitute_word = []\n",
    "        for i in range(one_hot_length):\n",
    "            if i == word_ind:\n",
    "                substitute_word.append(1)\n",
    "            else:\n",
    "                substitute_word.append(0)\n",
    "        substitute_sentence.append(substitute_word)\n",
    "    one_hot_facts.append(substitute_sentence)\n",
    "\n",
    "for sentence in new_questions_list:\n",
    "    substitute_sentence = []\n",
    "    for word_ind in sentence:\n",
    "        substitute_word = []\n",
    "        for i in range(one_hot_length):\n",
    "            if i == word_ind:\n",
    "                substitute_word.append(1)\n",
    "            else:\n",
    "                substitute_word.append(0)\n",
    "        substitute_sentence.append(substitute_word)\n",
    "    one_hot_questions.append(substitute_sentence)\n",
    "\n",
    "for sentence in new_info_list:\n",
    "    substitute_sentence = []\n",
    "    for word_ind in sentence:\n",
    "        substitute_word = []\n",
    "        for i in range(one_hot_length):\n",
    "            if i == word_ind:\n",
    "                substitute_word.append(1)\n",
    "            else:\n",
    "                substitute_word.append(0)\n",
    "        substitute_sentence.append(substitute_word)\n",
    "    one_hot_info.append(substitute_sentence)\n",
    "    \n",
    "for sentence in new_relations_list:\n",
    "    substitute_sentence = []\n",
    "    for word_ind in sentence:\n",
    "        substitute_word = []\n",
    "        for i in range(one_hot_length):\n",
    "            if i == word_ind:\n",
    "                substitute_word.append(1)\n",
    "            else:\n",
    "                substitute_word.append(0)\n",
    "        substitute_sentence.append(substitute_word)\n",
    "    one_hot_relations.append(substitute_sentence)\n",
    "    \n",
    "vectorized_fact_list = np.asarray(one_hot_facts)\n",
    "vectorized_questions = np.asarray(one_hot_questions) \n",
    "vectorized_info = np.asarray(one_hot_info)\n",
    "vectorized_relations = np.asarray(one_hot_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 100, 168)\n",
      "(79, 100, 168)\n",
      "(79, 100, 168)\n",
      "(79, 100, 168)\n"
     ]
    }
   ],
   "source": [
    "print(vectorized_fact_list.shape)\n",
    "print(vectorized_questions.shape)\n",
    "print(vectorized_info.shape)\n",
    "print(vectorized_relations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "label_words_to_index = {}\n",
    "label_index_to_words = {}\n",
    "label_index = 0\n",
    "label_words_to_index[\"\\t\"]=label_index\n",
    "label_index_to_words[label_index]=\"\\t\"\n",
    "label_index += 1\n",
    "label_words_to_index[\"<PAD>\"]=label_index\n",
    "label_index_to_words[label_index]=\"<PAD>\"\n",
    "new_label_list = []\n",
    "label_pad_up_to = 50\n",
    "for sentence in labels_list:\n",
    "    substitute_sentence = []\n",
    "    sent = sentence.split()\n",
    "    for char in sent: #char could be a word or group of characters\n",
    "        if char in label_words_to_index.keys():\n",
    "            substitute_sentence.append(label_words_to_index[char])\n",
    "        else:\n",
    "            label_index += 1\n",
    "            label_words_to_index[char]=label_index\n",
    "            label_index_to_words[label_index]=char\n",
    "            substitute_sentence.append(label_words_to_index[char])\n",
    "    for i in range(len(substitute_sentence),label_pad_up_to): #pad to regular\n",
    "        substitute_sentence.append(label_words_to_index[\"<PAD>\"])\n",
    "        \n",
    "    new_label_list.append(substitute_sentence)\n",
    "    \n",
    "#vectorize labels\n",
    "vectorized_label_list = []\n",
    "for sentence in new_label_list:\n",
    "    sentence_vector = []\n",
    "    for word in sentence:\n",
    "        vector = [0]*len(label_words_to_index)\n",
    "        vector[word] = 1\n",
    "        sentence_vector.append(vector)\n",
    "    vectorized_label_list.append(sentence_vector)\n",
    "    \n",
    "label_array = np.asarray(vectorized_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 50, 12)\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(label_array.shape)\n",
    "print(len(label_words_to_index))\n",
    "print(len(label_index_to_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, dictionary):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"    \n",
    "    return ' '.join([label_index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cascaded_reasoning(info_shape, questions_shape, facts_shape \\\n",
    "                       , relations_shape, labels_index_len):\n",
    "    \"\"\"\n",
    "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement\n",
    "    learning_rate = 0.01\n",
    "    hidden_units = 128\n",
    "    latent_dim = 128 \n",
    "    # TODO: Build the layers\n",
    "    \n",
    "    LSTM_info_inputs = Input(shape=(None, info_shape[2]))\n",
    "    LSTM_info = LSTM(hidden_units,return_state=True)\n",
    "    LSTM_info_output, info_h, info_c=LSTM_info(LSTM_info_inputs)\n",
    "    info_states = [info_h,info_c]\n",
    "    \n",
    "    LSTM_questions_inputs = Input(shape=(None, questions_shape[2]))\n",
    "    LSTM_questions = LSTM(hidden_units,return_state=True)\n",
    "    LSTM_questions_output, questions_h, questions_c=LSTM_questions(LSTM_questions_inputs)\n",
    "    questions_states= [questions_h,questions_c]\n",
    "    \n",
    "    LSTM_facts_inputs = Input(shape=(None, facts_shape[2]))\n",
    "    LSTM_facts = LSTM(hidden_units,return_state=True)\n",
    "    LSTM_facts_output, facts_h, facts_c=LSTM_facts(LSTM_facts_inputs)\n",
    "    facts_states= [facts_h,facts_c]\n",
    "    \n",
    "    LSTM_rela_inputs = Input(shape=(None, relations_shape[2]))\n",
    "    LSTM_rela = LSTM(hidden_units,return_state=True)\n",
    "    LSTM_rela_output,rela_h,rela_c=LSTM_rela(LSTM_rela_inputs)\n",
    "    rela_states= [rela_h,rela_c]\n",
    "    \n",
    "    added_h = keras.layers.Add()([info_h,questions_h,facts_h,rela_h])\n",
    "    added_c = keras.layers.Add()([info_c,questions_c,facts_c,rela_c])\n",
    "    states = [added_h,added_c]\n",
    "    \n",
    "    decoder_inputs = Input(shape=(1, labels_index_len))\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_dense = Dense(labels_index_len, activation='softmax')\n",
    "\n",
    "    all_outputs = []\n",
    "    inputs = decoder_inputs\n",
    "    for _ in range(label_pad_up_to):\n",
    "        # Run the decoder on one timestep\n",
    "        outputs, state_h, state_c = decoder_lstm(inputs,\n",
    "                                             initial_state=states)\n",
    "        outputs = decoder_dense(outputs)\n",
    "        # Store the current prediction (we will concatenate all predictions later)\n",
    "        all_outputs.append(outputs)\n",
    "        # Reinject the outputs as inputs for the next loop iteration\n",
    "        # as well as update the states\n",
    "        inputs = outputs\n",
    "        states = [state_h, state_c]\n",
    "\n",
    "    # Concatenate all predictions\n",
    "    decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
    "\n",
    "    # Define and compile model as previously\n",
    "    model_T = Model([LSTM_info_inputs, LSTM_questions_inputs, LSTM_facts_inputs, \\\n",
    "                     LSTM_rela_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    model_T.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model_T\n",
    "\n",
    "#Example inputs: X1 = \"There are four apples at the top of the tree.\" X2 = \"What do you need to get the apples?\"\n",
    "# X3 = \"Trees are high.\"  Label result = \"Trees -> High\"\n",
    "#Example inputs: X1 = \"There are four apples at the top of the tree.\" X2 = \"What do you need to get the apples?\"\n",
    "# X3 = \"Pick apples from tree.\"  Label result = \"Apples -> On tree\"\n",
    "#Example inputs: X1 = \"Apples->On tree, Tree->High\" X2 = \"What do you need to get the apples?\"\n",
    "# X3 = \"You can go on tree with a ladder.\"  Label result = \"Ladder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "cascaded_reasoning loaded\n",
      "Train on 71 samples, validate on 8 samples\n",
      "Epoch 1/50\n",
      "71/71 [==============================] - 71s 1s/step - loss: 2.5034 - acc: 0.0051 - val_loss: 2.3798 - val_acc: 0.9600\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 2.3812 - acc: 0.9428 - val_loss: 2.2177 - val_acc: 0.9600\n",
      "Epoch 3/50\n",
      "71/71 [==============================] - 4s 54ms/step - loss: 2.2214 - acc: 0.9428 - val_loss: 1.5706 - val_acc: 0.9600\n",
      "Epoch 4/50\n",
      "71/71 [==============================] - 4s 54ms/step - loss: 1.5825 - acc: 0.9428 - val_loss: 0.2293 - val_acc: 0.9600\n",
      "Epoch 5/50\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.3024 - acc: 0.9428 - val_loss: 0.1804 - val_acc: 0.9600\n",
      "Epoch 6/50\n",
      "71/71 [==============================] - 4s 54ms/step - loss: 0.2189 - acc: 0.9428 - val_loss: 0.1699 - val_acc: 0.9675\n",
      "Epoch 7/50\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.1935 - acc: 0.9555 - val_loss: 0.1493 - val_acc: 0.9600\n",
      "Epoch 8/50\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.1924 - acc: 0.9428 - val_loss: 0.1820 - val_acc: 0.9575\n",
      "Epoch 9/50\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.1923 - acc: 0.9600 - val_loss: 0.1379 - val_acc: 0.9600\n",
      "Epoch 10/50\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.1820 - acc: 0.9428 - val_loss: 0.1440 - val_acc: 0.9675\n",
      "Epoch 11/50\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.1654 - acc: 0.9555 - val_loss: 0.1342 - val_acc: 0.9675\n",
      "Epoch 12/50\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.1610 - acc: 0.9555 - val_loss: 0.1359 - val_acc: 0.9675\n",
      "Epoch 13/50\n",
      "71/71 [==============================] - 4s 57ms/step - loss: 0.1580 - acc: 0.9555 - val_loss: 0.1311 - val_acc: 0.9675\n",
      "Epoch 14/50\n",
      "71/71 [==============================] - 4s 61ms/step - loss: 0.1558 - acc: 0.9555 - val_loss: 0.1325 - val_acc: 0.9675\n",
      "Epoch 15/50\n",
      "71/71 [==============================] - 4s 62ms/step - loss: 0.1539 - acc: 0.9555 - val_loss: 0.1279 - val_acc: 0.9675\n",
      "Epoch 16/50\n",
      "71/71 [==============================] - 4s 58ms/step - loss: 0.1524 - acc: 0.9555 - val_loss: 0.1314 - val_acc: 0.9575\n",
      "Epoch 17/50\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.1512 - acc: 0.9600 - val_loss: 0.1243 - val_acc: 0.9675\n",
      "Epoch 18/50\n",
      "71/71 [==============================] - 6s 82ms/step - loss: 0.1504 - acc: 0.9555 - val_loss: 0.1347 - val_acc: 0.9575\n",
      "Epoch 19/50\n",
      "71/71 [==============================] - 6s 81ms/step - loss: 0.1504 - acc: 0.9600 - val_loss: 0.1197 - val_acc: 0.9675\n",
      "Epoch 20/50\n",
      "71/71 [==============================] - 5s 76ms/step - loss: 0.1520 - acc: 0.9555 - val_loss: 0.1452 - val_acc: 0.9575\n",
      "Epoch 21/50\n",
      "71/71 [==============================] - 5s 68ms/step - loss: 0.1544 - acc: 0.9600 - val_loss: 0.1178 - val_acc: 0.9675\n",
      "Epoch 22/50\n",
      "71/71 [==============================] - 4s 58ms/step - loss: 0.1545 - acc: 0.9555 - val_loss: 0.1397 - val_acc: 0.9575\n",
      "Epoch 23/50\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.1509 - acc: 0.9600 - val_loss: 0.1181 - val_acc: 0.9675\n",
      "Epoch 24/50\n",
      "71/71 [==============================] - 4s 58ms/step - loss: 0.1480 - acc: 0.9555 - val_loss: 0.1296 - val_acc: 0.9575\n",
      "Epoch 25/50\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.1456 - acc: 0.9600 - val_loss: 0.1195 - val_acc: 0.9675\n",
      "Epoch 26/50\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.1444 - acc: 0.9555 - val_loss: 0.1260 - val_acc: 0.9575\n",
      "Epoch 27/50\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.1435 - acc: 0.9600 - val_loss: 0.1193 - val_acc: 0.9575\n",
      "Epoch 28/50\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.1428 - acc: 0.9600 - val_loss: 0.1249 - val_acc: 0.9575\n",
      "Epoch 29/50\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.1422 - acc: 0.9600 - val_loss: 0.1180 - val_acc: 0.9575\n",
      "Epoch 30/50\n",
      "71/71 [==============================] - 4s 57ms/step - loss: 0.1417 - acc: 0.9600 - val_loss: 0.1258 - val_acc: 0.9575\n",
      "Epoch 31/50\n",
      "71/71 [==============================] - 5s 73ms/step - loss: 0.1414 - acc: 0.9600 - val_loss: 0.1155 - val_acc: 0.9575\n",
      "Epoch 32/50\n",
      "71/71 [==============================] - 6s 79ms/step - loss: 0.1414 - acc: 0.9600 - val_loss: 0.1301 - val_acc: 0.9575\n",
      "Epoch 33/50\n",
      "71/71 [==============================] - 5s 75ms/step - loss: 0.1420 - acc: 0.9600 - val_loss: 0.1122 - val_acc: 0.9675\n",
      "Epoch 34/50\n",
      "71/71 [==============================] - 5s 71ms/step - loss: 0.1434 - acc: 0.9555 - val_loss: 0.1360 - val_acc: 0.9575\n",
      "Epoch 35/50\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.1441 - acc: 0.9600 - val_loss: 0.1113 - val_acc: 0.9675\n",
      "Epoch 36/50\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.1431 - acc: 0.9555 - val_loss: 0.1301 - val_acc: 0.9575\n",
      "Epoch 37/50\n",
      "71/71 [==============================] - 4s 57ms/step - loss: 0.1409 - acc: 0.9600 - val_loss: 0.1127 - val_acc: 0.9575\n",
      "Epoch 38/50\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.1392 - acc: 0.9600 - val_loss: 0.1235 - val_acc: 0.9575\n",
      "Epoch 39/50\n",
      "71/71 [==============================] - 4s 57ms/step - loss: 0.1377 - acc: 0.9600 - val_loss: 0.1138 - val_acc: 0.9575\n",
      "Epoch 40/50\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.1369 - acc: 0.9600 - val_loss: 0.1208 - val_acc: 0.9575\n",
      "Epoch 41/50\n",
      "71/71 [==============================] - 4s 57ms/step - loss: 0.1362 - acc: 0.9600 - val_loss: 0.1138 - val_acc: 0.9575\n",
      "Epoch 42/50\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.1358 - acc: 0.9600 - val_loss: 0.1200 - val_acc: 0.9575\n",
      "Epoch 43/50\n",
      "71/71 [==============================] - 6s 83ms/step - loss: 0.1354 - acc: 0.9600 - val_loss: 0.1130 - val_acc: 0.9575\n",
      "Epoch 44/50\n",
      "71/71 [==============================] - 6s 83ms/step - loss: 0.1351 - acc: 0.9600 - val_loss: 0.1207 - val_acc: 0.9575\n",
      "Epoch 45/50\n",
      "71/71 [==============================] - 6s 81ms/step - loss: 0.1348 - acc: 0.9600 - val_loss: 0.1114 - val_acc: 0.9575\n",
      "Epoch 46/50\n",
      "71/71 [==============================] - 6s 81ms/step - loss: 0.1348 - acc: 0.9600 - val_loss: 0.1225 - val_acc: 0.9575\n",
      "Epoch 47/50\n",
      "71/71 [==============================] - 5s 73ms/step - loss: 0.1345 - acc: 0.9600 - val_loss: 0.1090 - val_acc: 0.9575\n",
      "Epoch 48/50\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.1348 - acc: 0.9600 - val_loss: 0.1263 - val_acc: 0.9575\n",
      "Epoch 49/50\n",
      "71/71 [==============================] - 4s 58ms/step - loss: 0.1349 - acc: 0.9600 - val_loss: 0.1071 - val_acc: 0.9575\n",
      "Epoch 50/50\n",
      "71/71 [==============================] - 4s 59ms/step - loss: 0.1349 - acc: 0.9600 - val_loss: 0.1262 - val_acc: 0.9575\n",
      "model fit\n"
     ]
    }
   ],
   "source": [
    "#tests.test_model_final(model_final)\n",
    "batch_size = 79\n",
    "\n",
    "print(len(label_index_to_words))\n",
    "\n",
    "cascaded_reasoning= cascaded_reasoning(vectorized_info.shape, vectorized_questions.shape, \\\n",
    "                       vectorized_fact_list.shape, vectorized_relations.shape, len(label_index_to_words))\n",
    "\n",
    "print('cascaded_reasoning loaded')\n",
    "\n",
    "# Prepare decoder input data that just contains the start character\n",
    "# Note that we could have made it a constant hard-coded in the model\n",
    "decoder_input_data = np.zeros((len(new_facts_list), 1, len(label_index_to_words)))\n",
    "decoder_input_data[:, 0, label_words_to_index['\\t']] = 1.\n",
    "\n",
    "cascaded_reasoning.fit([vectorized_info, vectorized_questions, \\\n",
    "                        vectorized_fact_list, vectorized_relations, decoder_input_data], \\\n",
    "                       label_array, batch_size=batch_size, epochs=50, validation_split=0.1)\n",
    "\n",
    "print(\"model fit\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hidden_units = 128\n",
    "latent_dim = 128 \n",
    "labels_index_len = len(label_index_to_words)\n",
    "    \n",
    "LSTM_info_inputs = Input(shape=(None, vectorized_info.shape[2]))\n",
    "LSTM_info = LSTM(hidden_units,return_state=True)\n",
    "LSTM_info_output, info_h, info_c=LSTM_info(LSTM_info_inputs)\n",
    "info_states = [info_h,info_c]\n",
    "    \n",
    "LSTM_questions_inputs = Input(shape=(None, vectorized_questions.shape[2]))\n",
    "LSTM_questions = LSTM(hidden_units,return_state=True)\n",
    "LSTM_questions_output, questions_h, questions_c=LSTM_questions(LSTM_questions_inputs)\n",
    "questions_states= [questions_h,questions_c]\n",
    "    \n",
    "LSTM_facts_inputs = Input(shape=(None, vectorized_fact_list.shape[2]))\n",
    "LSTM_facts = LSTM(hidden_units,return_state=True)\n",
    "LSTM_facts_output, facts_h, facts_c=LSTM_facts(LSTM_facts_inputs)\n",
    "facts_states= [facts_h,facts_c]\n",
    "    \n",
    "LSTM_rela_inputs = Input(shape=(None, vectorized_relations.shape[2]))\n",
    "LSTM_rela = LSTM(hidden_units,return_state=True)\n",
    "LSTM_rela_output,rela_h,rela_c=LSTM_rela(LSTM_rela_inputs)\n",
    "rela_states= [rela_h,rela_c]\n",
    "    \n",
    "added_h = keras.layers.Add()([info_h,questions_h,facts_h,rela_h])\n",
    "added_c = keras.layers.Add()([info_c,questions_c,facts_c,rela_c])\n",
    "states = [added_h,added_c]\n",
    "\n",
    "encoder_model = Model([LSTM_info_inputs,LSTM_questions_inputs,LSTM_facts_inputs,LSTM_rela_inputs],states)\n",
    "\n",
    "fact_model = Model(LSTM_facts_inputs, facts_states)\n",
    "ques_model = Model(LSTM_questions_inputs, questions_states)\n",
    "info_model = Model(LSTM_info_inputs, info_states)\n",
    "rela_model = Model(LSTM_rela_inputs, rela_states)\n",
    "\n",
    "decoder_inputs = Input(shape=(1, labels_index_len))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_dense = Dense(labels_index_len, activation='softmax')\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decode_sequence(info_input, facts_input, ques_input, rela_input,label_words_to_index=label_words_to_index, \\\n",
    "                                        label_index_to_words=label_index_to_words, label_pad_up_to=label_pad_up_to):\n",
    "    \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict([info_input, facts_input, ques_input, rela_input])\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, len(label_words_to_index)))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, label_words_to_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = label_index_to_words[sampled_token_index]\n",
    "        decoded_sentence += sampled_char + \" \"\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > label_pad_up_to):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, len(label_words_to_index)))\n",
    "        target_seq[0, 0, label_words_to_index['\\t']] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_info =  vectorized_info[0,:,:]\n",
    "test_info = test_info.reshape(1,*test_info.shape) \n",
    "test_fact = vectorized_fact_list[0,:,:]\n",
    "test_fact = test_fact.reshape(1,*test_fact.shape)\n",
    "test_ques = vectorized_questions[0,:,:]\n",
    "test_ques = test_ques.reshape(1,*test_ques.shape)\n",
    "test_rela = vectorized_relations[0,:,:]\n",
    "test_rela = test_rela.reshape(1,*test_rela.shape)\n",
    "\n",
    "decoded_sentence = decode_sequence(test_info, test_fact, test_ques, test_rela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN2 IN2 IN2 IN2 IN2 IN2 IN2 IN2 IN2 IN2 IN2 IN2 IN2 \n"
     ]
    }
   ],
   "source": [
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
